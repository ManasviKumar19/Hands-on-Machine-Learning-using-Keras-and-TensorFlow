{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3882ce44-45a4-42b9-8930-3463aee7c922",
   "metadata": {},
   "source": [
    "# Processing Sequences Using RNNs and CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d11690-461d-4999-a37a-d165a4921c36",
   "metadata": {},
   "source": [
    "In this chapter we will discuss recurrent neural networks (RNNs), a class of nets that can predict the future (well, up to a point, of course). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb6cd9-2092-4865-977d-f4a5d5b17ed5",
   "metadata": {},
   "source": [
    "They can analyze time series data such as stock prices, and tell you when to buy or sell. In autonomous driving systems, they can anticipate car trajectories and help avoid accidents. More generally, they can work on sequences of arbitrary lengths, rather than on fixed-sized inputs like all the nets we have considered so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704121fb-51bf-4147-b116-46f2be478850",
   "metadata": {},
   "source": [
    "For example, they can take sentences, documents, or audio samples as input, making them extremely useful for natural language processing applications such as automatic translation or speech-to-text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f957e-e8fc-4c88-93bc-ddb8d108fa8f",
   "metadata": {},
   "source": [
    "## Important Definition Timestep\n",
    "\n",
    "1) In figure 15-7 of the book, the timestep is X(0), X(1), X(t-1), X(t) which means the network is unrolling through time from left to right. In figure it shows that the network goes from left to right while the input goes from bottom to top in the layers in RNN.\n",
    "2) For the Batch Normalization with RNNs block in Fighting the Unstable Gradients Problem, the first point that says \"Batch Normalization cannot be used as efficiently with RNNs as with deep feedforward nets. In fact, you cannot use it between time steps, only between recurrent layers.\" means that you cannot apply BN for the unrolling part that is between X(0) to X(t) but you can only apply for the input that goes from bottom to top in the layers in RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6b919c-650f-4fd5-a912-ee2c6875a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651ac7c0-031d-4ae9-ba7e-6b4d581e1a8d",
   "metadata": {},
   "source": [
    "## Chapter Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd519e6b-8788-42d0-a26b-a25e81923ddd",
   "metadata": {},
   "source": [
    "In this chapter we will first look at the fundamental concepts underlying RNNs and how to train them using backpropagation through time, then we will use them to forecast a time series. After that we’ll explore the two main difficulties that RNNs face:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a9169-046b-49d4-b597-c921fa3bb14b",
   "metadata": {},
   "source": [
    "1) Unstable gradients, which can be alleviated using various techniques, including recurrent dropout and recurrent layer normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5cec60-85c0-441b-9e7d-e0667d614b44",
   "metadata": {},
   "source": [
    "2) A (very) limited short-term memory, which can be extended using LSTM and GRU cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c09de0-6562-452d-8e08-fb0473aaa074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0005a5bf-ef99-4786-b62a-fafc73255877",
   "metadata": {},
   "source": [
    "### RNNs vs CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de765a06-6edb-45f7-ab1f-89bf8e358a37",
   "metadata": {},
   "source": [
    "RNNs are not the only types of neural networks capable of handling sequential data: for small sequences, a regular dense network can do the trick; and for very long sequences, such as audio samples or text, convolutional neural networks can actually work quite well too. We will discuss both of these possibilities, and we will finish this chapter by implementing a WaveNet: this is a CNN architecture capable of handling sequences of tens of thousands of time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a695f7-5698-430b-a081-0655c6fbc31c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6b240fc-273a-4ee1-8d06-1011707f7fcd",
   "metadata": {},
   "source": [
    " ## Recurrent Neurons and Layers\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7082b-4795-456f-bd81-0a1fade2ab64",
   "metadata": {},
   "source": [
    "Up to now we have focused on feedforward neural networks, where the activations flow only in one direction, from the input layer to the output layer. A recurrent neural network looks very much like a feedforward neural network, except it also has connections pointing backward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980f0aa-c90c-41f3-98db-7f75ca23d1a0",
   "metadata": {},
   "source": [
    "A recurrent neural network looks very much like a feedforward neural network, except it also has connections pointing backward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d66641f-8353-4fca-9161-e1f488bb2923",
   "metadata": {},
   "source": [
    "### RNN example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1d503-8bfa-4dc5-9bb7-df5c8569eca6",
   "metadata": {},
   "source": [
    "Let’s look at the simplest possible RNN, it is composed of one neuron receiving inputs, producing an output, and sending that output back to itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d94fcc-0b6e-48ea-ad71-dc58711b7011",
   "metadata": {},
   "source": [
    "At each time step t (also called a frame), this recurrent neuron receives the inputs x(t) as well as its own output from the previous time step, y(t–1). Since there is no previous output at the first time step, it is generally set to 0. We can represent this tiny network against the time axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa036e-0238-42cd-9d10-b78604e03898",
   "metadata": {},
   "source": [
    "This is called unrolling the network through time (it’s the same recurrent neuron represented once per time step). See Fig 15-1 from book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bffe7d-1091-448c-9afe-01b84a182229",
   "metadata": {},
   "source": [
    "### Creating RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c33dd3-be5f-4af8-93e8-26f8235618ed",
   "metadata": {},
   "source": [
    "You can easily create a layer of recurrent neurons. At each time step t, every neuron receives both the input vector x(t) and the output vector from the previous time step y(t–1). Note that both the inputs and outputs are vectors now (when there was just a single neuron, the output was a scalar). See Fig 15-2 from the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc24cf7-7517-4c44-a3ce-8c8fc4eab1d0",
   "metadata": {},
   "source": [
    "### Weights and Equations of RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eebe32-1459-4ff8-95ef-3cab0753a8a6",
   "metadata": {},
   "source": [
    "Each recurrent neuron has two sets of weights: one for the inputs x(t) and the other for the outputs of the previous time step, y(t–1). Let’s call these weight vectors wx and wy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd448756-08d2-4b66-bd4a-b552d3e0cd59",
   "metadata": {},
   "source": [
    "If we consider the whole recurrent layer instead of just one recurrent neuron, we can place all the weight vectors in two weight matrices, Wx and Wy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3941ce3-4e7f-4b59-8955-5650398191cb",
   "metadata": {},
   "source": [
    "The output vector of the whole recurrent layer can then be computed pretty much as you might expect, as shown.(b is the bias vector and ϕ(·) is the activation function (e.g., ReLU))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcd9e59-ff3c-4997-9142-4666ae23fb82",
   "metadata": {},
   "source": [
    "$$\r\n",
    "y_t = \\phi(W_x \\cdot x_t + W_y \\cdot y_{t-1} + b)\r\n",
    "$$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061d1e6-3efe-4981-897d-2b2c7f56c562",
   "metadata": {},
   "source": [
    "Just as with feedforward neural networks, we can compute a recurrent layer’s output in one shot for a whole mini-batch by placing all the inputs at time step t in an input matrix X(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201687c-51b5-44a2-984d-738263444fab",
   "metadata": {},
   "source": [
    "$$\r",
    "y_t = \n",
    "\\phi\\left(\\begin{bmatrix} X_t & Y_{t-1} \\end{bmatrix} W + b\\right), \\quad \\text{where} \\quad W = \\begin{bmatrix} W_x \\\\ W_y \\end{bmatrix}\r\n",
    "$$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec9864-7919-4588-a149-9ced90ea9205",
   "metadata": {},
   "source": [
    "#### Equation terms explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f818b-4188-450e-8a0f-7cb08e7d55ff",
   "metadata": {},
   "source": [
    "In this equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f99e9-6ab9-4eed-b25d-c77dffcd464c",
   "metadata": {},
   "source": [
    "1) Y(t):- Is an m × n_neurons matrix containing the layer’s outputs at time step t for each instance in the mini-batch (m is the number of instances in the mini-batch and n_neurons is the number of neurons)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82181a6-00d5-4d9e-b282-b091c6a5075f",
   "metadata": {},
   "source": [
    "2) X(t) :- Is an m × n_inputs matrix containing the inputs for all instances (n_inputs is the number of input features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3706ef-7f60-4d13-a0d4-3997ed6df74c",
   "metadata": {},
   "source": [
    "3. Wx :- Is an n_inputs × n_neurons matrix containing the connection weights for the inputs of the current time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db03ad4-aa09-4b9b-a9dd-2ca8e8999c1b",
   "metadata": {},
   "source": [
    "4. Wy :- Is an nneurons × nneurons matrix containing the connection weights for the outputs of the previous time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca36de3-5aa2-41a1-b425-b6eb2ccd7d1f",
   "metadata": {},
   "source": [
    "5. b is a vector of size n_neurons containing each neuron’s bias term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f512104a-6574-4572-ad3b-1e59e5da84b3",
   "metadata": {},
   "source": [
    "6. The weight matrices Wx and Wy are often concatenated vertically into a single weight matrix W of shape (n_inputs + n_neurons) × n_neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68dc394-9970-4797-a06f-af389c8ab536",
   "metadata": {},
   "source": [
    "7. The notation [X(t) Y(t–1)] represents the horizontal concatenation of the matrices X(t) and Y(t–1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f679af06-5300-471b-b9d8-b7ede7b03f60",
   "metadata": {},
   "source": [
    "#### Y(t)\n",
    "Notice that Y(t), that is the current output is a function of X(t) and Y(t–1), which is a function of X(t–1) and Y(t–2), which is a function of X(t–2) and Y(t–3), and so on. This makes Y(t) a function of all the inputs since time t = 0 (that is, X(0), X(1), …, X(t) ). At the first time step, t = 0, there are no previous outputs, so they are typically assumed to be all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de979a2-42ac-4c0a-890a-4ebc2729790a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3ef54-072e-45f8-b653-7859fdf7cdae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da59bfb-33e3-4516-98bb-7bf796f68f1c",
   "metadata": {},
   "source": [
    "## Memory Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1c5b15-feb7-4f93-afa5-2f5f7112b5e5",
   "metadata": {},
   "source": [
    "Since the output of a recurrent neuron at time step t is a function of all the inputs from previous time steps, you could say it has a form of memory. A part of a neural network that preserves some state across time steps is called a memory cell (or simply a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c7e131-c719-45b0-aae7-ca4443ac9766",
   "metadata": {},
   "source": [
    "A single recurrent neuron, or a layer of recurrent neurons, is a very basic cell, capable of learning only short patterns (typically about 10 steps long, but this varies depending on the task)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0108d-71da-44f5-a8e6-371bbabdde83",
   "metadata": {},
   "source": [
    "### Cell's state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87c568-1275-4faa-85de-1b56d6cbec07",
   "metadata": {},
   "source": [
    "In general a cell’s state at time step t, denoted h(t) (the “h” stands for “hidden”), is a function of some inputs at that time step and its state at the previous time step: h(t) = f(h(t–1), x(t))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0cb53a-4a22-49a0-ad50-f859e5e0917e",
   "metadata": {},
   "source": [
    "Its output at time step t, denoted y(t) , is also a function of the previous state and the current inputsf(h(t–1), x(t)). In the case of the basic cells we have discussed so far, the output is simply equal to the state, but in more complex cells this is not always the case. See fig-15-3 in the right side, the hidden state h(0) of neuron x(0) is given as the hidden state for neuron x(1). Hence here the hidden state of neuron x(1) becomes h(0), however, the output computed by x(1) is y(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d0c7c-177e-4473-b21a-d56365949ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c9443-44b1-457a-8d7e-5dd6df158f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01017a6b-e01c-470a-9ca5-d489bac614ae",
   "metadata": {},
   "source": [
    "## Input and Output Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147dbadf-a067-410a-84a9-4430f3b8a7a3",
   "metadata": {},
   "source": [
    "### Sequence-to-Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd71901-e20d-4bbb-b0f7-af0eb89425f2",
   "metadata": {},
   "source": [
    "An RNN can simultaneously take a sequence of inputs and produce a sequence of outputs (see the top-left network in Figure 15-4). This type of sequence-to-sequence network is useful for predicting time series such as stock prices: you feed it the prices over the last N days, and it must output the prices shifted by one day into the future (i.e., from N – 1 days ago to tomorrow)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83c434-c016-4010-a292-9fe246585911",
   "metadata": {},
   "source": [
    "### Sequence-to-Vector network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d0e45-4c52-4bb0-8753-16c01282ba90",
   "metadata": {},
   "source": [
    "Alternatively, you could feed the network a sequence of inputs and ignore all outputs except for the last one (see the top-right network in Figure 15-4). In other words, this is a sequence-to-vector network. For example, you could feed the network a sequence of words corresponding to a movie review, and the network would output a sentiment score (e.g., from –1 [hate] to +1 [love])."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c87c001-006c-494c-baae-fde9cac7f488",
   "metadata": {},
   "source": [
    "### Vector-to-Sequence network\n",
    "Conversely, you could feed the network the same input vector over and over again at each time step and let it output a sequence (see the bottom-left network of Figure 15-4). This is a vector-to-sequence network. For example, the input could be an image (or the output of a CNN), and the output could be a caption for that image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5429b481-1acd-478a-8ff4-05c481d2c6b5",
   "metadata": {},
   "source": [
    "### Encoder Decoder\n",
    "Lastly, you could have a sequence-to-vector network, called an encoder, followed by a vector-to-sequence network, called a decoder (see the bottom-right network of Figure 15-4). For example, this could be used for translating a sentence from one language to another. You would feed the network a sentence in one language, the encoder would convert this sentence into a single vector representation, and then the decoder would decode this vector into a sentence in another language. This two-step model, called an Encoder–Decoder, works much better than trying to translate on the fly with a single sequence-to-sequence RNN (like the one represented at the top left): the last words of a sentence can affect the first words of the translation, so you need to wait until you have seen the whole sentence before translating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dadee4-1811-4cc9-bf0e-e75f1a5c0e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "221b6e7d-9804-46dc-a77c-3dc5e9a11e98",
   "metadata": {},
   "source": [
    "## Training RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1dd2c9-1865-4c70-9cde-8c87e8b91a2a",
   "metadata": {},
   "source": [
    "### Backpropagation through time (BPTT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585021e-6548-40ed-99f9-aa43f6c9c3a5",
   "metadata": {},
   "source": [
    "To train an RNN, the trick is to unroll it through time (like we just did) and then simply use regular backpropagation. This strategy is called backpropagation through time (BPTT)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a3b9a-dfc6-45cc-976d-08d1bfedfb1f",
   "metadata": {},
   "source": [
    "### Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c91f89-7489-4f3c-804a-41c3896920f2",
   "metadata": {},
   "source": [
    "Just like in regular backpropagation, there is a first forward pass through the unrolled network (represented by the dashed arrows). Then the output sequence is evaluated using a cost function C(Y(0), Y(1), …Y(T) ) (where T is the max time step). Note that this cost function may ignore some outputs, as shown in Figure 15-5 (for example, in a sequence-to-vector RNN, all outputs are ignored except for the very last one)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e27635-c1db-4007-9dec-b1ee1eef7731",
   "metadata": {},
   "source": [
    "The gradients of that cost function are then propagated backward through the unrolled network (represented by the solid arrows). Finally the model parameters are updated using the gradients computed during BPTT(Note, here BPTT is very similar to normal BP, only difference is that for each error and weight matrix, we also have the historical data, like how Y(current) is the function of previous state and current input) so when BPTT we are updating based on all the timesteps now and not just current)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f99a8f-47b2-4c72-b30b-c50a77c27567",
   "metadata": {},
   "source": [
    "Note that the gradients flow backward through only the outputs that were used by the cost function, not just through the final output (for example, in Figure 15-5 the cost function is computed using the last three outputs of the network, Y(2), Y(3), and Y(4), so gradients flow through these three outputs, but not through Y(0) and Y(1)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808deec-1efc-4d11-8fe7-4e73ed3f5ca7",
   "metadata": {},
   "source": [
    "Moreover, since the same parameters W and b are used at each time step, backpropagation through time will do the right thing and sum over all time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc2424-36ff-4a80-bce9-7e9a68388528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b69c19-8765-419c-b7a1-b88ea3c1f9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8dd293-7382-4444-abde-9005135a870c",
   "metadata": {},
   "source": [
    "## Forecasting a Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5897bd-2954-4b5d-a73d-8ef39100e5eb",
   "metadata": {},
   "source": [
    "Suppose you are studying the number of active users per hour on your website, or the daily temperature in your city, or your company’s financial health, measured quarterly using multiple metrics. In all these cases, the data will be a sequence of one or more values per time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2955fe4d-6e0d-4406-a020-d82d84cf2801",
   "metadata": {},
   "source": [
    "This is called a time series. In the first two examples there is a single value per time step, so these are univariate time series, while in the financial example there are multiple values per time step (e.g., the company’s revenue, debt, and so on), so it is a multivariate time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4334f3-4663-44cf-afc5-eba6127d460f",
   "metadata": {},
   "source": [
    "#### Forecasting and Postdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99514056-e906-4966-892b-499aedb77d2d",
   "metadata": {},
   "source": [
    "A typical task is to predict future values, which is called forecasting. Another common task is to fill in the blanks: to predict (or rather “postdict”) missing values from the past.This is called $imputation$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6319669f-1cc2-47cb-97e7-82abb6726ce1",
   "metadata": {},
   "source": [
    "For example, Figure 15-6 shows 3 univariate time series, each of them 50 time steps long, and the goal here is to forecast the value at the next time step (represented by the X) for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb18dc-6d3b-4129-b98b-7da716723317",
   "metadata": {},
   "source": [
    "### Generating Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a9550-cc36-408d-bea5-8ad8e14ba9b1",
   "metadata": {},
   "source": [
    "For simplicity, we are using a time series generated by the generate_time_series() function, shown here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4de8fc-ce94-403f-8677-dd1539ab7e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e20e6cf-a716-45e5-8bd8-e0279acbc511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5c5372-793b-4c20-8d80-0290b08bb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10)) # wave 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # + wave 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5) # + noise\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5fbf88-c76d-4c46-b804-b92f779e5bac",
   "metadata": {},
   "source": [
    "#### generate_time_series function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6823d-b7ab-4b42-90c1-0e14c7db105f",
   "metadata": {},
   "source": [
    "This function creates as many time series as requested (via the batch_size argument), each of length n_steps, and there is just one value per time step in each series (i.e., all series are univariate). The function returns a NumPy array of shape [batch size, time steps, 1], where each series is the sum of two sine waves of fixed amplitudes but random frequencies and phases, plus a bit of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc3cbe-fe72-4841-869d-4dfeee241c44",
   "metadata": {},
   "source": [
    "### Note about dimension of time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7c6eb4-aee0-4676-9053-9221d329b6be",
   "metadata": {},
   "source": [
    "When dealing with time series (and other types of sequences such as sentences), the input features are generally represented as 3D arrays of shape [batch size, time steps, dimensionality], where dimensionality is 1 for univariate time series and more for multivariate time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265433cd-0bb1-4beb-a919-72b4ab36528a",
   "metadata": {},
   "source": [
    "### Creating the Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205ccd8-91e2-4b29-ab9d-4c22dd816ad1",
   "metadata": {},
   "source": [
    "Now let’s create a training set, a validation set, and a test set using this function:\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81935c9-c493-4ea9-87b9-51c236a1c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0449e512-597b-4460-b0dd-536bca834392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 50, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape # We have 7000 time series, each with 50 timesteps or 50 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca02658e-9c9d-475e-9ccd-bf94ac8d6a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee1c789-20a4-4ec9-8b24-9f044ccb4254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bee96-f931-4c39-9642-5e0bde6e1ea3",
   "metadata": {},
   "source": [
    "#### Code explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb0aea7-bd12-41d2-80d0-c6d7b66c2be8",
   "metadata": {},
   "source": [
    "X_train contains 7,000 time series (i.e., its shape is [7000, 50, 1]), while X_valid contains 2,000 (from the 7,000th time series to the 8,999th) and X_test contains 1,000 (from the 9,000th to the 9,999th). Since we want to forecast a single value for each series, the targets are column vectors (e.g., y_train has a shape of [7000, 1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e247701-43d6-4b17-8b69-9cc5ea0922db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49eb6562-c680-4f4a-9c83-95796a84cb10",
   "metadata": {},
   "source": [
    "## Baseline Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629980ff-61ac-4ad6-968b-0c0bc5bc1ce7",
   "metadata": {},
   "source": [
    "Before we start using RNNs, it is often a good idea to have a few baseline metrics, or else we may end up thinking our model works great when in fact it is doing worse than basic models. For example, the simplest approach is to predict the last value in each series. This is called naive forecasting, and it is sometimes surprisingly difficult to outperform. In this case, it gives us a mean squared error of about 0.020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "975530f8-1211-4fd5-ab08-b49718577d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02010869"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = X_valid[:, -1]\n",
    "np.mean(keras.losses.mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fac87843-e1b7-4589-b52d-c681fa107437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 50, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_valid.shape)\n",
    "X_valid[:, -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab68ef61-e395-41a1-a601-e3e129338e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06317361],\n",
       "       [ 0.53231114],\n",
       "       [-0.17881976],\n",
       "       ...,\n",
       "       [-0.46301198],\n",
       "       [ 0.32124105],\n",
       "       [-0.5564701 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb40e30a-8894-4c1d-a306-a076cb3f2f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06317361]\n",
      "[0.53231114]\n",
      "[-0.17881976]\n",
      "[-0.46301198]\n",
      "[0.32124105]\n",
      "[-0.5564701]\n"
     ]
    }
   ],
   "source": [
    "print(X_valid[0][-1])\n",
    "print(X_valid[1][-1])\n",
    "print(X_valid[2][-1])\n",
    "print(X_valid[1997][-1])\n",
    "print(X_valid[1998][-1])\n",
    "print(X_valid[1999][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599b421-023b-4911-8dd7-55e7f03ee90c",
   "metadata": {},
   "source": [
    "#### Explanation of slicing in  X_valid[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1608a1-d147-45d1-b944-b677c5a2186c",
   "metadata": {},
   "source": [
    "So here in X_valid, we have 2000 time series, each with 50 values or 50 timesteps, now when we do X_valid[:, -1], what we're doing is that we select the last value from the 50 values for each of the 2000 timeseries. This can be verified by checking the above two blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64411638-2673-434e-8a2f-503f37f00260",
   "metadata": {},
   "source": [
    "### Baseling using Fully connected layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8dc9b-77e1-4153-b62d-303a81b47b29",
   "metadata": {},
   "source": [
    "Another simple approach is to use a fully connected network. Since it expects a flat\r\n",
    "list of features for each input, we need to add a Flatten layer. Let’s just use a simple\r\n",
    "Linear Regression model so that each prediction will be a linear combination of the\r\n",
    "values in the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75e8754-11ab-4076-bf4a-08583f62939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.Flatten(input_shape=[50, 1]),\n",
    " keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc927e7-ebb5-4f71-acac-3ff61f2dff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.1222 - val_loss: 0.0562\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0243\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0195 - val_loss: 0.0146\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0095 - val_loss: 0.0086\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 1s 2ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2530231-410e-4850-bb0b-9bab425fed5d",
   "metadata": {},
   "source": [
    "If we compile this model using the MSE loss and the default Adam optimizer, then fit it on the training set for 20 epochs and evaluate it on the validation set, we get an MSE of about 0.0037. That’s much better than the naive approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea1db69e-383d-4bd7-8562-f3c8732bd6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.0036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.003617848502472043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e1d99e-a253-4543-a99f-c523b514e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c03fbe1-f6e6-4b0a-b2cc-5bfebbd75aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.-\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r.-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.axis([1, 20, 0, 0.05])\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plot_learning_curves(history.history[\"loss\"], history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236981d-e4b8-475b-a196-4ed79af0729e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b776f529-2474-453b-a345-a8b4d338bae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e198ecb9-4e52-4173-9b73-061a87b3a93b",
   "metadata": {},
   "source": [
    "## Implementing a Simple RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06632fdf-44ba-4659-9a26-9171043bfcfb",
   "metadata": {},
   "source": [
    "Let’s see if we can beat that with a simple RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2221f0c2-2d9d-45a3-ae5d-d037121f2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.4950 - val_loss: 0.2782\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.1914 - val_loss: 0.1504\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.1483 - val_loss: 0.1540\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.1472 - val_loss: 0.1463\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.1457 - val_loss: 0.1464\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.1458 - val_loss: 0.1345\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0839 - val_loss: 0.0544\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0435 - val_loss: 0.0362\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0318 - val_loss: 0.0282\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 0.0258 - val_loss: 0.0235\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0220 - val_loss: 0.0203\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0194 - val_loss: 0.0180\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0174 - val_loss: 0.0163\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0159 - val_loss: 0.0149\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0147 - val_loss: 0.0139\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 0.0138 - val_loss: 0.0130\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0130 - val_loss: 0.0123\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 2s 9ms/step - loss: 0.0117 - val_loss: 0.0111\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.SimpleRNN(1, input_shape=[None, 1]) ])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7ba6eb8-8d6e-4908-b866-53a21e9fb2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011158519424498081"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94151790-cd6f-44c0-b3ba-51bc164990a9",
   "metadata": {},
   "source": [
    "### Understanding the RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5930f2e-bf8c-4fe2-b7c8-d83bc939c89c",
   "metadata": {},
   "source": [
    "That’s really the simplest RNN you can build. It just contains a single layer, with a single neuron.We do not need to specify the length of the input sequences (unlike in the previous model), since a recurrent neural network can process any number of time steps (this is why we set the first input dimension to None)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8c570-5dac-4481-af09-ac29b5a73e3a",
   "metadata": {},
   "source": [
    "By default, the SimpleRNN layer uses the hyperbolic tangent activation function. It works exactly as we saw earlier: the initial state h(init) is set to 0, and it is passed to a single recurrent neuron, along with the value of the first time step, x(0). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf435fa-1afb-44af-be74-d4520ea2c86b",
   "metadata": {},
   "source": [
    "The neuron computes a weighted sum of these values and applies the hyperbolic tangent activation function to the result, and this gives the first output, y0 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc0c78-3776-4675-a7e7-13d0ff4e2504",
   "metadata": {},
   "source": [
    "In a simple RNN, this output is also the new state h0. This new state is passed to the same recurrent neuron along with the next input value, x(1), and the process is repeated until the last time step. Then the layer just outputs the last value, y49. All of this is performed simultaneously for every time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d834ead-2fce-48e9-a34d-9f9e98d60a42",
   "metadata": {},
   "source": [
    "### Note RNN output\n",
    "By default, recurrent layers in Keras only return the final output. To make them return one output per time step, you must set return_sequences=True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb116747-31aa-4ec8-af83-43ffe8da96f0",
   "metadata": {},
   "source": [
    "#### Conclusion Simple RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b9a32b-f0b5-479c-bb28-e889072aef45",
   "metadata": {},
   "source": [
    "If you compile, fit, and evaluate this model (just like earlier, we train for 20 epochs using Adam), you will find that its MSE reaches only 0.010, so it is better than the naive approach but it does not beat a simple linear model, where the MSE is 0.0034"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d83ca0-c529-471e-bbe5-2cc969862d5a",
   "metadata": {},
   "source": [
    "Note that for each neuron, a linear model has one parameter per input timestep(that means for every new input, meaning for 50 values there is one parameter and not like for each 50 value there is a parameter, so per input is different from per input value) , plus a bias term (in the simple linear model we used, that’s a total of 51 parameters, since we are inputting 50 timesteps each time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c2281-fa40-431d-8a3d-d3a97b5f7e56",
   "metadata": {},
   "source": [
    "In contrast, for each recurrent neuron in a simple RNN, there is just one parameter per input and per hidden state dimension (in a simple RNN, that’s just the number of recurrent neurons in the layer), plus a bias term. In this simple RNN, that’s a total of just three parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609cd57e-4c4f-4812-b55e-2aae235aa9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9af410b-7f66-4572-8ce9-55da8b5f5ed8",
   "metadata": {},
   "source": [
    "### Trend and Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a9836d-d4d7-4753-80ab-671a83c78400",
   "metadata": {},
   "source": [
    "There are many other models to forecast time series, such as weighted moving average models or autoregressive integrated moving average (ARIMA) models. Some of them require you to first remove the trend and seasonality. For example, if you are studying the number of active users on your website, and it is growing by 10% every month, you would have to remove this trend from the time series. Once the model is trained and starts making predictions, you would have to add the trend back to get the final predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428213b9-6de1-4524-ba56-1ef507697cd8",
   "metadata": {},
   "source": [
    "Similarly, if you are trying to predict the amount of sunscreen lotion sold every month, you will probably observe strong seasonality: since it sells well every summer, a similar pattern will be repeated every year. You would have to remove this seasonality from the time series, for example by computing the difference between the value at each time step and the value one year earlier (this technique is called differencing). Again, after the model is trained and makes predictions, you would have to add the seasonal pattern back to get the final predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be397bdf-de62-4c2f-ba77-905a6337d2ef",
   "metadata": {},
   "source": [
    "When using RNNs, it is generally not necessary to do all this, but it may improve performance in some cases, since the model will not have to learn the trend or the seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed1cbd-0309-49d1-9f25-3d7e352f55c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a22266e-fb80-4771-bc53-ab9a42236328",
   "metadata": {},
   "source": [
    "## Deep RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863c731-c844-43ee-bed5-816c4c5d8ab7",
   "metadata": {},
   "source": [
    "It is quite common to stack multiple layers of cells. This gives you a deep RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818bba9-e398-4078-a057-23b46c062964",
   "metadata": {},
   "source": [
    "Implementing a deep RNN with tf.keras is quite simple: just stack recurrent layers. In this example, we use three SimpleRNN layers (but we could add any other type of recurrent layer, such as an LSTM layer or a GRU layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4654ab29-b404-4921-9eeb-0e6ef197c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    " keras.layers.SimpleRNN(20, return_sequences=True),\n",
    " keras.layers.SimpleRNN(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7b748-8714-4327-93c9-97bed86c3e8f",
   "metadata": {},
   "source": [
    "### Warning - Defining RNNs\n",
    "Make sure to set return_sequences=True for all recurrent layers (except the last one if you only want the last output). If you don’t set return_sequences=True, the layers will output a 2D array (containing only the output of the last time step) instead of a 3D array (containing outputs for all time steps), and the next recurrent layer will complain that you are not feeding it sequences in the expected 3D format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e860015-3176-4dd9-a986-f7c4adc81ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 10s 31ms/step - loss: 0.0543 - val_loss: 0.0068\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 0.0061 - val_loss: 0.0057\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0032 - val_loss: 0.0027\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b30229-909b-489a-bdda-137d13318245",
   "metadata": {},
   "source": [
    "#### This model reaches an MSE of 0.003. We finally managed to beat the linear model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f47358d-f7c7-4d88-8868-eec384d7c532",
   "metadata": {},
   "source": [
    "### RNNs with Dense output layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d962caa-968e-4038-8745-bc1a96e61748",
   "metadata": {},
   "source": [
    "Note that the last layer is not ideal: it must have a single unit because we want to forecast a univariate time series, and this means we must have a single output value per time step. However, having a single unit means that the hidden state is just a single number. That’s really not much, and it’s probably not that useful; presumably, the RNN will mostly use the hidden states of the other recurrent layers to carry over all the information it needs from time step to time step, and it will not use the final layer’s hidden state very much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ebbc1-a112-4ef0-a2d0-f818352732ed",
   "metadata": {},
   "source": [
    "Moreover, since a SimpleRNN layer uses the tanh activation function by default, the predicted values must lie within the range –1 to 1. But what if you want to use another activation function? For both these reasons, it might be preferable to replace the output layer with a Dense layer: it would run slightly faster, the accuracy would be roughly the same, and it would allow us to choose any output activation function we want. If you make this change, also make sure to remove return_sequences=True from the second (now last) recurrent layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb817993-f6f5-40a2-81f6-e6e209c49a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    " keras.layers.SimpleRNN(20),\n",
    " keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea324ff-2ee2-4c82-aac5-6c89e0e284a7",
   "metadata": {},
   "source": [
    "#### If you train this model, you will see that it converges faster and performs just as well. Plus, you could change the output activation function if you wanted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11c49919-c6e8-4c26-ac81-baaa63732ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 7s 23ms/step - loss: 0.0160 - val_loss: 0.0043\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0028 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, y_train, epochs=20,validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734cab2-b36d-4fdb-806a-65f75669df67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac2999-4db7-4c8f-b0a5-2b64b410cbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e18f91-d239-45c8-b387-ce0c20e7bf31",
   "metadata": {},
   "source": [
    "## Forecasting Several Time Steps Ahead\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09d073-eafa-46b9-97ab-73ef3750ff37",
   "metadata": {},
   "source": [
    "So far we have only predicted the value at the next time step, but we could just as easily have predicted the value several steps ahead by changing the targets appropriately (e.g., to predict 10 steps ahead, just change the targets to be the value 10 steps ahead instead of 1 step ahead). But what if we want to predict the next 10 values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060b9ea-9f61-4ad5-b2ec-4e226207143b",
   "metadata": {},
   "source": [
    "The first option is to use the model we already trained, make it predict the next value, then add that value to the inputs (acting as if this predicted value had actually occurred), and use the model again to predict the following value, and so on, as in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4aeb885e-243f-4f85-84ed-c50e8464aea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.3802521 ],\n",
       "        [ 0.23149052],\n",
       "        [ 0.2192999 ],\n",
       "        [ 0.06664104],\n",
       "        [-0.01360943],\n",
       "        [-0.02652485],\n",
       "        [-0.11426771],\n",
       "        [-0.1682559 ],\n",
       "        [-0.25135887],\n",
       "        [-0.30491805],\n",
       "        [-0.42245686],\n",
       "        [-0.51784587],\n",
       "        [-0.49846223],\n",
       "        [-0.4510185 ],\n",
       "        [-0.31313136],\n",
       "        [-0.09688105],\n",
       "        [ 0.18704093],\n",
       "        [ 0.33760712],\n",
       "        [ 0.55655795],\n",
       "        [ 0.6908075 ],\n",
       "        [ 0.6606459 ],\n",
       "        [ 0.5541175 ],\n",
       "        [ 0.42396563],\n",
       "        [ 0.20434976],\n",
       "        [-0.03002512],\n",
       "        [-0.25153124],\n",
       "        [-0.38200936],\n",
       "        [-0.5031775 ],\n",
       "        [-0.49952325],\n",
       "        [-0.45007983],\n",
       "        [-0.3745698 ],\n",
       "        [-0.25856388],\n",
       "        [-0.2103539 ],\n",
       "        [-0.12440667],\n",
       "        [-0.04544733],\n",
       "        [ 0.03558336],\n",
       "        [ 0.08591889],\n",
       "        [ 0.11731767],\n",
       "        [ 0.30122334],\n",
       "        [ 0.3689921 ],\n",
       "        [ 0.49028647],\n",
       "        [ 0.51113313],\n",
       "        [ 0.51492333],\n",
       "        [ 0.46602097],\n",
       "        [ 0.2938937 ],\n",
       "        [ 0.08122978],\n",
       "        [-0.21097939],\n",
       "        [-0.44347495],\n",
       "        [-0.56730884],\n",
       "        [-0.74011475],\n",
       "        [-0.6939473 ],\n",
       "        [-0.57672274],\n",
       "        [-0.41448998],\n",
       "        [-0.19680956],\n",
       "        [ 0.1010337 ],\n",
       "        [ 0.31709963],\n",
       "        [ 0.39755008],\n",
       "        [ 0.47358713],\n",
       "        [ 0.4822212 ],\n",
       "        [ 0.46508   ]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_time_series(1, n_steps + 10)\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fb096c2-084e-4d65-94b5-90918589305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 60, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "678922dc-bb79-4e7c-8f0c-4b878f0208d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d85b9d6-cfa3-4b62-900f-2bcee283d526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fe2070a-c410-4e44-a5f3-5510948e8376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " Y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e7fc2bc-b9a9-48e9-aedb-ce0ab272b876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_new\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc8f8f-2f9c-4edf-995a-ee88bc8c4383",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4e24822-372f-4c0c-92f4-2a6816f177b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 567ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis] # https://www.reddit.com/r/learnpython/comments/13vs2fu/need_help_to_understand_the_notation_x_npnewaxis/\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "570262a9-1c97-4deb-b268-ecac9f4e6647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684ba79-b121-43a4-b89d-20e4f3181357",
   "metadata": {},
   "source": [
    "As you might expect, the prediction for the next step will usually be more accurate than the predictions for later time steps, since the errors might accumulate (as you can see in Figure below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe4d1fff-6527-43b0-8e30-fbc20eff210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(series, y=None, y_pred=None, x_label=\"$t$\", y_label=\"$x(t)$\", legend=True):\n",
    "    plt.plot(series, \".-\")\n",
    "    if y is not None:\n",
    "        plt.plot(n_steps, y, \"bo\", label=\"Target\")\n",
    "    if y_pred is not None:\n",
    "        plt.plot(n_steps, y_pred, \"rx\", markersize=10, label=\"Prediction\")\n",
    "    plt.grid(True)\n",
    "    if x_label:\n",
    "        plt.xlabel(x_label, fontsize=16)\n",
    "    if y_label:\n",
    "        plt.ylabel(y_label, fontsize=16, rotation=0)\n",
    "    plt.hlines(0, 0, 100, linewidth=1)\n",
    "    plt.axis([0, n_steps + 1, -1, 1])\n",
    "    if legend and (y or y_pred):\n",
    "        plt.legend(fontsize=14, loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfaeed65-f9d4-42d4-b4e5-d8469e8d7a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_multiple_forecasts(X, Y, Y_pred):\n",
    "    n_steps = X.shape[1]\n",
    "    ahead = Y.shape[1]\n",
    "    plot_series(X[0, :, 0])\n",
    "    plt.plot(np.arange(n_steps, n_steps + ahead), Y[0, :, 0], \"bo-\", label=\"Actual\")\n",
    "    plt.plot(np.arange(n_steps, n_steps + ahead), Y_pred[0, :, 0], \"rx-\", label=\"Forecast\", markersize=10)\n",
    "    plt.axis([0, n_steps + ahead, -1, 1])\n",
    "    plt.legend(fontsize=14)\n",
    "\n",
    "plot_multiple_forecasts(X_new, Y_new, Y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dce5dfcd-0dff-423c-aea5-989c685011af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 7ms/step - loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.002723966259509325"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0590565-2e31-4225-9f1a-f78aed0e95dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8239b0fd-7a6a-4415-89c8-dbb2394a807c",
   "metadata": {},
   "source": [
    "### Building a Sequence to Vector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53125a02-fdc0-4366-9815-3d58533ee108",
   "metadata": {},
   "source": [
    "The second option is to train an RNN to predict all 10 next values at once. We can still use a sequence-to-vector model, but it will output 10 values instead of 1. However, we first need to change the targets to be vectors containing the next 10 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae2fdf91-34dc-4fd2-841c-3bfbcbc279b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 60, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = generate_time_series(10000, n_steps + 10)\n",
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c655d7-9810-45a1-8702-954e1ea830ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19cdc68f-427a-483d-8041-afbef8858294",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = series[:7000, :n_steps], series[:7000, -10:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ba6aa-4dcd-4c01-916d-ab95c2c19e18",
   "metadata": {},
   "source": [
    "#### Explanation of above code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934b962-f228-423b-9b4b-4302d1637af9",
   "metadata": {},
   "source": [
    "For X_train we use normal slicing and get the first 7000 timesteps list, and then for each timestep list we only select the first 50 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5f3ef86-cf7e-4f30-a730-00f363f56f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3410013"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series[3,4,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5884f599-1dbe-4d64-8348-ef3b8a2cc647",
   "metadata": {},
   "source": [
    "For y_train what we do can be seen as this series[3,4,0], so if you see what we're doing is selecting the 0th term from the series[3,4] array, and basically reducing the dimensionality of the array from 3 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f3d39a8-570d-4559-85d9-2490eae7e00e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 50, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb90df2e-3982-4855-9420-6e366c6251ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ed48249-4e47-4a9d-8221-bbd4deebb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, Y_valid = series[7000:9000, :n_steps], series[7000:9000, -10:, 0]\n",
    "X_test, Y_test = series[9000:, :n_steps], series[9000:, -10:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff48437-7f8f-440a-b1b0-b433a597b133",
   "metadata": {},
   "source": [
    "### Building the Sequence to Vector model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "774235f6-0145-44a9-9e09-36099f413b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    " keras.layers.SimpleRNN(20),\n",
    " keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b94ca7e5-5aec-49fc-ab8e-d3546fcc9df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 7s 23ms/step - loss: 0.0619 - val_loss: 0.0346\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0271 - val_loss: 0.0212\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0188 - val_loss: 0.0160\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0146 - val_loss: 0.0130\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0131 - val_loss: 0.0136\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0119 - val_loss: 0.0133\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 6s 30ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 6s 28ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 6s 29ms/step - loss: 0.0102 - val_loss: 0.0093\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0097 - val_loss: 0.0094\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0091 - val_loss: 0.0085\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history = model.fit(X_train, Y_train, epochs=20,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1fcfeb1b-727d-4691-8fe2-31a74c4b537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 446ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.682712  , -0.56280404, -0.4062042 , -0.18403411,  0.02780987,\n",
       "         0.201294  ,  0.34443343,  0.464635  ,  0.5566441 ,  0.5249793 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_new)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12271a80-8f19-4db0-aea3-a5c05495f3a0",
   "metadata": {},
   "source": [
    "This model works nicely: the MSE for the next 10 time steps is about 0.0097. That’s much better than the linear model. But we can still do better: indeed, instead of training the model to forecast the next 10 values only at the very last time step, we can train it to forecast the next 10 values at each and every time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814abd61-1fd8-4f49-9567-4b2425122181",
   "metadata": {},
   "source": [
    "In other words, we can turn this sequence-to-vector RNN into a sequence-to-sequence RNN. The advantage of this technique is that the loss will contain a term for the output of the RNN at each and every time step, not just the output at the last time step, what this means is that the loss will have more terms for the RNN's output. This means there will be many more error gradients flowing through the model; they will also flow from the output of each time step. This will both stabilize and speed up training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15525096-d73b-48c3-9b39-398e32f5d0b1",
   "metadata": {},
   "source": [
    "### Building a Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda22e9-19af-40f4-911a-d428cbd64100",
   "metadata": {},
   "source": [
    "#### Creating the Targets for the Sequence to Sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70641d92-d314-47d8-892e-249e8c81075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.empty((10000, n_steps, 10)) # each target is a sequence of 10D vectors\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fc68248-99ef-43ca-b783-ec30c2af0605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,5,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c319e817-6d02-4ae7-9146-4dd9cf46ea45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "110b6626-1216-4055-b337-e7e1dcec75fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 60, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b64887a0-f998-4ea3-adfa-868a50335a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47407362],\n",
       "       [0.55489206]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series[2,3:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f057883-225f-4b48-8bf1-fe9ce7ccaf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47407362, 0.55489206], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series[2,3:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb3be412-23b3-4d97-93e6-4d7f0abb3765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 50)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series[:, 2:52, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80c3aec6-887f-49bc-b906-d704c27a0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step_ahead in range(1, 10 + 1):\n",
    "    Y[:, :, step_ahead - 1] = series[:, step_ahead:step_ahead + n_steps, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "324d04c9-ba88-435d-9b28-89077b2a33f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y[:7000]\n",
    "Y_valid = Y[7000:9000]\n",
    "Y_test = Y[9000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14dab2-870a-4940-bd07-9b54681fdb7d",
   "metadata": {},
   "source": [
    "### Important!! read below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d640ee-1ae2-4f28-aca7-f898f8495bb3",
   "metadata": {},
   "source": [
    "How Y[:, :, step_ahead - 1] works is that you start with the first column for all the 50 rows in the 1000 timestep list, that means that all the 50 row values for the first column get the data at once. And they get the data from series, where it follows the logic that you get values from 1 to 51 for the 0th timestep and this 0th is of Y , and then 2 to 52 for the 1st timestep and this 1st is of Y and so on.  You can verify using example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b46c368f-a3f0-46a3-a64a-8960f84e090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1033389 , -0.07078035, -0.31519347, -0.44316781, -0.56059605,\n",
       "       -0.5022195 , -0.41308492, -0.32441959, -0.3470166 , -0.2889764 ,\n",
       "       -0.33363661, -0.47243151, -0.51208895, -0.48120731, -0.32930911,\n",
       "       -0.16255446,  0.03197737,  0.23216781,  0.37547612,  0.43706536,\n",
       "        0.46103221,  0.4089984 ,  0.28193858,  0.24898152,  0.32530156,\n",
       "        0.44128111,  0.4607172 ,  0.50861371,  0.56319672,  0.4410986 ,\n",
       "        0.24593072,  0.08810017, -0.12310109, -0.35903275, -0.38819128,\n",
       "       -0.41862857, -0.34305269, -0.28082377, -0.23064181, -0.33991426,\n",
       "       -0.38766631, -0.52408928, -0.58493125, -0.62353468, -0.49672887,\n",
       "       -0.31832057, -0.1654391 ,  0.08291646,  0.19499661,  0.25814912])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bb977bb-4435-481e-9b2d-41566ec8c9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1033389 ],\n",
       "       [-0.07078035],\n",
       "       [-0.31519347],\n",
       "       [-0.4431678 ],\n",
       "       [-0.56059605],\n",
       "       [-0.5022195 ],\n",
       "       [-0.41308492],\n",
       "       [-0.3244196 ],\n",
       "       [-0.3470166 ],\n",
       "       [-0.2889764 ],\n",
       "       [-0.3336366 ],\n",
       "       [-0.4724315 ],\n",
       "       [-0.51208895],\n",
       "       [-0.4812073 ],\n",
       "       [-0.3293091 ],\n",
       "       [-0.16255446],\n",
       "       [ 0.03197737],\n",
       "       [ 0.23216781],\n",
       "       [ 0.37547612],\n",
       "       [ 0.43706536],\n",
       "       [ 0.4610322 ],\n",
       "       [ 0.4089984 ],\n",
       "       [ 0.28193858],\n",
       "       [ 0.24898152],\n",
       "       [ 0.32530156],\n",
       "       [ 0.4412811 ],\n",
       "       [ 0.4607172 ],\n",
       "       [ 0.5086137 ],\n",
       "       [ 0.5631967 ],\n",
       "       [ 0.4410986 ],\n",
       "       [ 0.24593072],\n",
       "       [ 0.08810017],\n",
       "       [-0.12310109],\n",
       "       [-0.35903275],\n",
       "       [-0.38819128],\n",
       "       [-0.41862857],\n",
       "       [-0.3430527 ],\n",
       "       [-0.28082377],\n",
       "       [-0.23064181],\n",
       "       [-0.33991426],\n",
       "       [-0.3876663 ],\n",
       "       [-0.5240893 ],\n",
       "       [-0.58493125],\n",
       "       [-0.6235347 ],\n",
       "       [-0.49672887],\n",
       "       [-0.31832057],\n",
       "       [-0.1654391 ],\n",
       "       [ 0.08291646],\n",
       "       [ 0.19499661],\n",
       "       [ 0.25814912]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series[0,1:51]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0e0e4-8e8c-429a-8821-7b993e52dec2",
   "metadata": {},
   "source": [
    "### Note Sequence-to-Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b5fd18-83e0-486e-afe2-cb2e9ede7ade",
   "metadata": {},
   "source": [
    "It may be surprising that the targets will contain values that appear in the inputs (there is a lot of overlap between X_train and Y_train). Isn’t that cheating? Fortunately, not at all: at each time step, the model only knows about past time steps, so it cannot look ahead. It is said to be a causal model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27689191-ff59-4811-a9ab-9b2ba0916d91",
   "metadata": {},
   "source": [
    "To turn the model into a sequence-to-sequence model, we must set return_sequences=True in all recurrent layers (even the last one), and we must apply the output Dense layer at every time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01ce2e-a90c-47b0-97dc-51ad99393986",
   "metadata": {},
   "source": [
    "Keras offers a TimeDistributed layer for this very purpose: it wraps any layer (e.g., a Dense layer) and applies it at every time step of its input sequence. It does this efficiently, by reshaping the inputs so that each time step is treated as a separate instance (i.e., it reshapes the inputs from [batch size, time steps, input dimensions] to [batch size × time steps, input dimensions]; in this example, the number of input dimensions is 20 because the previous SimpleRNN layer has 20 units)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e95d1e6-4158-4217-8b8b-82db676e1b38",
   "metadata": {},
   "source": [
    "Then it runs the Dense layer, and finally it reshapes the outputs back to sequences (i.e., it reshapes the outputs from [batch size × time steps, output dimensions] to [batch size, time steps, output dimensions]; in this example the number of output dimensions is 10, since the Dense layer has 10 units). Here is the updated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f455ccb-5730-44b6-8246-6aaff7c0eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    " keras.layers.SimpleRNN(20, return_sequences=True),\n",
    " keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f9fa6-be5a-4d3e-acb5-21145fdd1277",
   "metadata": {},
   "source": [
    "The Dense layer actually supports sequences as inputs (and even higher-dimensional inputs): it handles them just like TimeDistributed(Dense(…)), meaning it is applied to the last input dimension only (independently across all time steps). Thus, we could replace the last layer with just Dense(10). For the sake of clarity, however, we will keep using TimeDistributed(Dense(10)) because it makes it clear that the Dense layer is applied independently at each time step and that the model will output a sequence, not just a single vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdd63b-8e51-417d-a5ed-31e4a4e29781",
   "metadata": {},
   "source": [
    "All outputs are needed during training, but only the output at the last time step is useful for predictions and for evaluation. So although we will rely on the MSE over all the outputs for training, we will use a custom metric for evaluation, to only compute the MSE over the output at the last time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96bebd6c-c4a1-4b1d-9f63-164244f6bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "017f91ca-6afc-4769-b00c-d4108129b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b9569cd-56c0-44af-910e-1e51e0b50b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[last_time_step_mse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "23ed1d69-861f-43d9-8629-f529c5c16b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "219/219 [==============================] - 8s 26ms/step - loss: 0.0499 - last_time_step_mse: 0.0390 - val_loss: 0.0390 - val_last_time_step_mse: 0.0255\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0358 - last_time_step_mse: 0.0230 - val_loss: 0.0330 - val_last_time_step_mse: 0.0201\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 6s 27ms/step - loss: 0.0312 - last_time_step_mse: 0.0188 - val_loss: 0.0307 - val_last_time_step_mse: 0.0183\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 6s 26ms/step - loss: 0.0276 - last_time_step_mse: 0.0158 - val_loss: 0.0266 - val_last_time_step_mse: 0.0146\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0262 - last_time_step_mse: 0.0148 - val_loss: 0.0260 - val_last_time_step_mse: 0.0144\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0251 - last_time_step_mse: 0.0139 - val_loss: 0.0256 - val_last_time_step_mse: 0.0143\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0240 - last_time_step_mse: 0.0124 - val_loss: 0.0243 - val_last_time_step_mse: 0.0132\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0215 - last_time_step_mse: 0.0097 - val_loss: 0.0197 - val_last_time_step_mse: 0.0066\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0202 - last_time_step_mse: 0.0082 - val_loss: 0.0210 - val_last_time_step_mse: 0.0088\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 6s 25ms/step - loss: 0.0197 - last_time_step_mse: 0.0078 - val_loss: 0.0204 - val_last_time_step_mse: 0.0076\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0197 - last_time_step_mse: 0.0078 - val_loss: 0.0192 - val_last_time_step_mse: 0.0068\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0189 - last_time_step_mse: 0.0070 - val_loss: 0.0199 - val_last_time_step_mse: 0.0076\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0190 - last_time_step_mse: 0.0071 - val_loss: 0.0183 - val_last_time_step_mse: 0.0060\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 4s 21ms/step - loss: 0.0191 - last_time_step_mse: 0.0074 - val_loss: 0.0211 - val_last_time_step_mse: 0.0108\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0187 - last_time_step_mse: 0.0070 - val_loss: 0.0197 - val_last_time_step_mse: 0.0073\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0185 - last_time_step_mse: 0.0067 - val_loss: 0.0182 - val_last_time_step_mse: 0.0057\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0185 - last_time_step_mse: 0.0068 - val_loss: 0.0190 - val_last_time_step_mse: 0.0074\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0186 - last_time_step_mse: 0.0068 - val_loss: 0.0194 - val_last_time_step_mse: 0.0069\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0182 - last_time_step_mse: 0.0064 - val_loss: 0.0179 - val_last_time_step_mse: 0.0057\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0186 - last_time_step_mse: 0.0070 - val_loss: 0.0190 - val_last_time_step_mse: 0.0071\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=20,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136651c-1b8c-44ec-ac62-5fb86421f532",
   "metadata": {},
   "source": [
    "#### We get a validation MSE of about 0.006 for the last_time_step_mse, which is 25% better than the previous model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf541df7-346c-4cf5-859b-a560499348b2",
   "metadata": {},
   "source": [
    "### Note about forecasting time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e356a3a4-beca-4ff2-a012-f368f145c10e",
   "metadata": {},
   "source": [
    "When forecasting time series, it is often useful to have some error bars along with your predictions. For this, an efficient technique is MC Dropout: add an MC Dropout layer\r\n",
    "within each memory cell, dropping part of the inputs and hidden states. After training, to forecast a new time series, use the model many times and compute the mean and standard deviation of the predictions at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6793d1b-08f3-4b50-b5a3-866c0f0edd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37881a0e-f6d8-49c4-8d7a-59ca3b1d5ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "392b7d2c-20f3-463c-a3e0-94243cc2422c",
   "metadata": {},
   "source": [
    "## Handling Long Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5f141-5245-4ef5-bb65-4ada1039d6d3",
   "metadata": {},
   "source": [
    "To train an RNN on long sequences, we must run it over many time steps, making the unrolled RNN a very deep network. Just like any deep neural network it may suffer from the unstable gradients problem it may take forever to train, or training may be unstable. Moreover, when an RNN processes a long sequence, it will gradually forget the first inputs in the sequence. Let’s look at both these problems, starting with the unstable gradients problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f03abc-080e-4658-9ed1-11f557e44ecf",
   "metadata": {},
   "source": [
    "## Fighting the Unstable Gradients Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d0c59-701b-4b36-a8b6-e907e50c83f8",
   "metadata": {},
   "source": [
    "Many of the tricks we used in deep nets to alleviate the unstable gradients problem can also be used for RNNs: good parameter initialization, faster optimizers, dropout, and so on. However, nonsaturating activation functions (e.g., ReLU) may not help as much here; in fact, they may actually lead the RNN to be even more unstable during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d5c49-90b7-42fa-9757-be2560352098",
   "metadata": {},
   "source": [
    "### Gradient Descent problems with ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a3c83-1aaf-4da5-b854-f365515f3a3d",
   "metadata": {},
   "source": [
    "1) Suppose Gradient Descent updates the weights in a way that increases the outputs slightly at the first time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5ae66-8043-43eb-ad42-a91135156c38",
   "metadata": {},
   "source": [
    "2) Because the same weights are used at every time step, the outputs at the second time step may also be slightly increased, and those at the third, and so on until the outputs explode—and a nonsaturating activation function does not prevent that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4449a80-0416-4c3d-8a65-1e4b2ffe863a",
   "metadata": {},
   "source": [
    "3) You can reduce this risk by using a smaller learning rate, but you can also simply use a saturating activation function like the hyperbolic tangent (this explains why it is the default)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5394c7a-6ebe-44c1-986d-25f46837ddcc",
   "metadata": {},
   "source": [
    "4) In much the same way, the gradients themselves can explode. If you notice that training is unstable, you may want to monitor the size of the gradients (e.g., using TensorBoard) and perhaps use Gradient Clipping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26508cc7-a6de-41eb-850e-ae644142a246",
   "metadata": {},
   "source": [
    "### Batch Normalization with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ccbfd0-5254-426c-89a3-d268ea28eb23",
   "metadata": {},
   "source": [
    "1) Batch Normalization cannot be used as efficiently with RNNs as with deep feedforward nets. In fact, you cannot use it between time steps, only between recurrent layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07df280-6da0-404b-971a-f36ff6e4d723",
   "metadata": {},
   "source": [
    "2) To be more precise, it is technically possible to add a BN layer to a memory cell (as we will see shortly) so that it will be applied at each time step (both on the inputs for that time step and on the hidden state from the previous step). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db58191-2aac-4f0f-af5d-3aba41b8b77f",
   "metadata": {},
   "source": [
    "3) However, the same BN layer will be used at each time step, with the same parameters, regardless of the actual scale and offset of the inputs and hidden state. In practice, this does not yield good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d4b9b2-e526-4ca4-92a6-4fa7b5ca9d8b",
   "metadata": {},
   "source": [
    "### Layer Normalization with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc775e3-f745-4051-b022-c447c53c483f",
   "metadata": {},
   "source": [
    "Another form of normalization often works better with RNNs: Layer Normalization. This idea was introduced by Jimmy Lei Ba et al. It is very similar to Batch Normalization, but instead of normalizing across the batch dimension, it normalizes across the features dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0aed78-f148-46de-9af0-334a104d985f",
   "metadata": {},
   "source": [
    "One advantage is that it can compute the required statistics on the fly, at each time step, independently for each instance. This also means that it behaves the same way during training and testing (as opposed to BN), and it does not need to use exponential moving averages to estimate the feature statistics across all instances in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69227141-6be5-4948-a597-6f8489786017",
   "metadata": {},
   "source": [
    "Like BN, Layer Normalization learns a scale and an offset parameter for each input. In an RNN, it is typically used right after the linear combination of the inputs and the hidden states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85120a5-adaf-4db8-88ea-38956ed00c6c",
   "metadata": {},
   "source": [
    "### Implementing Layer Normalization in RNN using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e67532-6ba8-40e4-be79-6b4cc779fa7c",
   "metadata": {},
   "source": [
    "Let’s use tf.keras to implement Layer Normalization within a simple memory cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a4362-ef6b-473a-8e4d-c2fa3098bdd5",
   "metadata": {},
   "source": [
    "1) For this, we need to define a custom memory cell. It is just like a regular layer, except its call() method takes two arguments: the inputs at the current time step and the hidden states from the previous time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87800b37-6baa-4e73-a608-fcba0f349fbf",
   "metadata": {},
   "source": [
    "2) Note that the states argument is a list containing one or more tensors. In the case of a simple RNN cell it contains a single tensor equal to the outputs of the previous time step, but other cells may have multiple state tensors (e.g., an LSTMCell has a long-term state and a short-term state, as we will see shortly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01648db-1eed-4d26-ac1a-abe78a1d1b48",
   "metadata": {},
   "source": [
    "3) A cell must also have a state_size attribute and an output_size attribute. In a simple RNN, both are simply equal to the number of units. The following code implements a custom memory cell which will behave like a SimpleRNNCell, except it will also apply Layer Normalization at each time step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d43c47d1-4f9f-4407-b497-f4fb7a3c6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7043d070-088e-49eb-8846-bfcbfcb64de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNNCell(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=\"tanh\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.state_size = units\n",
    "        self.output_size = units\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "                                                          activation=None)\n",
    "        self.layer_norm = LayerNormalization()\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if inputs is not None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            dtype = inputs.dtype\n",
    "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805255ef-a4c4-4b79-afa6-76315bd16629",
   "metadata": {},
   "source": [
    "### Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bea231-b408-47eb-8a56-68b4119b9442",
   "metadata": {},
   "source": [
    "#### Init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad42e2-539e-4346-86b4-eeeb55118eed",
   "metadata": {},
   "source": [
    "1) Our LNSimpleRNNCell class inherits from the keras.layers.Layer class, just like any custom layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8d1b5-21da-4fac-9e52-b321f4c0c143",
   "metadata": {},
   "source": [
    "2) The constructor takes the number of units and the desired activation function, and it sets the state_size and output_size attributes, then creates a SimpleRNNCell with no activation function (because we want to perform Layer Normalization after the linear operation but before the activation function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378ac8e-e54e-44d0-8a72-7828b42ac9b7",
   "metadata": {},
   "source": [
    "3) Then the constructor creates the LayerNormalization layer, and finally it fetches the desired activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e32a4-ef1d-454b-b401-da747fdbd2cf",
   "metadata": {},
   "source": [
    "#### Call()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673ee3c3-237e-454b-839e-fb20cfe1ed85",
   "metadata": {},
   "source": [
    "1) The call() method starts by applying the simple RNN cell, which computes a linear combination of the current inputs and the previous hidden states, and it returns the result twice (indeed, in a SimpleRNNCell, the outputs are just equal to the hidden states: in other words, new_states[0] is equal to outputs, so we can safely ignore new_states in the rest of the call() method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20ef15-b6ee-4339-a718-277968ef0fcd",
   "metadata": {},
   "source": [
    "2) Next, the call() method applies Layer Normalization, followed by the activation function. Finally, it returns the outputs twice (once as the outputs, and once as the new hidden states). To use this custom cell, all we need to do is create a keras.layers.RNN layer, passing it a cell instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f387a-6979-48db-96f9-b88157e13d5d",
   "metadata": {},
   "source": [
    "### Creating the model for Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "214dea75-5fde-4428-83d1-0eacd861d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\layers\\normalization\\layer_normalization.py:328: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True,\n",
    "                     input_shape=[None, 1]),\n",
    "    keras.layers.RNN(LNSimpleRNNCell(20), return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f77f75ce-dbcf-491e-b30f-1c0cdaa67de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cd696dc5-1abe-49f2-a033-2a8aecf00e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 18s 64ms/step - loss: 0.1421 - last_time_step_mse: 0.1238 - val_loss: 0.0622 - val_last_time_step_mse: 0.0465\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 15s 70ms/step - loss: 0.0549 - last_time_step_mse: 0.0411 - val_loss: 0.0503 - val_last_time_step_mse: 0.0359\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 14s 63ms/step - loss: 0.0462 - last_time_step_mse: 0.0325 - val_loss: 0.0450 - val_last_time_step_mse: 0.0295\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.0408 - last_time_step_mse: 0.0265 - val_loss: 0.0384 - val_last_time_step_mse: 0.0232\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 14s 64ms/step - loss: 0.0359 - last_time_step_mse: 0.0203 - val_loss: 0.0371 - val_last_time_step_mse: 0.0199\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 14s 66ms/step - loss: 0.0335 - last_time_step_mse: 0.0168 - val_loss: 0.0331 - val_last_time_step_mse: 0.0169\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 14s 66ms/step - loss: 0.0312 - last_time_step_mse: 0.0149 - val_loss: 0.0313 - val_last_time_step_mse: 0.0152\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.0300 - last_time_step_mse: 0.0141 - val_loss: 0.0308 - val_last_time_step_mse: 0.0146\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 14s 64ms/step - loss: 0.0292 - last_time_step_mse: 0.0133 - val_loss: 0.0291 - val_last_time_step_mse: 0.0129\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 14s 65ms/step - loss: 0.0286 - last_time_step_mse: 0.0130 - val_loss: 0.0291 - val_last_time_step_mse: 0.0128\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 14s 63ms/step - loss: 0.0280 - last_time_step_mse: 0.0124 - val_loss: 0.0283 - val_last_time_step_mse: 0.0120\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 14s 63ms/step - loss: 0.0278 - last_time_step_mse: 0.0126 - val_loss: 0.0280 - val_last_time_step_mse: 0.0122\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 16s 75ms/step - loss: 0.0272 - last_time_step_mse: 0.0120 - val_loss: 0.0274 - val_last_time_step_mse: 0.0116\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.0385 - last_time_step_mse: 0.0261 - val_loss: 0.0348 - val_last_time_step_mse: 0.0200\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 16s 74ms/step - loss: 0.0307 - last_time_step_mse: 0.0160 - val_loss: 0.0293 - val_last_time_step_mse: 0.0131\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 15s 68ms/step - loss: 0.0283 - last_time_step_mse: 0.0130 - val_loss: 0.0284 - val_last_time_step_mse: 0.0124\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.0275 - last_time_step_mse: 0.0123 - val_loss: 0.0280 - val_last_time_step_mse: 0.0124\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 15s 69ms/step - loss: 0.0270 - last_time_step_mse: 0.0120 - val_loss: 0.0274 - val_last_time_step_mse: 0.0119\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 15s 70ms/step - loss: 0.0266 - last_time_step_mse: 0.0119 - val_loss: 0.0268 - val_last_time_step_mse: 0.0116\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 15s 70ms/step - loss: 0.0270 - last_time_step_mse: 0.0125 - val_loss: 0.0270 - val_last_time_step_mse: 0.0115\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=20,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51173c68-fd67-4851-ac1c-12cd6a8c8da1",
   "metadata": {},
   "source": [
    "Similarly, you could create a custom cell to apply dropout between each time step. But there’s a simpler way: all recurrent layers (except for keras.layers.RNN) and all cells provided by Keras have a dropout hyperparameter and a recurrent_dropout hyperparameter: the former defines the dropout rate to apply to the inputs (at each time step), and the latter defines the dropout rate for the hidden states (also at each time step). No need to create a custom cell to apply dropout at each time step in an RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa8fc39-e7c4-4db4-93bb-80dbe31afb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "185ca743-fd25-4434-a44b-4d53e7328b15",
   "metadata": {},
   "source": [
    "## Tackling the Short-Term Memory Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff49e7f-16b3-47d5-b794-11784d235cea",
   "metadata": {},
   "source": [
    "Due to the transformations that the data goes through when traversing an RNN, some information is lost at each time step. After a while, the RNN’s state contains virtually no trace of the first inputs. This can be a showstopper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e70a0-9422-46d9-b0ec-a5913400450f",
   "metadata": {},
   "source": [
    "To tackle this problem, various types of cells with long-term memory have been introduced. They have proven so successful that the basic cells are not used much anymore. Let’s first look at the most popular of these long-term memory cells: the LSTM cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e425f90-1352-4e64-8cb5-8a4aa743ffee",
   "metadata": {},
   "source": [
    "## LSTM cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a02a3d-da52-4221-86b9-e3bcbbba6edb",
   "metadata": {},
   "source": [
    "If you consider the LSTM cell as a black box, it can be used very much like a basic cell, except it will perform much better; training will converge faster, and it will detect long-term dependencies in the data. In Keras, you can simply use the LSTM layer instead of the SimpleRNN layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4095527-88c7-43d6-b0eb-b445f3006a59",
   "metadata": {},
   "source": [
    "#### Method 1 for creating an LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bfaf0bc-12bb-4f1c-9750-f8bb45efd44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    " keras.layers.LSTM(20, return_sequences=True),\n",
    " keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a152b0b2-2cc0-4365-9a58-e003f4887166",
   "metadata": {},
   "source": [
    "#### Method 2 of creating an LSTM layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711bc33-d4e9-4745-bb4f-ec2a0107c7ce",
   "metadata": {},
   "source": [
    "Alternatively, you could use the general-purpose keras.layers.RNN layer, giving it an LSTMCell as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2067ca2-bd0a-4037-8c4c-199a2d77fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    " keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True,\n",
    " input_shape=[None, 1]),\n",
    " keras.layers.RNN(keras.layers.LSTMCell(20), return_sequences=True),\n",
    " keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cd7e410-6020-477d-a7da-339d6f9ecee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 11s 40ms/step - loss: 0.0793 - last_time_step_mse: 0.0661 - val_loss: 0.0555 - val_last_time_step_mse: 0.0356\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0483 - last_time_step_mse: 0.0281 - val_loss: 0.0439 - val_last_time_step_mse: 0.0233\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.0401 - last_time_step_mse: 0.0193 - val_loss: 0.0378 - val_last_time_step_mse: 0.0168\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0357 - last_time_step_mse: 0.0154 - val_loss: 0.0348 - val_last_time_step_mse: 0.0151\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0333 - last_time_step_mse: 0.0142 - val_loss: 0.0333 - val_last_time_step_mse: 0.0152\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0317 - last_time_step_mse: 0.0132 - val_loss: 0.0314 - val_last_time_step_mse: 0.0132\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0304 - last_time_step_mse: 0.0124 - val_loss: 0.0304 - val_last_time_step_mse: 0.0125\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0294 - last_time_step_mse: 0.0120 - val_loss: 0.0298 - val_last_time_step_mse: 0.0125\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0286 - last_time_step_mse: 0.0117 - val_loss: 0.0287 - val_last_time_step_mse: 0.0117\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0280 - last_time_step_mse: 0.0114 - val_loss: 0.0281 - val_last_time_step_mse: 0.0115\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.0273 - last_time_step_mse: 0.0111 - val_loss: 0.0277 - val_last_time_step_mse: 0.0116\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 8s 34ms/step - loss: 0.0267 - last_time_step_mse: 0.0107 - val_loss: 0.0267 - val_last_time_step_mse: 0.0102\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0262 - last_time_step_mse: 0.0104 - val_loss: 0.0270 - val_last_time_step_mse: 0.0111\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 7s 30ms/step - loss: 0.0259 - last_time_step_mse: 0.0103 - val_loss: 0.0265 - val_last_time_step_mse: 0.0099\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 7s 33ms/step - loss: 0.0254 - last_time_step_mse: 0.0100 - val_loss: 0.0259 - val_last_time_step_mse: 0.0100\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 7s 32ms/step - loss: 0.0250 - last_time_step_mse: 0.0096 - val_loss: 0.0252 - val_last_time_step_mse: 0.0094\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0246 - last_time_step_mse: 0.0093 - val_loss: 0.0249 - val_last_time_step_mse: 0.0093\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0243 - last_time_step_mse: 0.0092 - val_loss: 0.0246 - val_last_time_step_mse: 0.0086\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 9s 43ms/step - loss: 0.0240 - last_time_step_mse: 0.0090 - val_loss: 0.0243 - val_last_time_step_mse: 0.0085\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0237 - last_time_step_mse: 0.0088 - val_loss: 0.0239 - val_last_time_step_mse: 0.0084\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ca751da-89b8-4011-8189-553831878850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 11ms/step - loss: 0.0239 - last_time_step_mse: 0.0084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02389674261212349, 0.008444379083812237]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51467440-2a3d-4e60-925b-2399cf8a93c4",
   "metadata": {},
   "source": [
    "### Working of LSTM cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9c9c9-a77d-4579-94c4-8c542be16c4d",
   "metadata": {},
   "source": [
    "LSTM cell looks exactly like a regular cell, except that its state is split into two vectors: h(t) and c(t) (“c” stands for “cell”). You can think of h(t) as the short-term state and c(t) as the long-term state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0222749-b98c-4b58-b361-51e29e79a61e",
   "metadata": {},
   "source": [
    "#### See figure 15-9 from the book while reading the below explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1b215-40aa-4139-8e92-92a0e02525f3",
   "metadata": {},
   "source": [
    "### The Long term state C(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da546f82-7ba9-4867-82cc-86f9b4959176",
   "metadata": {},
   "source": [
    "The key idea is that the network can learn what to store in the long-term state, what to throw away, and what to read from it. As the long-term state c(t–1) traverses the network from left to right, it first goes through a forget gate, dropping some memories, and then it adds some new memories via the addition operation (which adds the memories that were selected by an input gate). After that, the result c(t) is sent straight out, without any further transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b40ba2-ac30-43a7-8647-961968d01898",
   "metadata": {},
   "source": [
    "### The Short term state h(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e690ee1-ae10-4570-b7fc-e6aeb6f6494f",
   "metadata": {},
   "source": [
    "After the addition operation, the long-term state is copied and passed through the tanh function, and then the result is filtered by the output gate. This produces the short-term state h(t) (which is equal to the cell’s output for this time step, y(t) )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395e682-701e-4555-bfe1-e37d7c05bfdb",
   "metadata": {},
   "source": [
    "### Working of the Gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c7d99e-5aea-42b7-9c5d-11619f92b1f6",
   "metadata": {},
   "source": [
    "Now let’s look at where new memories come from and how the gates work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec801d-9a63-4b6e-a450-9d3affbf53ee",
   "metadata": {},
   "source": [
    "First, the current input vector x(t) and the previous short-term state h(t–1) are fed to four different fully connected layers(FC in the image). They all serve a different purpose:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff151cd-092d-4613-bc0f-0a0923dccc9a",
   "metadata": {},
   "source": [
    "#### Main FC Layer outputting g(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03843a8a-8037-48b9-877c-7ed865ec7442",
   "metadata": {},
   "source": [
    "1) The main layer is the one that outputs g(t). It has the usual role of analyzing the current inputs x(t) and the previous (short-term) state h(t–1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970cb6df-019a-4e76-8d91-a31f364872a0",
   "metadata": {},
   "source": [
    "2) In a basic cell, there is nothing other than this layer, and its output goes straight out to y(t) and h(t). In contrast, in an LSTM cell this layer’s output does not go straight out, but instead its most important parts are stored in the long-term state (and the rest is dropped)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5baf9e0-a211-4657-b389-91ced5b2b413",
   "metadata": {},
   "source": [
    "#### Gate Controller layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb676e3-1042-4317-848c-65b482acadda",
   "metadata": {},
   "source": [
    "The three other layers are gate controllers. Since they use the logistic activation function, their outputs range from 0 to 1. As you can see, their outputs are fed to element-wise multiplication operations, so if they output 0s they close the gate, and if they output 1s they open it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69d664-e6ce-48ed-8834-320a0082a21b",
   "metadata": {},
   "source": [
    "##### The forget gate f(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23faefb0-2070-41c8-b81e-a9f8fdbf02fc",
   "metadata": {},
   "source": [
    "The forget gate (controlled by f(t)) controls which parts of the long-term state should be erased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6770b1b-9ab3-45ed-ae83-9f28ddfa70b9",
   "metadata": {},
   "source": [
    "##### The input gate i(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef722b6-c27a-4b8c-a185-df0b6172c58c",
   "metadata": {},
   "source": [
    "The input gate (controlled by i(t)) controls which parts of g(t)should be added to the long-term state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf7828-6717-463d-af53-5080ed116b4d",
   "metadata": {},
   "source": [
    "##### The output gate o(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd49fcf-9673-4fc3-8472-16c5ed91dfc3",
   "metadata": {},
   "source": [
    "Finally, the output gate (controlled by o(t)) controls which parts of the longterm state should be read and output at this time step, both to h(t) and to y(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f188b5a-7169-474b-830e-f5957a0fbc59",
   "metadata": {},
   "source": [
    "### VVV IMP!!! See equation 15-3 from the book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed5bc6-502d-4b02-8f4b-33dafb4fcdf9",
   "metadata": {},
   "source": [
    "### Conclusion LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1521676-9d2e-471a-a6c6-0fc2fff7b06e",
   "metadata": {},
   "source": [
    "In short, an LSTM cell can learn to recognize an important input (that’s the role of the input gate), store it in the long-term state, preserve it for as long as it is needed (that’s the role of the forget gate), and extract it whenever it is needed. This explains why these cells have been amazingly successful at capturing long-term patterns in time series, long texts, audio recordings, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7b26e-9754-43ac-83a2-48fc75f7fa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35bebe11-2f6e-4563-a395-5f9065a7e52b",
   "metadata": {},
   "source": [
    "### Peephole connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9715ac1-f08d-4848-b88d-34fe1f0abfb1",
   "metadata": {},
   "source": [
    "In a regular LSTM cell, the gate controllers can look only at the input x(t) and the previous short-term state h(t–1). It may be a good idea to give them a bit more context by letting them peek at the long-term state as well. This idea was proposed by Felix Gersand Jürgen Schmidhuber in 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320eba5-83f3-48ce-9202-4d75be693feb",
   "metadata": {},
   "source": [
    "They proposed an LSTM variant with extra connections called peephole connections: the previous long-term state c(t–1) is added as an input to the controllers of the forget gate and the input gate, and the current longterm state c(t) is added as input to the controller of the output gate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46a55a-e747-4869-a646-8849ee7f7b09",
   "metadata": {},
   "source": [
    "This often improves performance, but not always, and there is no clear pattern for which tasks are better off with or without them: you will have to try it on your task and see if it helps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8dab5-c1d4-4016-b49f-f0d3d811b698",
   "metadata": {},
   "source": [
    "In Keras, the LSTM layer is based on the keras.layers.LSTMCell cell, which does not support peepholes. The experimental tf.keras.experimental.PeepholeLSTMCell does, however, so you can create a keras.layers.RNN layer and pass a PeepholeLSTM Cell to its constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabaac5-b02f-4976-84a0-704a41e77461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78ae74ad-1c83-4142-a593-b0de37ec6ecc",
   "metadata": {},
   "source": [
    "## GRU cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe991f0-c8b7-45eb-a31e-fa98486d6e35",
   "metadata": {},
   "source": [
    "The Gated Recurrent Unit (GRU) cell was proposed by Kyunghyun Cho et al."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec865cf-a230-4de0-9b36-01fa97fe15b1",
   "metadata": {},
   "source": [
    "The GRU cell is a simplified version of the LSTM cell, and it seems to perform just as well. These are the main simplifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7b35de61-a9df-4049-9e31-5b713dee0441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 11s 40ms/step - loss: 0.0751 - last_time_step_mse: 0.0677 - val_loss: 0.0541 - val_last_time_step_mse: 0.0424\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0487 - last_time_step_mse: 0.0386 - val_loss: 0.0468 - val_last_time_step_mse: 0.0369\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0437 - last_time_step_mse: 0.0332 - val_loss: 0.0423 - val_last_time_step_mse: 0.0307\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0398 - last_time_step_mse: 0.0288 - val_loss: 0.0384 - val_last_time_step_mse: 0.0267\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0363 - last_time_step_mse: 0.0252 - val_loss: 0.0358 - val_last_time_step_mse: 0.0234\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0338 - last_time_step_mse: 0.0219 - val_loss: 0.0334 - val_last_time_step_mse: 0.0207\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0317 - last_time_step_mse: 0.0190 - val_loss: 0.0312 - val_last_time_step_mse: 0.0174\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0297 - last_time_step_mse: 0.0162 - val_loss: 0.0302 - val_last_time_step_mse: 0.0163\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0283 - last_time_step_mse: 0.0144 - val_loss: 0.0282 - val_last_time_step_mse: 0.0139\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0274 - last_time_step_mse: 0.0134 - val_loss: 0.0275 - val_last_time_step_mse: 0.0127\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0267 - last_time_step_mse: 0.0127 - val_loss: 0.0268 - val_last_time_step_mse: 0.0121\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0261 - last_time_step_mse: 0.0120 - val_loss: 0.0265 - val_last_time_step_mse: 0.0121\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 7s 34ms/step - loss: 0.0259 - last_time_step_mse: 0.0119 - val_loss: 0.0262 - val_last_time_step_mse: 0.0121\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 8s 34ms/step - loss: 0.0255 - last_time_step_mse: 0.0116 - val_loss: 0.0259 - val_last_time_step_mse: 0.0119\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0252 - last_time_step_mse: 0.0115 - val_loss: 0.0254 - val_last_time_step_mse: 0.0111\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0248 - last_time_step_mse: 0.0111 - val_loss: 0.0255 - val_last_time_step_mse: 0.0116\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 8s 34ms/step - loss: 0.0247 - last_time_step_mse: 0.0111 - val_loss: 0.0248 - val_last_time_step_mse: 0.0107\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 8s 35ms/step - loss: 0.0244 - last_time_step_mse: 0.0107 - val_loss: 0.0249 - val_last_time_step_mse: 0.0112\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 8s 36ms/step - loss: 0.0241 - last_time_step_mse: 0.0105 - val_loss: 0.0247 - val_last_time_step_mse: 0.0109\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 8s 37ms/step - loss: 0.0239 - last_time_step_mse: 0.0104 - val_loss: 0.0242 - val_last_time_step_mse: 0.0103\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train, epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd7fc69e-8113-4d16-aaa3-9ad03bb1af17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 11ms/step - loss: 0.0242 - last_time_step_mse: 0.0103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024223146960139275, 0.010310187935829163]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7727dc-ae49-4333-87ef-dd48671468fb",
   "metadata": {},
   "source": [
    "#### See figure 15-10 from the book while reading the below explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b930a5-5647-4051-b6b9-fcd126f98fc2",
   "metadata": {},
   "source": [
    "1) Both state vectors are merged into a single vector h(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc2879-56be-41d1-811f-70621cf17e7e",
   "metadata": {},
   "source": [
    "2) A single gate controller z(t) controls both the forget gate and the input gate. If the gate controller outputs a 1, the forget gate is open (= 1) and the input gate is closed (1 – 1 = 0). If it outputs a 0, the opposite happens. In other words, whenever a memory must be stored, the location where it will be stored is erased first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645326e5-9a40-4a34-98dc-89e35b04359c",
   "metadata": {},
   "source": [
    "3) There is no output gate; the full state vector is output at every time step. However, there is a new gate controller r(t) that controls which part of the previous state will be shown to the main layer (g(t))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a929331-f1ce-49df-92a5-30f8800f6bb7",
   "metadata": {},
   "source": [
    "Keras provides a keras.layers.GRU layer (based on the keras.layers.GRUCell memory cell); using it is just a matter of replacing SimpleRNN or LSTM with GRU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d2a3d-1403-4aac-89e1-2a20c7b7620b",
   "metadata": {},
   "source": [
    "### VVV IMP!!! See equation 15-4 from the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab79a6e-4938-4a12-b77c-263b435062b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae8033f-029e-4bf5-a62e-7b91ad7e3f75",
   "metadata": {},
   "source": [
    "## Solving Long Sequences problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6b1e2-4122-4714-862f-5fdcec3668ce",
   "metadata": {},
   "source": [
    "### Using 1D convolutional layers to process sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2caba24-a755-468d-9eb1-214e54f17fb4",
   "metadata": {},
   "source": [
    "In CNNs, we saw that a 2D convolutional layer works by sliding several fairly small kernels (or filters) across an image, producing multiple 2D feature maps (one per kernel). Similarly, a 1D convolutional layer slides several kernels across a sequence, producing a 1D feature map per kernel. Each kernel will learn to detect a single very short sequential pattern (no longer than the kernel size)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98103bf9-47c1-46cd-b88a-3a9909f51bc2",
   "metadata": {},
   "source": [
    "If you use 10 kernels, then the layer’s output will be composed of 10 1-dimensional sequences (all of the same length), or equivalently you can view this output as a single 10-dimensional sequence. This means that you can build a neural network composed of a mix of recurrent layers and 1D convolutional layers (or even 1D pooling layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c00c21-b851-4b08-b70e-326ec0e8e6f9",
   "metadata": {},
   "source": [
    "If you use a 1D convolutional layer with a stride of 1 and \"same\" padding, then the output sequence will have the same length as the input sequence. But if you use \"valid\" padding or a stride greater than 1, then the output sequence will be shorter than the input sequence, so make sure you adjust the targets accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91201f41-1171-42a0-aa50-bcd63c3d68d2",
   "metadata": {},
   "source": [
    "### Implementing CNNs with GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7576b8d-52e1-4480-bd58-d5c5471e3150",
   "metadata": {},
   "source": [
    "The following model is the same as earlier, except it starts with a 1D convolutional layer that downsamples the input sequence by a factor of 2, using a stride of 2. The kernel size is larger than the stride, so all inputs will be used to compute the layer’s output, and therefore the model can learn to preserve the useful information, dropping only the unimportant details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4b863-5adb-4e95-8f15-b1e282e3d25d",
   "metadata": {},
   "source": [
    "By shortening the sequences, the convolutional layer may help the GRU layers detect longer patterns. Note that we must also crop off the first three time steps in the targets (since the kernel’s size is 4, the first output of the convolutional layer will be based on the input time steps 0 to 3, and since we've seen that in case of RNN the hidden state for the first run is set to 0, and if we don't do this then the LSTM will get 0 as the input for the hidden state.), and downsample the targets by a factor of 2(downsample basically means select only every second target value from the columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "103b4508-74e8-4f10-9eab-b9f47b88a241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 8s 25ms/step - loss: 0.0692 - last_time_step_mse: 0.0613 - val_loss: 0.0482 - val_last_time_step_mse: 0.0380\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 4s 20ms/step - loss: 0.0412 - last_time_step_mse: 0.0333 - val_loss: 0.0366 - val_last_time_step_mse: 0.0271\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 5s 23ms/step - loss: 0.0305 - last_time_step_mse: 0.0206 - val_loss: 0.0276 - val_last_time_step_mse: 0.0161\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 5s 24ms/step - loss: 0.0256 - last_time_step_mse: 0.0144 - val_loss: 0.0250 - val_last_time_step_mse: 0.0131\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0240 - last_time_step_mse: 0.0130 - val_loss: 0.0238 - val_last_time_step_mse: 0.0123\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0229 - last_time_step_mse: 0.0121 - val_loss: 0.0231 - val_last_time_step_mse: 0.0120\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0222 - last_time_step_mse: 0.0117 - val_loss: 0.0224 - val_last_time_step_mse: 0.0112\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0216 - last_time_step_mse: 0.0110 - val_loss: 0.0222 - val_last_time_step_mse: 0.0113\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0212 - last_time_step_mse: 0.0109 - val_loss: 0.0218 - val_last_time_step_mse: 0.0112\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0209 - last_time_step_mse: 0.0108 - val_loss: 0.0216 - val_last_time_step_mse: 0.0112\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0205 - last_time_step_mse: 0.0105 - val_loss: 0.0209 - val_last_time_step_mse: 0.0102\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0201 - last_time_step_mse: 0.0101 - val_loss: 0.0206 - val_last_time_step_mse: 0.0105\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0199 - last_time_step_mse: 0.0101 - val_loss: 0.0203 - val_last_time_step_mse: 0.0100\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0197 - last_time_step_mse: 0.0100 - val_loss: 0.0198 - val_last_time_step_mse: 0.0096\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0194 - last_time_step_mse: 0.0098 - val_loss: 0.0196 - val_last_time_step_mse: 0.0095\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0191 - last_time_step_mse: 0.0095 - val_loss: 0.0197 - val_last_time_step_mse: 0.0098\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0188 - last_time_step_mse: 0.0094 - val_loss: 0.0190 - val_last_time_step_mse: 0.0091\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0185 - last_time_step_mse: 0.0090 - val_loss: 0.0187 - val_last_time_step_mse: 0.0088\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 5s 21ms/step - loss: 0.0181 - last_time_step_mse: 0.0087 - val_loss: 0.0190 - val_last_time_step_mse: 0.0094\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 5s 22ms/step - loss: 0.0177 - last_time_step_mse: 0.0083 - val_loss: 0.0180 - val_last_time_step_mse: 0.0084\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\",\n",
    "                        input_shape=[None, 1]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "history = model.fit(X_train, Y_train[:, 3::2], epochs=20,\n",
    "                    validation_data=(X_valid, Y_valid[:, 3::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ddc0e5bc-9876-4c72-b962-fdce466d62a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31480166, -0.35355434, -0.44950873, -0.4210304 , -0.41469261,\n",
       "        -0.34517896, -0.1852376 ,  0.05097008,  0.35469484,  0.53110516],\n",
       "       [-0.35355434, -0.44950873, -0.4210304 , -0.41469261, -0.34517896,\n",
       "        -0.1852376 ,  0.05097008,  0.35469484,  0.53110516,  0.60427958],\n",
       "       [-0.44950873, -0.4210304 , -0.41469261, -0.34517896, -0.1852376 ,\n",
       "         0.05097008,  0.35469484,  0.53110516,  0.60427958,  0.57887834],\n",
       "       [-0.4210304 , -0.41469261, -0.34517896, -0.1852376 ,  0.05097008,\n",
       "         0.35469484,  0.53110516,  0.60427958,  0.57887834,  0.44205871],\n",
       "       [-0.41469261, -0.34517896, -0.1852376 ,  0.05097008,  0.35469484,\n",
       "         0.53110516,  0.60427958,  0.57887834,  0.44205871,  0.32154039],\n",
       "       [-0.34517896, -0.1852376 ,  0.05097008,  0.35469484,  0.53110516,\n",
       "         0.60427958,  0.57887834,  0.44205871,  0.32154039,  0.23079869],\n",
       "       [-0.1852376 ,  0.05097008,  0.35469484,  0.53110516,  0.60427958,\n",
       "         0.57887834,  0.44205871,  0.32154039,  0.23079869,  0.20819977],\n",
       "       [ 0.05097008,  0.35469484,  0.53110516,  0.60427958,  0.57887834,\n",
       "         0.44205871,  0.32154039,  0.23079869,  0.20819977,  0.24509065],\n",
       "       [ 0.35469484,  0.53110516,  0.60427958,  0.57887834,  0.44205871,\n",
       "         0.32154039,  0.23079869,  0.20819977,  0.24509065,  0.29302391],\n",
       "       [ 0.53110516,  0.60427958,  0.57887834,  0.44205871,  0.32154039,\n",
       "         0.23079869,  0.20819977,  0.24509065,  0.29302391,  0.25405806],\n",
       "       [ 0.60427958,  0.57887834,  0.44205871,  0.32154039,  0.23079869,\n",
       "         0.20819977,  0.24509065,  0.29302391,  0.25405806,  0.2043478 ],\n",
       "       [ 0.57887834,  0.44205871,  0.32154039,  0.23079869,  0.20819977,\n",
       "         0.24509065,  0.29302391,  0.25405806,  0.2043478 ,  0.08044362],\n",
       "       [ 0.44205871,  0.32154039,  0.23079869,  0.20819977,  0.24509065,\n",
       "         0.29302391,  0.25405806,  0.2043478 ,  0.08044362, -0.15130411],\n",
       "       [ 0.32154039,  0.23079869,  0.20819977,  0.24509065,  0.29302391,\n",
       "         0.25405806,  0.2043478 ,  0.08044362, -0.15130411, -0.40118885],\n",
       "       [ 0.23079869,  0.20819977,  0.24509065,  0.29302391,  0.25405806,\n",
       "         0.2043478 ,  0.08044362, -0.15130411, -0.40118885, -0.60727513],\n",
       "       [ 0.20819977,  0.24509065,  0.29302391,  0.25405806,  0.2043478 ,\n",
       "         0.08044362, -0.15130411, -0.40118885, -0.60727513, -0.67960876],\n",
       "       [ 0.24509065,  0.29302391,  0.25405806,  0.2043478 ,  0.08044362,\n",
       "        -0.15130411, -0.40118885, -0.60727513, -0.67960876, -0.67928213],\n",
       "       [ 0.29302391,  0.25405806,  0.2043478 ,  0.08044362, -0.15130411,\n",
       "        -0.40118885, -0.60727513, -0.67960876, -0.67928213, -0.57650429],\n",
       "       [ 0.25405806,  0.2043478 ,  0.08044362, -0.15130411, -0.40118885,\n",
       "        -0.60727513, -0.67960876, -0.67928213, -0.57650429, -0.36356413],\n",
       "       [ 0.2043478 ,  0.08044362, -0.15130411, -0.40118885, -0.60727513,\n",
       "        -0.67960876, -0.67928213, -0.57650429, -0.36356413, -0.18485373],\n",
       "       [ 0.08044362, -0.15130411, -0.40118885, -0.60727513, -0.67960876,\n",
       "        -0.67928213, -0.57650429, -0.36356413, -0.18485373, -0.10606553],\n",
       "       [-0.15130411, -0.40118885, -0.60727513, -0.67960876, -0.67928213,\n",
       "        -0.57650429, -0.36356413, -0.18485373, -0.10606553, -0.01478523],\n",
       "       [-0.40118885, -0.60727513, -0.67960876, -0.67928213, -0.57650429,\n",
       "        -0.36356413, -0.18485373, -0.10606553, -0.01478523, -0.04792443],\n",
       "       [-0.60727513, -0.67960876, -0.67928213, -0.57650429, -0.36356413,\n",
       "        -0.18485373, -0.10606553, -0.01478523, -0.04792443, -0.02151654],\n",
       "       [-0.67960876, -0.67928213, -0.57650429, -0.36356413, -0.18485373,\n",
       "        -0.10606553, -0.01478523, -0.04792443, -0.02151654, -0.05206799],\n",
       "       [-0.67928213, -0.57650429, -0.36356413, -0.18485373, -0.10606553,\n",
       "        -0.01478523, -0.04792443, -0.02151654, -0.05206799,  0.05842903],\n",
       "       [-0.57650429, -0.36356413, -0.18485373, -0.10606553, -0.01478523,\n",
       "        -0.04792443, -0.02151654, -0.05206799,  0.05842903,  0.22970435],\n",
       "       [-0.36356413, -0.18485373, -0.10606553, -0.01478523, -0.04792443,\n",
       "        -0.02151654, -0.05206799,  0.05842903,  0.22970435,  0.42907357],\n",
       "       [-0.18485373, -0.10606553, -0.01478523, -0.04792443, -0.02151654,\n",
       "        -0.05206799,  0.05842903,  0.22970435,  0.42907357,  0.5818339 ],\n",
       "       [-0.10606553, -0.01478523, -0.04792443, -0.02151654, -0.05206799,\n",
       "         0.05842903,  0.22970435,  0.42907357,  0.5818339 ,  0.68988335],\n",
       "       [-0.01478523, -0.04792443, -0.02151654, -0.05206799,  0.05842903,\n",
       "         0.22970435,  0.42907357,  0.5818339 ,  0.68988335,  0.6971643 ],\n",
       "       [-0.04792443, -0.02151654, -0.05206799,  0.05842903,  0.22970435,\n",
       "         0.42907357,  0.5818339 ,  0.68988335,  0.6971643 ,  0.61073887],\n",
       "       [-0.02151654, -0.05206799,  0.05842903,  0.22970435,  0.42907357,\n",
       "         0.5818339 ,  0.68988335,  0.6971643 ,  0.61073887,  0.34636354],\n",
       "       [-0.05206799,  0.05842903,  0.22970435,  0.42907357,  0.5818339 ,\n",
       "         0.68988335,  0.6971643 ,  0.61073887,  0.34636354,  0.14752936],\n",
       "       [ 0.05842903,  0.22970435,  0.42907357,  0.5818339 ,  0.68988335,\n",
       "         0.6971643 ,  0.61073887,  0.34636354,  0.14752936, -0.02777057],\n",
       "       [ 0.22970435,  0.42907357,  0.5818339 ,  0.68988335,  0.6971643 ,\n",
       "         0.61073887,  0.34636354,  0.14752936, -0.02777057, -0.0924909 ],\n",
       "       [ 0.42907357,  0.5818339 ,  0.68988335,  0.6971643 ,  0.61073887,\n",
       "         0.34636354,  0.14752936, -0.02777057, -0.0924909 , -0.14909704],\n",
       "       [ 0.5818339 ,  0.68988335,  0.6971643 ,  0.61073887,  0.34636354,\n",
       "         0.14752936, -0.02777057, -0.0924909 , -0.14909704, -0.17776802],\n",
       "       [ 0.68988335,  0.6971643 ,  0.61073887,  0.34636354,  0.14752936,\n",
       "        -0.02777057, -0.0924909 , -0.14909704, -0.17776802, -0.15904522],\n",
       "       [ 0.6971643 ,  0.61073887,  0.34636354,  0.14752936, -0.02777057,\n",
       "        -0.0924909 , -0.14909704, -0.17776802, -0.15904522, -0.17623015],\n",
       "       [ 0.61073887,  0.34636354,  0.14752936, -0.02777057, -0.0924909 ,\n",
       "        -0.14909704, -0.17776802, -0.15904522, -0.17623015, -0.3065688 ],\n",
       "       [ 0.34636354,  0.14752936, -0.02777057, -0.0924909 , -0.14909704,\n",
       "        -0.17776802, -0.15904522, -0.17623015, -0.3065688 , -0.38701382],\n",
       "       [ 0.14752936, -0.02777057, -0.0924909 , -0.14909704, -0.17776802,\n",
       "        -0.15904522, -0.17623015, -0.3065688 , -0.38701382, -0.52245861],\n",
       "       [-0.02777057, -0.0924909 , -0.14909704, -0.17776802, -0.15904522,\n",
       "        -0.17623015, -0.3065688 , -0.38701382, -0.52245861, -0.63717854],\n",
       "       [-0.0924909 , -0.14909704, -0.17776802, -0.15904522, -0.17623015,\n",
       "        -0.3065688 , -0.38701382, -0.52245861, -0.63717854, -0.6540364 ],\n",
       "       [-0.14909704, -0.17776802, -0.15904522, -0.17623015, -0.3065688 ,\n",
       "        -0.38701382, -0.52245861, -0.63717854, -0.6540364 , -0.57042772],\n",
       "       [-0.17776802, -0.15904522, -0.17623015, -0.3065688 , -0.38701382,\n",
       "        -0.52245861, -0.63717854, -0.6540364 , -0.57042772, -0.37353641],\n",
       "       [-0.15904522, -0.17623015, -0.3065688 , -0.38701382, -0.52245861,\n",
       "        -0.63717854, -0.6540364 , -0.57042772, -0.37353641, -0.0779064 ],\n",
       "       [-0.17623015, -0.3065688 , -0.38701382, -0.52245861, -0.63717854,\n",
       "        -0.6540364 , -0.57042772, -0.37353641, -0.0779064 ,  0.10002153],\n",
       "       [-0.3065688 , -0.38701382, -0.52245861, -0.63717854, -0.6540364 ,\n",
       "        -0.57042772, -0.37353641, -0.0779064 ,  0.10002153,  0.33614752]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770e676-260c-471e-9d3f-cf7f3093ec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "679041af-c8e1-4dd8-8278-ab6743c359a0",
   "metadata": {},
   "source": [
    "## WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745e943a-be4b-4cc1-93ef-86eeaa068b6e",
   "metadata": {},
   "source": [
    "In a 2016 paper, Aaron van den Oord and other DeepMind researchers introduced an architecture called WaveNet. They stacked 1D convolutional layers, doubling the dilation rate (how spread apart each neuron’s inputs are) at every layer: the first convolutional layer gets a glimpse of just two time steps at a time, while the next one sees four time steps (its receptive field is four time steps long), the next one sees eight time steps, and so on (see Figure 15-11)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb05042-731d-4454-9746-0f87a6858212",
   "metadata": {},
   "source": [
    "This way, the lower layers learn short-term patterns, while the higher layers learn long-term patterns. Thanks to the doubling dilation rate, the network can process extremely large sequences very efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b9312-a282-4ce1-a8ea-4083940441b9",
   "metadata": {},
   "source": [
    "### WaveNet architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ad445-e71d-4fe8-bbe6-caba030036e1",
   "metadata": {},
   "source": [
    "In the WaveNet paper, the authors actually stacked 10 convolutional layers with dilation rates of 1, 2, 4, 8, …, 256, 512, then they stacked another group of 10 identical layers (also with dilation rates 1, 2, 4, 8, …, 256, 512), then again another identical group of 10 layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9054a17-69fa-477f-ac27-9db6c2a10c8f",
   "metadata": {},
   "source": [
    "They justified this architecture by pointing out that a single stack of 10 convolutional layers with these dilation rates will act like a super-efficient convolutional layer with a kernel of size 1,024 (except way faster, more powerful, and using significantly fewer parameters), which is why they stacked 3 such blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c683f52-5072-4bed-9b69-e080726b92bb",
   "metadata": {},
   "source": [
    "They also left-padded the input sequences with a number of zeros equal to the dilation rate before every layer, to preserve the same sequence length throughout the network (this is done by passing padding = 'casual')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e70357-95bf-4ca5-b6ac-6b44564cf25c",
   "metadata": {},
   "source": [
    "### Implementing WaveNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d5b7440-701d-4bd4-9381-afac54e5162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 4s 12ms/step - loss: 0.0627 - last_time_step_mse: 0.0507 - val_loss: 0.0369 - val_last_time_step_mse: 0.0219\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0321 - last_time_step_mse: 0.0183 - val_loss: 0.0312 - val_last_time_step_mse: 0.0182\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0284 - last_time_step_mse: 0.0155 - val_loss: 0.0279 - val_last_time_step_mse: 0.0145\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0265 - last_time_step_mse: 0.0139 - val_loss: 0.0267 - val_last_time_step_mse: 0.0134\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0251 - last_time_step_mse: 0.0128 - val_loss: 0.0256 - val_last_time_step_mse: 0.0126\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0243 - last_time_step_mse: 0.0122 - val_loss: 0.0248 - val_last_time_step_mse: 0.0120\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0238 - last_time_step_mse: 0.0118 - val_loss: 0.0248 - val_last_time_step_mse: 0.0123\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0233 - last_time_step_mse: 0.0114 - val_loss: 0.0240 - val_last_time_step_mse: 0.0111\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0227 - last_time_step_mse: 0.0108 - val_loss: 0.0228 - val_last_time_step_mse: 0.0103\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0223 - last_time_step_mse: 0.0105 - val_loss: 0.0238 - val_last_time_step_mse: 0.0123\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0221 - last_time_step_mse: 0.0104 - val_loss: 0.0222 - val_last_time_step_mse: 0.0097\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0214 - last_time_step_mse: 0.0097 - val_loss: 0.0218 - val_last_time_step_mse: 0.0096\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0213 - last_time_step_mse: 0.0098 - val_loss: 0.0223 - val_last_time_step_mse: 0.0103\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0207 - last_time_step_mse: 0.0091 - val_loss: 0.0223 - val_last_time_step_mse: 0.0104\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0204 - last_time_step_mse: 0.0089 - val_loss: 0.0210 - val_last_time_step_mse: 0.0091\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0200 - last_time_step_mse: 0.0085 - val_loss: 0.0205 - val_last_time_step_mse: 0.0081\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0196 - last_time_step_mse: 0.0081 - val_loss: 0.0199 - val_last_time_step_mse: 0.0077\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.0193 - last_time_step_mse: 0.0077 - val_loss: 0.0197 - val_last_time_step_mse: 0.0072\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0190 - last_time_step_mse: 0.0074 - val_loss: 0.0200 - val_last_time_step_mse: 0.0081\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0188 - last_time_step_mse: 0.0072 - val_loss: 0.0191 - val_last_time_step_mse: 0.0069\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.InputLayer(input_shape=[None, 1]))\n",
    "for rate in (1, 2, 4, 8) * 2:\n",
    "    model.add(keras.layers.Conv1D(filters=20, kernel_size=2, padding=\"causal\",activation=\"relu\", dilation_rate=rate))\n",
    "model.add(keras.layers.Conv1D(filters=10, kernel_size=1))\n",
    "\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[last_time_step_mse])\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=20,validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d4f0f-4e01-4d00-951c-e945b0308943",
   "metadata": {},
   "source": [
    "### Code Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b58541-84d2-4762-b575-6b2bdde6aad4",
   "metadata": {},
   "source": [
    "This Sequential model starts with an explicit input layer (this is simpler than trying to set input_shape only on the first layer), then continues with a 1D convolutional layer using \"causal\" padding: this ensures that the convolutional layer does not peek into the future when making predictions (it is equivalent to padding the inputs with the right amount of zeros on the left and using \"valid\" padding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb8022b-a680-4790-bace-84ed6654d980",
   "metadata": {},
   "source": [
    "We then add similar pairs of layers using growing dilation rates: 1, 2, 4, 8, and again 1, 2, 4, 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e7385-54cf-4859-9df7-ffda5dbe910e",
   "metadata": {},
   "source": [
    "Finally, we add the output layer: a convolutional layer with 10 filters of size 1 and without any activation function. Thanks to the padding layers, every convolutional layer outputs a sequence of the same length as the input sequences, so the targets we use during training can be the full sequences: no need to crop them or downsample them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b612e83-e591-459f-9c84-390fb14d6ceb",
   "metadata": {},
   "source": [
    "In the WaveNet paper, the authors achieved state-of-the-art performance on various audio tasks (hence the name of the architecture), including text-to-speech tasks, producing incredibly realistic voices across several languages. They also used the model to generate music, one audio sample at a time. This feat is all the more impressive when you realize that a single second of audio can contain tens of thousands of time steps—even LSTMs and GRUs cannot handle such long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96ea2a-1f05-4f43-b024-52a4577a6fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c1eee45c-11c0-4ed9-a834-c4946a5e9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for ki  in (1,2,3,4) * 2:\n",
    "    print(ki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a0f24-6faa-465c-8302-f90105c95194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f8edc-c59a-4b55-a4f1-e79b2adc5761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e2b49-7896-44ab-bb65-4f9d7c820f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d563a-d8a1-4466-bf4c-cc2ff1a91820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda1e21-97cf-473f-9312-49ffef236da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d9bd4a-6b06-42b0-b938-16d805051035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f21b66-444b-4db6-af8e-30487943eccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00523eb-df70-4e73-adfc-a3e8d0b12861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab269a-258e-4b49-81ef-a445d36dbe6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a6adc9-3e8f-4ebc-8f6c-64a61e84c513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d8098-6b8e-4407-94da-a9b146ea6d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e339ff-521f-4ce9-b567-fa01544a99b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446bf71-2c41-42c3-83a4-95b652e703d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459fa801-2fa9-4336-8112-bb36f4592b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc90100-0e27-4f27-b8ca-3633618bcfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd4d8c-f5a4-4e77-8e5c-51670c8d44c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d5ee2-5a92-4cc3-87c5-7411f8fc5b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1f96d-09c0-43c6-b0a4-eaf4005d2f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f787c-9cda-49ab-b8bf-19329e48cd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49bc51c-32d2-4d34-85bf-a0ddca410ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14439ee-7927-4d40-8ac9-e0c312fa83a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a680a-f9de-4511-ab35-a2a115137c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265d8d3-66de-44d7-836a-a02808aefbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048a529-1e6b-41c6-9023-c191014f1b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28e9b1d-7d84-47bf-9428-8d633b4c9e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829d092-b987-45c3-ae06-51edaea2a199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94656bb3-fff8-477a-a287-49aa50b40514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dfb52-82e0-4a96-af68-bf965015597a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93f2d8-86bd-445f-8bde-b6d6c6f47b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e7fa72-0343-47c8-8810-3d955103d386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612d9f1-f25a-450b-861d-9a600f6792b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901bbe68-4dea-438a-b912-093f27f890c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2659a65c-68c2-4ebd-bf6b-e22a3b86ed4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b98e45-cd8c-4e24-a306-d19e631fe6a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1463fe4d-3dad-40d5-8f42-61534e81e2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b68db-ad9e-4c5f-8cf7-18d14705ebd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474842a4-9669-4c48-ac86-6257babf7142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9d711-bc79-42df-beed-42739297bd35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e50ee-f659-41c0-a693-6be64f0ed46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71a57c-35ed-44e4-a543-8dba7a7b23fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e62ab9-4f0b-4b97-93d7-5c74693a0739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af13a8b-bced-4d7b-9213-b5db440ce17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc764b0-0e57-441b-a467-11fd80a292cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58bf3e-79b1-419d-b504-3d0ea6ac1ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9d0af-7151-4786-b381-2ae258ae0c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82ca7b-62b7-40d9-930b-58015e8fab35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fd960-a9fc-40ad-9c07-4267490fc1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a73a4-e09f-4ec2-9e86-06459f89204b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb029a3-c1c9-4a39-b38a-273e43135a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022aa7fa-71f8-4021-bb98-bb89607cda28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee600b7d-e83f-446b-bee3-237c029b175b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79d852c-dbe0-4030-9703-ce0a5a508a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc59a506-496b-49e7-bd91-d12586558070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe17c4-4ee9-4df7-879f-13a9eb111001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa02329-0f1a-490c-8fa8-c04c77bf56bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1e6b4-8fd7-4ab2-a806-e292ab885330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ad9bb-bae2-4adf-9b2f-1eb79f3c1c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8253fdb-5e91-46dc-94b7-31aecb9f3c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd4cf1-0653-4ea0-9b0b-15acda27dc35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566d80c-b4da-47ac-bb8a-1984d373210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8756cdd-4452-4b85-9224-3ef4ccfeab97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca856a2a-3aa1-488b-8c59-5a2e2d2b14ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8381ed3-0110-48e8-9c7a-a58053507890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3964ba65-a035-4cd9-93b8-b462ed3b8e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25928e-23df-4dca-bcca-ed8bf37ce852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679844f-59fe-42da-9caf-ccf33a3b0f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e78db-9742-40f0-864b-b94d1b43657d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0d8bd7-6d55-43ba-a70e-9986b2f74566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878467cf-5226-4fd3-b27e-92c7979ba253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce8c69-e4eb-4bcf-9d82-b06c3628d620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97ecb5-d188-45f7-b26d-e3e04c043eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2883c-1a9e-44c6-9fbe-b496c4bc729a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d89b51-2b1d-43bd-9e91-cea32fcf6237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c840e0e5-68c1-4e25-8e85-0e90e8dd3c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286fef2-72da-42b8-a463-8ac18d1d8b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195eed4-52f4-430a-8d5d-7034944249eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3b133-5b4f-4a70-9891-ee38c9a7aa74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded06f6a-0b33-4c45-9584-d4b1af99aa97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917584c6-b471-4b0e-ad97-f87239e022f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718e05e-f1a1-4149-8975-5fcbd7b3e36e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe67a83-bd2c-4314-adac-521f3793b4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61f477-55cd-49ed-a841-42af91bec209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196770d8-0cf3-498d-9641-6780148df02f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e700847-60f2-4289-b313-a72785a5659a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c3c9a-65e4-482e-b05e-3024d05a13ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25f8c82-d217-4fa9-97a2-6e49e8eadf34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ed7a5-ed2c-417a-988f-f03ffc656dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b22b10-9d54-4297-bcbf-80db02a7b488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a8e53-07ee-4c38-890f-81600ceb0535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945457f5-b577-4822-a161-4ae64bde2280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b52065-9fe0-43a7-97e6-3863a9082077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a2eec-c240-4947-9203-c9716e816958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257622b-6ef2-4939-9a5e-b87cd5537d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b8ed9-bba3-4755-8bf0-7eba7af5133a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf05aa-be67-48e8-8501-14005e15aaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5e5d5-894f-4c33-902b-fea7e83a5451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572c363-2080-4c87-ae30-44db5b4fdb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d60048-270a-41ab-b6ce-1855bbc57c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4fab2-2a6b-4b26-bc3a-d47648f4e9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be154c50-04e8-4046-8a3b-2d6b01f02263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee828c9c-c9da-4bde-97a3-7715e4a9a789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d01563-0332-418d-a6d4-7b57c7255fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51323821-02e5-4777-9800-d4141d064fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430af0ab-006c-4986-b85d-1287f636d727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7817cbc6-ba86-4914-af43-546055065d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e002eea-ae3b-4df2-b705-839c73117fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb585a-bc09-48ed-a707-5ffe9122a9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909a75c-9c70-4730-afcd-818c81ff72a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061eb907-4e25-4fab-8268-c03a34176c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bdbf4e-344f-4a43-b60d-dd518cdfc41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22180d2-b89c-4a57-b7e3-cf41dc97df7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00656896-29c1-4445-8266-2d4af6036135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e80ff6-7d24-4e75-a379-fd8e6d267f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffa0c58-db7a-49f8-8b8d-efc1d309e667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f2455-4b1d-42bb-b843-65b9cc0c1056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c73d48-c803-4314-9fa2-f2f7742cb2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae2bae-309c-47b0-b70e-97f314c7056e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f1480-ca13-49cc-ae56-8944d3d79804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd6a63-a02a-4d00-ad28-13441cbf1b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa3224-ff03-4145-b0ca-6022137d1971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e26bab-bc37-43a5-99ab-bea68bb7b859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5952f1b7-2ef3-491f-94ec-6401446fae60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732253c7-3d21-4ffc-b09e-a65660a94534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c0b67-4662-4511-8d92-5fa73fb15b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a489d-ebc6-4dc5-9a0f-25a45b22d93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ede13b-ce08-4965-b45b-acdb7e73d468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0163ce-cded-4da3-93d4-f5fdec8a9b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74875b-c395-44d8-8162-62fda2650d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701bc33f-741b-4a07-b327-8f61c8e6ef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfdffc-4b02-454f-ae19-8c9b2c6b3035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898399e9-82e8-4452-9fa1-ed9662316ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e925ce56-0d21-4c5d-970f-5b116d9611ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9262ce7f-9426-41ba-a2d3-50c6614e6d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28283c-1389-404c-bdbe-9b311a8695df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f07b2-a86e-412b-93ee-d6f252989356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dfc41c-7e0c-4ab5-846f-d605a451da42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f7906-b062-4dd3-978c-52cddeac3af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87111e-ea66-4faf-ac94-0daa7ba04221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
