{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84183451-8e0e-42b3-9b3a-6cbe301e5a64",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b019dfd-698d-4b53-b3b0-8e0247684442",
   "metadata": {},
   "source": [
    "So far we have used only datasets that fit in memory, but Deep Learning systems are often trained on very large datasets that will not fit in RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcefe9-4a95-4cd3-8552-aed246a13dbf",
   "metadata": {},
   "source": [
    "Ingesting a large dataset and preprocessing it efficiently can be tricky to implement with other Deep Learning libraries, but TensorFlow makes it easy thanks to the Data API, you just create a dataset object, and tell it where to get the data and how to transform it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3597cf-0910-4a0b-a827-fb460d88c979",
   "metadata": {},
   "source": [
    "TensorFlow takes care of all the implementation details, such as multithreading, queuing, batching, and prefetching. Moreover, the Data API works seamlessly with tf.keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc14134-d1f9-4123-88a6-6b7658f3712b",
   "metadata": {},
   "source": [
    "Off the shelf, the Data API can read from text files (such as CSV files), binary files with fixed-size records, and binary files that use TensorFlow’s TFRecord format, which supports records of varying sizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a781670-0da4-4069-a09d-d308603fbbb1",
   "metadata": {},
   "source": [
    "TFRecord is a flexible and efficient binary format usually containing protocol buffers (an open source binary format)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595aebb-abdb-468f-84ed-f1d0b23e9df2",
   "metadata": {},
   "source": [
    "The Data API also has support for reading from SQL databases. Moreover, many open source extensions are available to read from all sorts of data sources, such as Google’s Big‐Query service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee0843-5ea5-46ba-85e5-c3beeeaec635",
   "metadata": {},
   "source": [
    "Reading huge datasets efficiently is not the only difficulty: the data also needs to be preprocessed, usually normalized. Moreover, it is not always composed strictly of convenient numerical fields: there may be text features, categorical features, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750614c4-7e7d-4527-84e6-266dc1a0444c",
   "metadata": {},
   "source": [
    "These need to be encoded, for example using one-hot encoding, bag-of-words encoding, or embedding. An embedding is a trainable dense vector that represents a category or token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1365612-3b6c-483e-a4d9-2f5f4a53f730",
   "metadata": {},
   "source": [
    "One option to handle all this preprocessing is to write your own custom preprocessing layers. Another is to use the standard preprocessing layers provided by Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d77246-7fcf-4ed4-b459-dd987496be08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79b5824-f0b5-4e28-b988-b13857f6f81c",
   "metadata": {},
   "source": [
    "## Chapter Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecd605-b8e8-4a5b-957d-97eb76eb3f12",
   "metadata": {},
   "source": [
    "In this chapter, we will cover the Data API, the TFRecord format, and how to create\r\n",
    "custom preprocessing layers and use the standard Keras ones. We will also take a quick look at a few related projects from TensorFlow’s ecosystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48cf8c4e-7261-4aaa-8eac-c70a6d285300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebd7a6-8c29-4e4d-9dc7-ee6f6fccb213",
   "metadata": {},
   "source": [
    "## TensorFlow Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a67cd-5805-4ad0-bc17-4895100378cc",
   "metadata": {},
   "source": [
    "### TF Transform (tf.Transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40203a01-ff82-433f-bc7e-e232f683279b",
   "metadata": {},
   "source": [
    "Makes it possible to write a single preprocessing function that can be run in batch mode on your full training set, before training (to speed it up), and then exported to a TF Function and incorporated into your trained model so that once it is deployed in production it can take care of preprocessing new instances on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534da13d-4194-4f95-8228-68662d5b46bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c7d523f-9e88-4f76-bcd5-d6bccf97924c",
   "metadata": {},
   "source": [
    "### TF Datasets (TFDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4d630-082c-4df7-bee9-2bd812182f78",
   "metadata": {},
   "source": [
    "Provides a convenient function to download many common datasets of all kinds, including large ones like ImageNet, as well as convenient dataset objects to manipulate them using the Data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2064bb-e765-438a-b570-2f826fa41f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd22caef-4390-43e3-9895-9d96d940805e",
   "metadata": {},
   "source": [
    "## The Data API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0a40e-1724-463b-ad7e-1d5536fe5658",
   "metadata": {},
   "source": [
    "The whole Data API revolves around the concept of a dataset: as you might suspect, this represents a sequence of data items. Usually you will use datasets that gradually read data from disk, but for simplicity let’s create a dataset entirely in RAM using tf.data.Dataset.from_tensor_slices():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bd3686-1e95-425d-92d3-e2c8752d94c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfaf947d-4f18-43a7-a625-643c06a09aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.range(10)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b416ddd-ee41-497c-9642-1955ef338c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9a551-4d38-4e97-a2b6-a294ee3789de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cefcf43-2ea3-42a6-94dd-d5056dd98eee",
   "metadata": {},
   "source": [
    "The from_tensor_slices() function takes a tensor and creates a tf.data.Dataset whose elements are all the slices of X (along the first dimension), so this dataset contains 10 items: tensors 0, 1, 2, …, 9. In this case we would have obtained the same dataset if we had used tf.data.Dataset.range(10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e57c9c-d7c5-4881-a5a9-3c5cd5e50523",
   "metadata": {},
   "source": [
    "You can simply iterate over a dataset’s items like this:\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd19fbb-f701-4d68-805e-e653cc16d967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82c7b8-c921-40d8-aea4-53e3d02728bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e50aa91c-fd18-4cd8-94d4-418cc8b96d6e",
   "metadata": {},
   "source": [
    "### Chaining Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2dfc2-194e-4f04-9389-62014c849ee4",
   "metadata": {},
   "source": [
    "Once you have a dataset, you can apply all sorts of transformations to it by calling its transformation methods. Each method returns a new dataset, so you can chain transformations like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c568c141-3855-4f6e-ac67-502f7f270c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfc81c5-2f0c-4fb4-9a21-ff0dd17c02cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bda9c03-c3a4-44ef-9d00-a99b4180a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.repeat(3).batch(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de3f9c1d-6498-4275-b569-52010854a56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9 0 1 2 3 4], shape=(7,), dtype=int32)\n",
      "tf.Tensor([5 6 7 8 9 0 1], shape=(7,), dtype=int32)\n",
      "tf.Tensor([2 3 4 5 6 7 8], shape=(7,), dtype=int32)\n",
      "tf.Tensor([9 0 1 2 3 4 5], shape=(7,), dtype=int32)\n",
      "tf.Tensor([6 7 8 9 0 1 2], shape=(7,), dtype=int32)\n",
      "tf.Tensor([3 4 5 6 7 8 9], shape=(7,), dtype=int32)\n",
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461910fe-f140-45a1-81e0-973da6f980f5",
   "metadata": {},
   "source": [
    "#### Explanation of the transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa9c0c-54d7-44f5-a641-c5990333ba72",
   "metadata": {},
   "source": [
    "##### repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59f23e9-b955-46cd-831c-cfe9ef5b8007",
   "metadata": {},
   "source": [
    "In this example, we first call the repeat() method on the original dataset, and it returns a new dataset that will repeat the items of the original dataset three times see the dataset = dataset.repeat(3) block and the for block after that . Of course, this will not copy all the data in memory three times!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57348a92-1321-4db5-9f1d-6a51ac7f485d",
   "metadata": {},
   "source": [
    "##### WARNING REPEAT!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "If you call this method with no arguments, the new dataset will repeat the source dataset forever, so the code that iterates over the dataset will have to decide when to stop. Try running the command dataset = dataset.repeat(3) and then run the for loop in the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a2354-c733-4c44-a32c-125be3c24830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd45a906-d46c-4158-a9cc-31679656a499",
   "metadata": {},
   "source": [
    "#### batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3446ce5b-fa20-46c8-a0a6-3f2d51987c4a",
   "metadata": {},
   "source": [
    "Then we call the batch() method on this new dataset, and again this creates a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf466c3c-e584-4955-89d9-eb34fa39dd70",
   "metadata": {},
   "source": [
    "This one will group the items of the previous dataset in batches of seven items. Finally, we iterate over the items of this final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1c05b-f2c2-4b63-a24c-e4bd799dc55b",
   "metadata": {},
   "source": [
    "As you can see, the batch() method had to output a final batch of size two instead of seven, but you can call it with drop_remainder=True if you want it to drop this final batch so that all batches have the exact same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c2b81-c096-4867-85d1-f4cd12fed41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee3d1066-4b56-4286-a0c2-3b2e3e3f1dde",
   "metadata": {},
   "source": [
    "#### map method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db2d06-9dd7-4ae8-a82b-e403e1bd40ad",
   "metadata": {},
   "source": [
    "You can also transform the items by calling the map() method. For example, this creates a new dataset with all items doubled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2bd6a17-0c62-48bd-b19d-245f8841d1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x:x**3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8a83fa-c181-4814-8150-cb5ae2213d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  0   1   8  27  64 125 216], shape=(7,), dtype=int32)\n",
      "tf.Tensor([343 512 729   0   1   8  27], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 64 125 216 343 512 729   0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([  1   8  27  64 125 216 343], shape=(7,), dtype=int32)\n",
      "tf.Tensor([512 729   0   1   8  27  64], shape=(7,), dtype=int32)\n",
      "tf.Tensor([125 216 343 512 729   0   1], shape=(7,), dtype=int32)\n",
      "tf.Tensor([  8  27  64 125 216 343 512], shape=(7,), dtype=int32)\n",
      "tf.Tensor([729   0   1   8  27  64 125], shape=(7,), dtype=int32)\n",
      "tf.Tensor([216 343 512 729   0   1   8], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 27  64 125 216 343 512 729], shape=(7,), dtype=int32)\n",
      "tf.Tensor([  0   1   8  27  64 125 216], shape=(7,), dtype=int32)\n",
      "tf.Tensor([343 512 729   0   1   8  27], shape=(7,), dtype=int32)\n",
      "tf.Tensor([ 64 125 216 343 512 729], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a0d41-4e6a-4a3e-88d8-6c211a3c8841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bc64731-e8a4-4da0-9423-8e00d7ae0b29",
   "metadata": {},
   "source": [
    "#### map method usage\n",
    "This function is the one you will call to apply any preprocessing you want to your data. Sometimes this will include computations that can be quite intensive, such as reshaping or rotating an image, so you will usually want to spawn multiple threads to speed things up: it’s as simple as setting the num_parallel_calls argument. Note that the function you pass to the map() method must be convertible to a TF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c6e51-1bb4-4446-95ca-96746f3853a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02c61a22-ce4d-4051-9d1a-15b2dc59c9da",
   "metadata": {},
   "source": [
    "#### apply method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98817573-ebd2-4497-bcd4-0cce37608f41",
   "metadata": {},
   "source": [
    "While the map() method applies a transformation to each item, the apply() method applies a transformation to the dataset as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1416c-3858-4da2-b82d-c0c29f27e0a4",
   "metadata": {},
   "source": [
    "For example, the following code. Each item in the new dataset will be a single-integer tensor instead of a batch of seven integers:applies the unbatch() function to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8f8b04-c9c4-4a4e-aceb-6d06571a0239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_22552\\923569130.py:1: unbatch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.unbatch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_UnbatchDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.apply(tf.data.experimental.unbatch())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206e327-b162-48c7-a60c-ce779694e54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e8f4d8b-1aec-451e-be18-01639b8a20f7",
   "metadata": {},
   "source": [
    "#### It is also possible to simply filter the dataset using the filter() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b90f4315-ac62-4e35-a552-ecbb3d027b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_FilterDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x : x<7)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8adc5fa0-7a6a-4b18-9633-4609c8e99b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23e1cc-d562-43b2-8465-1e64d2951bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e97ea57-daff-442c-bee4-9a70d38df744",
   "metadata": {},
   "source": [
    "#### You will often want to look at just a few items from a dataset. You can use the take() method for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac6da8f7-3b92-463e-a2d4-7f7d61e29779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(533):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c118f-04d1-412e-a41d-59c2fdf63e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db74d86-46e5-4697-9f0b-ffa3f9c80891",
   "metadata": {},
   "source": [
    "## Shuffling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5ac74-6acc-4019-b7ff-148a8f9cade2",
   "metadata": {},
   "source": [
    "As you know, Gradient Descent works best when the instances in the training set are independent and identically distributed. A simple way to ensure this is to shuffle the instances, using the shuffle() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fc96b-bcd2-4df4-b2b6-7cfc82451aba",
   "metadata": {},
   "source": [
    "#### Shuffle method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a686b7ff-e184-4371-9923-9031f68df7a5",
   "metadata": {},
   "source": [
    "1) It will create a new dataset that will start by filling up a buffer with the first items of the source dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1c487-17ad-48d3-a7b4-ee1757de7541",
   "metadata": {},
   "source": [
    "2) Then, whenever it is asked for an item, it will pull one out randomly from the buffer and replace it with a fresh one from the source dataset, until it has iterated entirely through the source dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cd3061-86bd-45d4-9156-5ada81b3d592",
   "metadata": {},
   "source": [
    "3) At this point it continues to pull out items randomly from the buffer until it is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47904538-18be-49d6-b374-8c6918b1ad33",
   "metadata": {},
   "source": [
    "4) You must specify the buffer size, and it is important to make it large enough, or else shuffling will not be very effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56399ee7-ac54-4380-aaac-a22d4da8af5c",
   "metadata": {},
   "source": [
    "#### A simple analogy to explain why it is important to have a bigger buffer size when shuffling\n",
    "Imagine a sorted deck of cards on your left: suppose you just take the top three cards and shuffle them, then pick one randomly and put it to your right, keeping the other two in your hands. Take another card on your left, shuffle the three cards in your hands and pick one of them randomly, and put it on your right. When you are done going through all the cards like this, you will have a deck of cards on your right: do you think it will be perfectly shuffled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b779dd73-79f2-425b-9eb6-c1d67f901e61",
   "metadata": {},
   "source": [
    "5) Just don’t exceed the amount of RAM you have, and even if you have plenty of it, there’s no need to go beyond the dataset’s size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407c221-feee-4941-b367-6052e4ef3434",
   "metadata": {},
   "source": [
    "6) You can provide a random seed if you want the same random order every time you run your program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c590102-e7c7-4376-94d9-12a22d96266f",
   "metadata": {},
   "source": [
    "For example, the following code creates and displays a dataset containing the integers 0 to 9, repeated 3 times, shuffled using a buffer of size 5 and a random seed of 42, and batched with a batch size of 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6bd5ab6-c91d-4c74-96fa-2b3e872cfc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_RepeatDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7f42f8-287a-499f-b17f-dd607d83e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef5805af-aa4f-494a-8578-8adb8bccd206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(None,), dtype=tf.int64, name=None)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(buffer_size=13,seed=231213).batch(7)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a7f1cd1-667e-4156-b809-9408d3eaaab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9 6 3 1 1 7 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 8 5 8 9 0 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 2 2 0 8 6 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([2 0 7 5 7 9 1], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 4], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c1711-d145-4618-a4c7-1b15f60d1712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f433eab-0f6b-4895-8f7b-3f04c209d2d0",
   "metadata": {},
   "source": [
    "#### Note about repeat on a shuffled dataset\n",
    "If you call repeat() on a shuffled dataset, by default it will generate a new order at every iteration. This is generally a good idea, but if you prefer to reuse the same order at each iteration (e.g., for tests or debugging), you can set reshuffle_each_iteration=False.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f861a593-5712-4a3d-bfe5-7cec084af40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f947dad-f47f-4295-aa0c-306fbdeb9e1e",
   "metadata": {},
   "source": [
    "#### Shuffling for Large Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f80d5d-6f75-45da-9418-23c1ba16f607",
   "metadata": {},
   "source": [
    "For a large dataset that does not fit in memory, this simple shuffling-buffer approach may not be sufficient, since the buffer will be small compared to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3542c29-9c9b-4997-8f56-94316ebb1ef2",
   "metadata": {},
   "source": [
    "One solution is to shuffle the source data itself (for example, on Linux you can shuffle text files using the shuf command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99644f23-c813-472d-bda4-bcd7a6452deb",
   "metadata": {},
   "source": [
    "This will definitely improve shuffling a lot! Even if the source data is shuffled, you will usually want to shuffle it some more, or else the same order will be repeated at each epoch, and the model may end up being biased(e.g., due to some spurious patterns present by chance in the source data’s order)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e2ebf-da27-413b-8d8f-0e66ca0b6f9f",
   "metadata": {},
   "source": [
    "To shuffle the instances some more, a common approach is to split the source data into multiple files, then read them in a random order during training. However, instances located in the same file will still end up close to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c959f-0935-44c0-bbec-47c6f98ed1ee",
   "metadata": {},
   "source": [
    "To avoid this you can pick multiple files randomly and read them simultaneously, interleaving their records(basically mixing their records, like you read first line from the first file and the next line from the seventh file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d5156-4b85-4f2f-9f7a-1b9dd0c851dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e0335ad-8d3e-4193-a060-9da4333d84d2",
   "metadata": {},
   "source": [
    "#### Interleaving lines from multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68eb42-3d30-4f99-a89d-20e660bbfe1a",
   "metadata": {},
   "source": [
    "First, let’s suppose that you’ve loaded the California housing dataset, shuffled it (unless it was already shuffled), and split it into a training set, a validation set, and a test set. Then you split each set into many CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac71152-9ff2-47a9-adad-8ccc61ad1ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "726f319f-db40-40e4-89d9-e53e9df23172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.89175860e+00,  2.86245478e+01,  5.45593655e+00,  1.09963474e+00,\n",
       "        1.42428122e+03,  2.95886657e+00,  3.56464315e+01, -1.19584363e+02])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bfb3f79-b024-4f8b-b807-a459afe69a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.90927329e+00, 1.26409177e+01, 2.55038070e+00, 4.65460128e-01,\n",
       "       1.09576000e+03, 2.36138048e+00, 2.13456672e+00, 2.00093304e+00])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c70079b0-f05b-40d9-a64b-8576fcd1cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"C:/Users/manas/Downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "417242ef-ae87-4160-a02b-1585a3daec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(dir,\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84b04ebe-ab8a-40dc-8478-2f6f2afd16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5be77878-9646-4d97-b826-aecd1bfaf713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11610"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c6403e9-476a-4c3b-aa4a-9a0c80e64dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5723a4b5-c757-4b9d-b43b-c250b33bd138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
      "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
      "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
     ]
    }
   ],
   "source": [
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc66a5a2-21a5-4aca-9b88-cc3c55e16660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fb18b27-ba47-4d6f-882d-36ca1c4b5c30",
   "metadata": {},
   "source": [
    "#### Now continuing with interleaving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf46a97-c096-4563-95e5-6932224bf97e",
   "metadata": {},
   "source": [
    "By default, the list_files() function returns a dataset that shuffles the file paths. In general this is a good thing, but you can set shuffle=False if you do not want that for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf81ebc8-6a90-4bcd-bb8a-ba2cfa62ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets_filepath = tf.data.Dataset.list_files(train_filepaths, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9de2a1e1-7578-48cb-b1a5-31269dd12fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_00.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_01.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_02.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_03.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_04.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_05.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_06.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_07.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_08.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_09.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_10.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_11.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_12.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_13.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_14.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_15.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_16.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_17.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_18.csv',\n",
       " 'C:/Users/manas/Downloads/datasets\\\\housing\\\\my_train_19.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d53f671-1027-4684-a4e5-f99e77eb7b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ShuffleDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea7abbad-8346-482d-94fa-c1dc1c52b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_datasets_filepath:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e46242-625d-4f12-9de1-0c5bbf3f1978",
   "metadata": {},
   "source": [
    "#### Interleave()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64557b-b095-4d7b-80e0-31febc4e6bdc",
   "metadata": {},
   "source": [
    "Next, you can call the interleave() method to read from five files at a time and interleave their lines (skipping the first line of each file, which is the header row, using the skip() method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24cf8180-4d7f-4f2b-bc0b-d13092d7398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_readers = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5b92f56-4ff5-4100-b486-33ba95ec262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_datasets_filepath.interleave( lambda train_datasets_filepath: tf.data.TextLineDataset(train_datasets_filepath).skip(1),cycle_length=n_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39bc1f-2b26-497d-8f89-2e2c2d34accd",
   "metadata": {},
   "source": [
    "#### Working of Interleave()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e823bdc-42aa-49e4-8822-54fb337f6224",
   "metadata": {},
   "source": [
    "1) The interleave() method will create a dataset that will pull five file paths (using the cyle length parameter) from the filepath_dataset, and for each one it will call the function you gave it (a lambda in this example) to create a new dataset (in this case a TextLineDataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb871e-774b-4d28-b8cd-b5d490029561",
   "metadata": {},
   "source": [
    "#### This point is important and explained\n",
    "2) To be clear, at this stage there will be seven datasets in all: the train_datasets_filepath dataset, the interleave dataset, and the five TextLineDatasets created internally by the interleave dataset.\n",
    "\n",
    "#### Explanation:- \n",
    "2.i) Here although train_datasets_filepath actually contains file paths, it's still considered as a dataset.\n",
    "\n",
    "\n",
    "2.ii) Now, the interleave dataset, this is the dataset that gets created by the first 5 files that were pulled and clubbed together by TextLineDatasets, hence since this TextLineDatasets is called by the interleave, thus it's said in the above statement TextLineDatasets created internally by the interleave dataset.\n",
    "\n",
    "\n",
    "2.iii) Now the 5 TextLineDatasets, here, the n_reader is used, basically, since there are 5 files pulled out everytime, hence each file is considered as a dataset, thus 5 TextLineDatasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c5f92-f225-4208-a078-ccf7a634fa4f",
   "metadata": {},
   "source": [
    "3) When we iterate over the interleave dataset, it will cycle through these five TextLineDatasets, reading one line at a time from each until all datasets are out of items. Then it will get the next five file paths from the filepath_dataset and interleave them the same way,\r\n",
    "and so on until it runs out of file paths\n",
    "\n",
    "So in a way you can say that although in the end you get the full shuffled dataset, the actual interleave dataset is created in iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7b76892-3604-4c59-bbb9-8503e616d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in dataset:\n",
    "    # print(i)\n",
    "    c+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f10e889-1d7b-419d-b20c-d8925056d48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11610"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75cc2d5-aa3f-447d-9ffa-b5713806dea5",
   "metadata": {},
   "source": [
    "By default, interleave() does not use parallelism; it just reads one line at a time from each file, sequentially. If you want it to actually read files in parallel, you can set the num_parallel_calls argument to the number of threads you want (note that the map() method also has this argument). You can even set it to tf.data.experimental.AUTOTUNE to make TensorFlow choose the right number of threads dynamically based on the available CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b461922-d300-4b64-815e-bb317d56308d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bada5fe-b862-4ed2-9ba0-e806b353eaf3",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2857e20-f9aa-4ade-bd25-fad012e6d586",
   "metadata": {},
   "source": [
    "#### Remember at this time our data is concatenated that means the X_train and y_train are present in one single file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675826c-cd30-48b1-97a9-7c2a124b59b1",
   "metadata": {},
   "source": [
    "Now that our data is shuffled and loaded, let's pre-process this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19762f76-889e-4eb1-9be5-c5b5abcd9b7a",
   "metadata": {},
   "source": [
    "Let’s implement a small function that will perform this preprocessing:\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d2f1347-02f6-4354-8198-63c53c4e2bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.89175860e+00,  2.86245478e+01,  5.45593655e+00,  1.09963474e+00,\n",
       "        1.42428122e+03,  2.95886657e+00,  3.56464315e+01, -1.19584363e+02])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d26a0fe5-73b0-4e05-8192-504fb319c059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.90927329e+00, 1.26409177e+01, 2.55038070e+00, 4.65460128e-01,\n",
       "       1.09576000e+03, 2.36138048e+00, 2.13456672e+00, 2.00093304e+00])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca240d0d-5e32-4eb9-ab1e-bc8775ae8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42fcdedb-95fa-492f-b165-0259bd34fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    print('fields hai ',fields,'\\n\\n\\n')\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f1749-d856-40f1-b3be-54921397e6ee",
   "metadata": {},
   "source": [
    "Let’s walk through this code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656eafd-0a08-4b70-bd2a-39eac807abee",
   "metadata": {},
   "source": [
    "1) First, the function assumes that we have precomputed the mean and standard deviation of each feature in the training set. X_mean and X_std are just 1D tensors (or NumPy arrays) containing eight floats, one per input feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d8525-751d-4d88-bc1c-e1ebfd565f14",
   "metadata": {},
   "source": [
    "2) The preprocess() function takes one CSV line and starts by parsing it. For this it uses the tf.io.decode_csv() function, which takes two arguments: the first is the line to parse, and the second is an array containing the default value for each column, the defs that we created in the CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e719e25-c941-49de-8d9d-87878d83533b",
   "metadata": {},
   "source": [
    "3) This array tells TensorFlow not only the default value for each column, but also the number of columns and their types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db74be0-015e-4b80-8511-e4e55ce73c5b",
   "metadata": {},
   "source": [
    "4) In this example, we tell it that all feature columns are floats and that missing values should default to 0, this is for the first 8 columns, but we provide an empty array of type tf.float32 as the default value for the last column (the target) which is done using [tf.constant([], dtype=tf.float32)], hence we just concatenate the two lists, the [0.] * n_inputs and [tf.constant([], dtype=tf.float32)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435ced8-028a-4669-b1e1-701fceb14253",
   "metadata": {},
   "source": [
    "#### Important point\n",
    "5) The array [tf.constant([], dtype=tf.float32)] tells TensorFlow that this column contains floats, but that there is no default value, so it will raise an exception if it encounters a missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333fb3f-6df6-4066-8d00-d21e69ced903",
   "metadata": {},
   "source": [
    "6) The decode_csv() function returns a list of scalar tensors (one per column), but we need to return 1D tensor arrays. So we call tf.stack() on all tensors except for the last one (the target): this will stack these tensors into a 1D array. We then do the same for the target value (this makes it a 1D tensor array with a single value, rather than a scalar tensor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e0d2ad-37d7-4cbf-990e-584dc3a31c0a",
   "metadata": {},
   "source": [
    "7) Finally, we scale the input features by subtracting the feature means and then dividing by the feature standard deviations, and we return a tuple containing the scaled features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82709d75-4ce9-413a-9e00-7e441635e15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "944ce956-af50-4935-8bb7-bdda0309fc98",
   "metadata": {},
   "source": [
    "Let’s test this preprocessing function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "844fb55f-71c7-478c-a30c-ae5cf9e33391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fields hai  [<tf.Tensor: shape=(), dtype=float32, numpy=4.2083>, <tf.Tensor: shape=(), dtype=float32, numpy=44.0>, <tf.Tensor: shape=(), dtype=float32, numpy=5.3232>, <tf.Tensor: shape=(), dtype=float32, numpy=0.9171>, <tf.Tensor: shape=(), dtype=float32, numpy=846.0>, <tf.Tensor: shape=(), dtype=float32, numpy=2.337>, <tf.Tensor: shape=(), dtype=float32, numpy=37.47>, <tf.Tensor: shape=(), dtype=float32, numpy=-122.2>, <tf.Tensor: shape=(), dtype=float32, numpy=2.782>] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,\n",
       "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00e76f4-336e-4f5b-a7b8-2cc01af21ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cba0a7-e309-49ac-87a6-846640efc784",
   "metadata": {},
   "source": [
    "## Putting Everything Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fe07c-b64d-4f2f-91a4-328b4bbae58e",
   "metadata": {},
   "source": [
    "To make the code reusable, let’s put together everything we have discussed so far into a small helper function: it will create and return a dataset that will efficiently load California housing data from multiple CSV files, preprocess it, shuffle it, optionally repeat it, and batch it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbad20bd-dec6-48a2-b5d3-19790aa79e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,n_read_threads=None, shuffle_buffer_size=10000,n_parse_threads=5, batch_size=32):\n",
    "\n",
    "    #Below we get the list of path in a tensor\n",
    "    train_datasets_filepath = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
    "\n",
    "    # Then we read the data from those files as explained before in text line format\n",
    "    dataset = train_datasets_filepath.interleave(lambda train_datasets_filepath: tf.data.TextLineDataset(train_datasets_filepath).skip(1),cycle_length=n_readers, num_parallel_calls=n_read_threads) # Here read_threads is used because we are reading the data from the disk\n",
    "\n",
    "    # Now we call the pre-process function that we just defined to get our data in desired tensor format\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads) # Here it's parse threads because we're just parsing the already read data for processing\n",
    "\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "\n",
    "    return dataset.batch(batch_size).prefetch(1) # Prefetching is explained below, the dataset.batch just batches the entire data into the specified batches. So you have the entire data, just in 32 tensor batches which is the batch size for our case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a57ad2b-1334-4055-8cd1-afb319001254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8cf9057-84b5-45d1-a2e4-09bb6697c003",
   "metadata": {},
   "source": [
    "## Prefetching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d8318-ba94-4d98-9ade-4d6efcabb23a",
   "metadata": {},
   "source": [
    "1) By calling prefetch(1) at the end, we are creating a dataset that will do its best to always be one batch ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d6b507-e7d3-4ad6-9856-2d48c9f99e3b",
   "metadata": {},
   "source": [
    "2) In general, just prefetching one batch is fine, but in some cases you may need to prefetch a few more. Alternatively, you can let TensorFlow decide automatically by passing tf.data.experimental.AUTOTUNE (this is an experimental feature for now)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1967b-607a-403d-abf7-4b877df6e62f",
   "metadata": {},
   "source": [
    "3) In other words, while our training algorithm is working on one batch, the dataset will already be working in parallel on getting the next batch ready (e.g., reading the data from disk and preprocessing it). This can improve performance dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823f17a-3a07-4bb7-9b6e-8597b5a0ef85",
   "metadata": {},
   "source": [
    "4) If we also ensure that loading and preprocessing are multithreaded (by setting num_parallel_calls when calling interleave() and map()), we can exploit multiple cores on the CPU and hopefully make preparing one batch of data shorter than running a training step on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124ad27-0f04-42ea-a63e-07a22f147250",
   "metadata": {},
   "source": [
    "5) This way the GPU will be almost 100% utilized (except for the data transfer time from the CPU to the GPU. But check out the tf.data.experimental.prefetch_to_device() function, which can prefetch data directly to the GPU), and training will run much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8527af3a-15b3-4a9e-b2b6-14bf1b28e8f4",
   "metadata": {},
   "source": [
    "6) If the dataset is small enough to fit in memory, you can significantly speed up training by using the dataset’s cache() method to cache its content to RAM. You should generally do this after loading and preprocessing the data, but before shuffling, repeating, batching, and prefetching. This way, each instance will only be read and preprocessed once (instead of once per epoch as you've already loaded the entire data in your RAM and now you just shuffle and batch it for every epoch), but the data will still be shuffled differently at each epoch, and the next batch will still be prepared in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b6ecf-23ea-4a58-954e-fa38c239d602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f92067e-caa4-4ff0-a018-2f05a567d36b",
   "metadata": {},
   "source": [
    "### Other Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa58a24a-03cd-472a-b911-7dc8e9fe6fb4",
   "metadata": {},
   "source": [
    "There are a few more you may want to look at: concatenate(), zip(), window(), reduce(), shard(), flat_map(), and padded_batch(). There are also a couple more class methods: from_generator() and from_tensors(), which create a new dataset from a Python generator or a list of tensors, respectively. Please check the API documentation for more details. Also note that there are experimental features available in tf.data.experimental, many of which will likely make it to the core API in future releases (e.g., check out the CsvDataset class, as well as the make_csv_dataset() method, which takes care of inferring the type of each column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f86d2-1ccc-4ab9-980e-0044c1b4fcb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67412a63-d436-4680-8963-89d0315bdd35",
   "metadata": {},
   "source": [
    "## Using the Dataset with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea1630-2126-4675-8097-2b61e690985a",
   "metadata": {},
   "source": [
    "Now we can use the csv_reader_dataset() function to create a dataset for the training set. Note that we do not need to repeat it, as this will be taken care of by tf.keras. We also create datasets for the validation set and the test set:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11376858-0a9c-41a9-bdf8-68b8be3dbac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fields hai  [<tf.Tensor 'DecodeCSV:0' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:3' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:4' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:5' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:6' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:7' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:8' shape=() dtype=float32>] \n",
      "\n",
      "\n",
      "\n",
      "fields hai  [<tf.Tensor 'DecodeCSV:0' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:3' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:4' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:5' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:6' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:7' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:8' shape=() dtype=float32>] \n",
      "\n",
      "\n",
      "\n",
      "fields hai  [<tf.Tensor 'DecodeCSV:0' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:1' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:2' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:3' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:4' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:5' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:6' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:7' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV:8' shape=() dtype=float32>] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = csv_reader_dataset(train_filepaths)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14ca32f3-b473-4985-b492-82867927ef5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a7b676c-c9b2-4e0d-8889-188db7e6f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for item in train_set:\n",
    "    c+=1\n",
    "    # print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15255d5f-692f-4d51-a139-74ab016be048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e6361-5858-4a5b-9c30-9c8ac4a42c1c",
   "metadata": {},
   "source": [
    "And now we can simply build and train a Keras model using these datasets. All we need to do is pass the training and validation datasets to the fit() method, instead of X_train, y_train, X_valid, and y_valid:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fafbd1f8-ad5e-4b67-88ff-9f76d2e453c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\backend.py:277: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([ keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]), \n",
    "                                 keras.layers.Dense(1), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf946651-38ed-476d-aa32-c294e0735b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5122775a-28e9-40dc-957f-f5c0a3580553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "363/363 [==============================] - 3s 4ms/step - loss: 2.1943 - val_loss: 1.0671\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.8860 - val_loss: 0.8000\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7617 - val_loss: 0.7270\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7013 - val_loss: 0.6753\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6558 - val_loss: 0.6333\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6162 - val_loss: 0.5972\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5830 - val_loss: 0.5667\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5549 - val_loss: 0.5412\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5309 - val_loss: 0.5194\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.5114 - val_loss: 0.5016\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4950 - val_loss: 0.4868\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4811 - val_loss: 0.4745\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4703 - val_loss: 0.4648\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4608 - val_loss: 0.4559\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4526 - val_loss: 0.4489\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4465 - val_loss: 0.4429\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4407 - val_loss: 0.4379\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4360 - val_loss: 0.4332\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4319 - val_loss: 0.4292\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4281 - val_loss: 0.4256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29ae4f5a510>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(train_set,  epochs=20,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09ac4169-b272-4d93-ad5a-339a4408637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4256276488304138"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "951414a0-f618-47ac-a57a-8ab7caa494e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for k in test_set.take(3):\n",
    "    # print(k[1])\n",
    "    c=0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8d691c6-8a79-45e5-bade-1584547488bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.take(3)\n",
    "new_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f91b2012-60b4-40fb-8e4e-021d51db44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_set = test_set.take(3).map(lambda X, y: X) # Here we are basically taking the features, i.e. X and the labels i.e. y and only keeping the features i.e. X.\n",
    "# If you look at the test set, it consists of batches and each batch has two tensors, the features, i.e. X and the labels, i.e, y. Remember that X and y that\n",
    "# we are using here are just for naming in general. Now you can refer the below for loop and try printing k[0], which will give you the features tensor\n",
    "# or k[1] that will give you the label tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "200a9922-3fcf-42d7-b5ba-834001c83223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in new_set:\n",
    "    c= 0\n",
    "    # print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6badc16-a22c-472f-84bb-26faf7e8ad7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c38a572-e638-464f-9181-147eeda92380",
   "metadata": {},
   "source": [
    "## The TFRecord Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9c823d-025c-420a-bff9-6b0f28ba6cea",
   "metadata": {},
   "source": [
    "The TFRecord format is TensorFlow’s preferred format for storing large amounts of data and reading it efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b832d-d0a8-4ff7-8f78-3bdabb51281c",
   "metadata": {},
   "source": [
    "It is a very simple binary format that just contains a sequence of binary records of varying sizes (each record is comprised of a length, a CRC checksum to check that the length was not corrupted, then the actual data, and finally a CRC checksum for the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628c457b-5bfd-465a-9161-8885685dc3a8",
   "metadata": {},
   "source": [
    "You can easily create a TFRecord file using the tf.io.TFRecordWriter class:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "466ad8b6-ae70-44bb-8ca8-8d97e4151222",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second rord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aee5eb-3b2d-4372-81aa-985a875b646e",
   "metadata": {},
   "source": [
    "And you can then use a tf.data.TFRecordDataset to read one or more TFRecord files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7788f4-88fc-48fa-9ef8-d37fb9ec59b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff567084-52c2-4db2-b349-946be28c5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [\"my_data.tfrecord\"]\n",
    "dataset = tf.data.TFRecordDataset(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9fbcebe-ad7c-4070-8123-ec3632befb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91e58851-8286-4e27-9a81-c1b82a77be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
      "tf.Tensor(b'And this is the second rord', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fa6ee-6e05-4d85-b1e7-23991e4c9d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1c7009-ad98-4969-815e-811e824e488d",
   "metadata": {},
   "source": [
    "#### Note about TFRecord\n",
    "By default, a TFRecordDataset will read files one by one, but you can make it read multiple files in parallel and interleave their records by setting num_parallel_reads. Alternatively, you could obtain the same result by using list_files() and interleave() as we did earlier to read multiple CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccee159e-059e-4a98-b7c8-32f7b3fbccca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec767315-3fe3-40ef-96dd-36aa88afae46",
   "metadata": {},
   "source": [
    "## Compressed TFRecord Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41bf86-f3a6-4465-868f-e5645b276bff",
   "metadata": {},
   "source": [
    "It can sometimes be useful to compress your TFRecord files, especially if they need to be loaded via a network connection. You can create a compressed TFRecord file by setting the options argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b567b939-0572-42be-ad4c-2533b7b5ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e1182c8-6e68-4c07-a1ac-ef5bbfe9fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as myfile:\n",
    "    myfile.write('Record 1 for comp file')\n",
    "    myfile.write('Record 2 for my comp file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a7080-8e92-45f9-b120-317cf4eeef18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5451eecb-0fb6-4076-b3c8-ae3e833a9069",
   "metadata": {},
   "source": [
    "#### When reading a compressed TFRecord file, you need to specify the compression type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b733c1a-45a3-4aee-b874-52bf0d6381d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],compression_type=\"GZIP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9fbb42f-be94-48c6-9541-bb0e99d6bcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Record 1 for comp file', shape=(), dtype=string)\n",
      "tf.Tensor(b'Record 2 for my comp file', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48461b-f58b-4175-b040-ab239cd0d85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5f45d5-c944-4e88-a84f-d5e09b50b799",
   "metadata": {},
   "source": [
    "## A Brief Introduction to Protocol Buffers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812db351-f6f5-4371-b048-4177aa2afcb5",
   "metadata": {},
   "source": [
    "Even though each record can use any binary format you want, TFRecord files usually contain serialized protocol buffers (also called protobufs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d1b40-e5f9-4780-8037-55f72e770a35",
   "metadata": {},
   "source": [
    "This is a portable, extensible, and efficient binary format developed at Google back in 2001 and made open source in 2008; protobufs are now widely used, in particular in gRPC, Google’s remote procedure call system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cae6e0-87bf-4522-b395-969482b2ec2f",
   "metadata": {},
   "source": [
    "### What is Remote Procedure Call (RPC)?\r\n",
    "Remote Procedure Call (RPC) is a type of technology used in computing to enable a program to request a service from software located on another computer in a network without needing to understand the network’s details. RPC abstracts the complexities of the network by allowing the developer to think in terms of function calls rather than network details, facilitating the process of making a piece of software distributed across different systems.\r\n",
    "\r\n",
    "RPC works by allowing one program (a client) to directly call procedures (functions) on another machine (the server). The client makes a procedure call that appears to be local but is run on a remote machine. When an RPC is made, the calling arguments are packaged and transmitted across the network to the server. The server unpacks the arguments, performs the desired procedure, and sends the results back to the client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5cb658-33df-4b32-b071-17c9b351f3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b99ff6c-64bd-4c83-a710-3fe43d722126",
   "metadata": {},
   "source": [
    "They are defined using a simple language that looks like this:\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d88815-87e2-4ecf-a427-f9e1aa04674c",
   "metadata": {},
   "source": [
    "First let's write a simple protobuf definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fbb0861d-4349-40e9-84a9-a6051bb98007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "  string name = 1;\n",
    "  int32 id = 2;\n",
    "  repeated string email = 3;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfaa7f7-e6cd-4431-bd88-b95eed3728c6",
   "metadata": {},
   "source": [
    "1) This definition says we are using version 3 of the protobuf format, and it specifies that each Person object may (optionally) have a name of type string, an id of type int32, and zero or more email fields, each of type string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bb716-54b9-425b-8238-05d46b0e3bac",
   "metadata": {},
   "source": [
    "2) The numbers 1, 2, and 3 are the field identifiers: they will be used in each record’s binary representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d8770-caa6-4946-a677-76ff3bca2f84",
   "metadata": {},
   "source": [
    "3) Once you have a definition in a .proto file, you can compile it. This requires protoc, the protobuf compiler, to generate access classes in Python (or some other language).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa8b57-d84a-40be-83c4-3a3784252a62",
   "metadata": {},
   "source": [
    "4) To illustrate the basics, let’s look at a simple example that uses the access classes generated for the Person protobuf (the code is explained in the comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "090296bb-69ee-473c-9048-26a1c5760567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> from person_pb2 import Person # import the generated access class\n",
    "# >>> person = Person(name=\"Al\", id=123, email=[\"a@b.com\"]) # create a Person\n",
    "# >>> print(person) # display the Person\n",
    "# name: \"Al\"\n",
    "# id: 123\n",
    "# email: \"a@b.com\"\n",
    "# >>> person.name # read a field\n",
    "# \"Al\"\n",
    "# >>> person.name = \"Alice\" # modify a field\n",
    "# >>> person.email[0] # repeated fields can be accessed like arrays\n",
    "# \"a@b.com\"\n",
    "# >>> person.email.append(\"c@d.com\") # add an email address\n",
    "# >>> s = person.SerializeToString() # serialize the object to a byte string\n",
    "# >>> s\n",
    "# b'\\n\\x05Alice\\x10{\\x1a\\x07a@b.com\\x1a\\x07c@d.com'\n",
    "# >>> person2 = Person() # create a new Person\n",
    "# >>> person2.ParseFromString(s) # parse the byte string (27 bytes long)\n",
    "# 27\n",
    "# >>> person == person2 # now they are equal\n",
    "# True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8558e8-9453-44b0-bad0-e954ee8cc899",
   "metadata": {},
   "source": [
    "#### Code summarization\n",
    "In short, we import the Person class generated by protoc, we create an instance and play with it, visualizing it and reading and writing some fields, then we serialize it using the SerializeToString() method. This is the binary data that is ready to be saved or transmitted over the network. When reading or receiving this binary data, we can parse it using the ParseFromString() method, and we get a copy of the object that was serialized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b953cb29-b3e1-4ad7-b7a2-c6be00fd3bb5",
   "metadata": {},
   "source": [
    "### To learn more about protobufs, please visit https://homl.info/protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85bf7b-863e-457b-89a5-252839fe84d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b26b65e-96f2-494e-9cbd-1c67894f2670",
   "metadata": {},
   "source": [
    "### Important Note about SerializeToString and ParseFromString functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fef786-9d6b-4df3-8e4c-8200d265c996",
   "metadata": {},
   "source": [
    "We could save the serialized Person object to a TFRecord file, then we could load and parse it: everything would work fine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019fb77-aa9a-4943-aac2-760c9faa99d9",
   "metadata": {},
   "source": [
    "However, SerializeToString() and ParseFromString() are not TensorFlow operations (and neither are the other operations in this code), so they cannot be included in a TensorFlow Function (except by wrapping them in a tf.py_function() operation, which would make the code slower and less portable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe8550-1198-46b7-bdc9-36510c2c60c3",
   "metadata": {},
   "source": [
    "Fortunately, TensorFlow does include special protobuf definitions for which it provides parsing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14194801-4de9-41c8-9e87-2bc2a886d453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2df96aea-c5a1-454d-9327-284c280c312e",
   "metadata": {},
   "source": [
    "## TensorFlow Protobufs\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc2979-ebcf-461b-99a2-dda6ab18b94b",
   "metadata": {},
   "source": [
    "The main protobuf typically used in a TFRecord file is the Example protobuf, which represents one instance in a dataset. It contains a list of named features, where each feature can either be a list of byte strings, a list of floats, or a list of integers. Here is the protobuf definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e1406e3-723e-48ea-a2aa-96ff95f1f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message BytesList { repeated bytes value = 1; }\n",
    "message FloatList { repeated float value = 1 [packed = true]; }\n",
    "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
    "message Feature {\n",
    " oneof kind {\n",
    " BytesList bytes_list = 1;\n",
    " FloatList float_list = 2;\n",
    " Int64List int64_list = 3;\n",
    " }\n",
    "};\n",
    "message Features { map<string, Feature> feature = 1; };\n",
    "message Example { Features features = 1; };"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea6c07-24fb-455e-84ba-208325139433",
   "metadata": {},
   "source": [
    "#### Explanation of above code\n",
    "The definitions of BytesList, FloatList, and Int64List are straightforward enough. Note that [packed = true] is used for repeated numerical fields, for a more efficient encoding. A Feature contains either a BytesList, a FloatList, or an Int64List. A Features (with an s) contains a dictionary that maps a feature name to the corresponding feature value. And finally, an Example contains only a Features object(Why was Example even defined, since it contains no more than a Features object? Well, TensorFlow’s developers may one day decide to add more fields to it. As long as the new Example definition still contains the features field, with the same ID, it will be backward compatible. This extensibility is one of the great features of protobufs.). Here is how you could create a tf.train.Example representing the same person as earlier and write it to a TFRecord file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70586ad9-4259-4af7-af1b-8364dd94319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "732abe0f-0356-41cd-8b79-20f61601223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_example = Example(\n",
    " features=Features(\n",
    " feature={\n",
    " \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\"id\": Feature(int64_list=Int64List(value=[123])),\n",
    " \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\",\n",
    " b\"c@d.com\"]))\n",
    " }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8843de-3e8c-42df-9abc-24015fcd215d",
   "metadata": {},
   "source": [
    "Now that we have an Example protobuf, we can serialize it by calling its SerializeToString() method, then write the resulting data to a TFRecord file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0f6d507-27e3-49fc-bc6e-8a6953bbb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10bde4-a8d6-40ff-841b-1cc654ab585a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfa0d680-5379-41dc-a8f4-0c371be0b90a",
   "metadata": {},
   "source": [
    "#### Important!!\n",
    "\n",
    "Normally you would write much more than one Example! Typically, you would create a conversion script that reads from your current format (say, CSV files), creates an Example protobuf for each instance, serializes them, and saves them to several TFRecord files, ideally shuffling them in the process. This requires a bit of work, so once again make sure it is really necessary (perhaps your pipeline works fine with CSV files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007ee61-7a80-4074-ab70-2ac1e6f03de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb75a5f9-9c19-4d27-8b06-844874365635",
   "metadata": {},
   "source": [
    "#### Now that we have a nice TFRecord file containing a serialized Example, let’s try to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdff70fa-e6d1-464d-a2e3-10dea9ba4074",
   "metadata": {},
   "source": [
    "## Loading and Parsing Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475cf2fa-ea02-4115-8b4c-85a89fa9cc6b",
   "metadata": {},
   "source": [
    "1) To load the serialized Example protobufs, we will use a tf.data.TFRecordDataset once again, and we will parse each Example using tf.io.parse_single_example(). This is a TensorFlow operation, so it can be included in a TF Function. It requires at least two arguments: a string scalar tensor containing the serialized data, and a description of each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cb27a-7f0d-4251-9df8-ce30da2eb352",
   "metadata": {},
   "source": [
    "2) The description is a dictionary that maps each feature name to either a tf.io.FixedLenFeature descriptor indicating the feature’s shape, type, and default value, or a tf.io.VarLenFeature descriptor indicating only the type (if the length of the feature’s list may vary, such as for the \"emails\" feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e7b27-80c5-4834-aa53-e532432f221b",
   "metadata": {},
   "source": [
    "The following code defines a description dictionary, then it iterates over the TFRecord Dataset and parses the serialized Example protobuf this dataset contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ee93945-afd9-4db5-a6ab-d47733258d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    " \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    " \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    " \"emails\": tf.io.VarLenFeature(tf.string),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2de37c35-4722-49e7-ab37-28cff273aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
    "    parsed_example = tf.io.parse_single_example(serialized_example,feature_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c3c26-1623-4f7f-a1e4-2cfbc2be2c0a",
   "metadata": {},
   "source": [
    "The fixed-length features are parsed as regular tensors, but the variable-length features are parsed as sparse tensors. You can convert a sparse tensor to a dense tensor using tf.sparse.to_dense(), but in this case it is simpler to just access its values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21670dd5-c5a0-4efa-8e06-fb13db73a2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4f0730c-a1de-43b8-992e-1d281660375d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_example[\"emails\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814ab04-061c-46a5-b82a-a80312dccef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c31aaca6-ebcd-4a79-90ff-f08c71ebc463",
   "metadata": {},
   "source": [
    "### Important Note about ByteList and tf.parser!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "A BytesList can contain any binary data you want, including any serialized object. For example, you can use tf.io.encode_jpeg() to encode an image using the JPEG format and put this binary data in a BytesList. Later, when your code reads the TFRecord, it will start by parsing the Example, then it will need to call tf.io.decode_jpeg() to parse the data and get the original image (or you can use tf.io.decode_image(), which can decode any BMP, GIF, JPEG, or PNG image). You can also store any tensor you want in a BytesList by serializing the tensor using tf.io.serialize_tensor() then putting the resulting byte string in a BytesList feature. Later, when you parse the TFRecord, you can parse this data using tf.io.parse_tensor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39831ab0-82c6-436a-bbfc-f5d80b0ee53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38be5d98-a25c-40cc-9669-b2c46fd2e69e",
   "metadata": {},
   "source": [
    "Instead of parsing examples one by one using tf.io.parse_single_example(), you may want to parse them batch by batch using tf.io.parse_example():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "507a5296-55be-4cea-86a1-11bd5497381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ea51916-fe42-47fe-9d40-ec99663d7133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'\\n@\\n\\x11\\n\\x04name\\x12\\t\\n\\x07\\n\\x05Alice\\n\\x1e\\n\\x06emails\\x12\\x14\\n\\x12\\n\\x07a@b.com\\n\\x07c@d.com\\n\\x0b\\n\\x02id\\x12\\x05\\x1a\\x03\\n\\x01{'], shape=(1,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for j in dataset:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "39486e00-a9cd-4b71-97df-0ba924cdaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for serialized_examples in dataset:\n",
    "    parsed_examples = tf.io.parse_example(serialized_examples,feature_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0743c026-c4f9-45a2-969a-d5963d74b8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emails': SparseTensor(indices=tf.Tensor(\n",
       " [[0 0]\n",
       "  [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([b'a@b.com' b'c@d.com'], shape=(2,), dtype=string), dense_shape=tf.Tensor([1 2], shape=(2,), dtype=int64)),\n",
       " 'id': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([123], dtype=int64)>,\n",
       " 'name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Alice'], dtype=object)>}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a04dc8-bd77-487f-a5d5-5f59a14fa8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23e12bba-46e2-4ec1-a07c-ef192f470cf7",
   "metadata": {},
   "source": [
    "## SequenceExample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c71504b-54d9-4f01-8c9b-8769e3b86f62",
   "metadata": {},
   "source": [
    "As you can see, the Example protobuf will probably be sufficient for most use cases. However, it may be a bit cumbersome to use when you are dealing with lists of lists. For example, suppose you want to classify text documents. Each document may be represented as a list of sentences, where each sentence is represented as a list of words. And perhaps each document also has a list of comments, where each comment is represented as a list of words. There may be some contextual data too, such as the document’s author, title, and publication date. TensorFlow’s SequenceExample protobuf is designed for such use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f85311-1494-4808-802f-8869cb99e33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b76d312b-2d0a-4ab7-a8f6-2aea05d71996",
   "metadata": {},
   "source": [
    "### Handling Lists of Lists Using the SequenceExample Protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8553c4-5cc8-4394-9412-dcc1f3c481a7",
   "metadata": {},
   "source": [
    "Here is the definition of the SequenceExample protobuf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0728fad3-989e-4cb3-8fd7-a05cd9894f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sequence_exmp.proto\n"
     ]
    }
   ],
   "source": [
    "%%writefile sequence_exmp.proto\n",
    "message FeatureList { repeated Feature feature = 1; };\n",
    "message FeatureLists { map<string, FeatureList> feature_list = 1; };\n",
    "message SequenceExample {\n",
    " Features context = 1;\n",
    " FeatureLists feature_lists = 2;\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525aa93-4ba2-4781-bc35-558ff16d22ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18496b42-21c7-4a07-b0c1-2bb77540bae8",
   "metadata": {},
   "source": [
    "1) A SequenceExample contains a Features object for the contextual data and a FeatureLists object that contains one or more named FeatureList objects (e.g., a FeatureList named \"content\" and another named \"comments\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e250824-6317-4172-a4ee-ae67ffdc4f88",
   "metadata": {},
   "source": [
    "2) Each FeatureList contains a list of Feature objects, each of which may be a list of byte strings, a list of 64-bit integers, or a list of floats (in this example, each Feature would represent a sentence or a comment, perhaps in the form of a list of word identifiers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc84df01-0b64-4dd2-8422-b1a0adc55e08",
   "metadata": {},
   "source": [
    "3) Building a SequenceExample, serializing it, and parsing it is similar to building, serializing, and parsing an Example, but you must use tf.io.parse_single_sequence_example() to parse a single SequenceExample or tf.io.parse_sequence_example() to parse a batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb10a8-9920-4b8c-b906-5fc5e9b22ed9",
   "metadata": {},
   "source": [
    "4) Both functions return a tuple containing the context features (as a dictionary) and the feature lists (also as a dictionary). If the feature lists contain sequences of varying sizes (as in the preceding example), you may want to convert them to ragged tensors, using tf.RaggedTensor.from_sparse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfb631-8396-4b13-b2f1-1365f353b0b7",
   "metadata": {},
   "source": [
    "#### Below we will see the example of working with sequenceExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "56d7fa1d-3303-40a8-80b4-d727064f8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureList = tf.train.FeatureList\n",
    "FeatureLists = tf.train.FeatureLists\n",
    "SequenceExample = tf.train.SequenceExample\n",
    "\n",
    "context = Features(feature={\n",
    "    \"author_id\": Feature(int64_list=Int64List(value=[123])),\n",
    "    \"title\": Feature(bytes_list=BytesList(value=[b\"A\", b\"desert\", b\"place\", b\".\"])),\n",
    "    \"pub_date\": Feature(int64_list=Int64List(value=[1623, 12, 25]))\n",
    "})\n",
    "\n",
    "content = [[\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"],\n",
    "           [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"]]\n",
    "comments = [[\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"],\n",
    "            [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"]]\n",
    "\n",
    "def words_to_feature(words):\n",
    "    return Feature(bytes_list=BytesList(value=[word.encode(\"utf-8\")\n",
    "                                               for word in words]))\n",
    "\n",
    "content_features = [words_to_feature(sentence) for sentence in content]\n",
    "comments_features = [words_to_feature(comment) for comment in comments]\n",
    "            \n",
    "sequence_example = SequenceExample(\n",
    "    context=context,\n",
    "    feature_lists=FeatureLists(feature_list={\n",
    "        \"content\": FeatureList(feature=content_features),\n",
    "        \"comments\": FeatureList(feature=comments_features)\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b129c7aa-9550-4d52-86a4-16caccee3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "serialized_sequence_example = sequence_example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c1189d3-8564-45b5-954e-bcbee15ae3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature_descriptions = {\n",
    "    \"author_id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"title\": tf.io.VarLenFeature(tf.string),\n",
    "    \"pub_date\": tf.io.FixedLenFeature([3], tf.int64, default_value=[0, 0, 0]),\n",
    "}\n",
    "sequence_feature_descriptions = {\n",
    "    \"content\": tf.io.VarLenFeature(tf.string),\n",
    "    \"comments\": tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
    "    serialized_sequence_example, context_feature_descriptions,\n",
    "    sequence_feature_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738113a8-e98c-4fa3-bf96-72dd946b8d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea7b8d93-fda4-4e02-b732-da1e67628ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
    " serialized_sequence_example, context_feature_descriptions,\n",
    " sequence_feature_descriptions)\n",
    "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba6c6816-5993-419b-863c-7092be3184d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': SparseTensor(indices=tf.Tensor(\n",
       " [[0]\n",
       "  [1]\n",
       "  [2]\n",
       "  [3]], shape=(4, 1), dtype=int64), values=tf.Tensor([b'A' b'desert' b'place' b'.'], shape=(4,), dtype=string), dense_shape=tf.Tensor([4], shape=(1,), dtype=int64)),\n",
       " 'author_id': <tf.Tensor: shape=(), dtype=int64, numpy=123>,\n",
       " 'pub_date': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1623,   12,   25], dtype=int64)>}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parsed_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "132978d0-2809-488b-bb2a-227401bf6238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[b'When', b'shall', b'we', b'three', b'meet', b'again', b'?'],\n",
      " [b'In', b'thunder', b',', b'lightning', b',', b'or', b'in', b'rain', b'?']]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b049c9d-0843-4a4b-9f3d-e1f2be8e9882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45117e-5323-41fd-9d68-4cccd1a0883e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53174547-1853-4883-90ef-517351a0c646",
   "metadata": {},
   "source": [
    "## Preprocessing the Input Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9db0a2-9c1c-40d3-a42c-6534833911c4",
   "metadata": {},
   "source": [
    "Preparing your data for a neural network requires converting all features into numerical features, generally normalizing them, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b40289-461f-4ef6-bc4c-0f97a01106d4",
   "metadata": {},
   "source": [
    "In particular, if your data contains categorical features or text features, they need to be converted to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086a0f6-f848-4ce9-8dca-661afcf55a10",
   "metadata": {},
   "source": [
    "This can be done ahead of time when preparing your data files, using any tool you like (e.g., NumPy, pandas, or Scikit-Learn)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b140afb-05af-4cbc-9837-9a2b69e7560d",
   "metadata": {},
   "source": [
    "Alternatively, you can preprocess your data on the fly when loading it with the Data API (e.g., using the dataset’s map() method, as we saw earlier), or you can include a preprocessing layer directly in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37129ca3-e356-4501-904b-ef57f9f4e1ac",
   "metadata": {},
   "source": [
    "Let’s look at this last option now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e56c9c2-6a25-41df-a1d9-1161473ba22e",
   "metadata": {},
   "source": [
    "For example, here is how you can implement a standardization layer using a Lambda layer. For each feature, it subtracts the mean and divides by its standard deviation (plus a tiny smoothing term to avoid division by zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ea415b6-197e-4c7d-8bd9-87b19d95b633",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.mean(X_train, axis=0, keepdims=True)\n",
    "stds = np.std(X_train, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "59ee5850-55fc-4d4b-8b5b-907bc82791b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = keras.backend.epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f181d237-2d5b-4923-ad0e-3f07226c8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([keras.layers.Lambda(lambda inputs: (inputs - means) / (stds + eps))\n",
    "                                 ### [Other layers]\n",
    "                                ])\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbd778c-70b5-4f15-8369-b8573448a90a",
   "metadata": {},
   "source": [
    "However, you may prefer to use a nice self-contained custom layer (much like Scikit-Learn’s StandardScaler), rather than having global variables like means and stds dangling around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c3941670-1847-4df7-bb10-a0fd51dc79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dae06e-34c4-4092-98a0-22dd05e2c2a5",
   "metadata": {},
   "source": [
    "####  IMPORTANT POINT!!!!!!\n",
    "#### Before you can use this standardization layer, you will need to adapt it to your dataset by calling the adapt() method and passing it a data sample. This will allow it to use the appropriate mean and standard deviation for each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "760a88d2-45b3-49e4-ba6c-a759c9384c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7b5b6018-4ee8-4f7b-8964-be80d5f97339",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68af42a8-8b73-4520-9ec0-b910ad7b6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72ecf162-7d38-4cf4-b3ec-65c3226a6f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    #image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a83773e-6662-4bb5-a993-ea701d9ef21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dd90c9e0-0ee2-48e7-af90-be1cab3e510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_layer = Standardization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9769d177-7b59-49f9-8d1c-f27178dedfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "# sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "#                                axis=0).astype(np.float32)\n",
    "# std_layer.adapt(sample_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1417a9-9de7-4f53-a6cc-f2dab9cff416",
   "metadata": {},
   "source": [
    "This sample must be large enough to be representative of your dataset, but it does not have to be the full training set: in general, a few hundred randomly selected instances will suffice (however, this depends on your task). Next, you can use this preprocessing layer like a normal layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "95ec65ea-9853-447a-ba80-6052d38836c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    std_layer,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d65d1-fa86-484b-8712-560a4c02cd8d",
   "metadata": {},
   "source": [
    "If you are thinking that Keras should contain a standardization layer like this one the keras.layers.Normalization works very much like our custom Standardization layer: first, create the layer, then adapt it to your dataset by passing\r\n",
    "a data sample to the adapt() method, and finally use the layer normally For adapt example see https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3285dd7e-6ea4-4de2-bd87-caa7d7392730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardization = keras.layers.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c13fa-cc2d-4109-abdc-6163b6ad5897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45918b53-9cd5-4464-99cd-ad2763af54c9",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features Using One-Hot Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651dddf-8dd2-4507-95a3-edb8ef9751bb",
   "metadata": {},
   "source": [
    "Now let’s look at categorical features. We will start by encoding them as one-hot vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3958f28f-2498-4cee-b18a-7e32791c8f47",
   "metadata": {},
   "source": [
    "Consider the ocean_proximity feature in the California housing dataset we explored in Chapter 2: it is a categorical feature with five possible values: \"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", and \"ISLAND\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530d4f7-3f3c-47d2-b603-38439e99d79c",
   "metadata": {},
   "source": [
    "We need to encode this feature before we feed it to a neural network. Since there are very few categories, we can use one-hot encoding. For this, we first need to map each category to its index (0 to 4), which can be done using a lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "80d639ed-d676-4f98-b30f-c251408f5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a2b1d14-0a34-4df2-8255-8619bb6a3f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 2, 3, 4], dtype=int64)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d9eaeeaa-f940-4ce7-afe8-97c381249f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.KeyValueTensorInitializer at 0x29ae4f14810>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "table_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6a79b41-b11f-4b40-975f-411f0f7eda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_oov_buckets = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c0358d9f-5f72-41c3-b161-ab1b9d372b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6919b427-7323-49c3-924f-42699b72b2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.lookup_ops.StaticVocabularyTable at 0x29ae853c910>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d71f1-e9a5-42e4-b843-e8618baf5650",
   "metadata": {},
   "source": [
    "#### Let’s go through this code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671e1a2-e11f-42b7-bf73-da13f6a2a5f7",
   "metadata": {},
   "source": [
    "1) We first define the vocabulary: this is the list of all possible categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bf3ad-2168-4200-bdab-d4eb50ee3ace",
   "metadata": {},
   "source": [
    "2) Then we create a tensor with the corresponding indices (0 to 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25305e9-cba1-4270-ba72-e768c281c760",
   "metadata": {},
   "source": [
    "#### Important Point!!!\n",
    "\n",
    "3) Next, we create an initializer for the lookup table, passing it the list of categories and their corresponding indices. In this example, we already have this data, so we use a KeyValueTensorInitializer; but if the categories were listed in a text file (with one category per line), we would use a TextFileInitializer instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176b351-151e-4724-b3a5-bb54adb4a3fb",
   "metadata": {},
   "source": [
    "4) In the last two lines we create the lookup table, giving it the initializer and specifying the number of out-of-vocabulary (oov) buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af032534-fb0a-4b4c-92db-b8b4bab74cb6",
   "metadata": {},
   "source": [
    "#### Important Point!!!\n",
    "If we look up a category that does not exist in the vocabulary, the lookup table will compute a hash of this category and use it to assign the unknown category to one of the oov buckets. Their indices start after the known categories, so in this example the indices of the two oov buckets are 5 and 6. So what this means is that the new category can either be assigned at index 5 or 6, the index here is being considered as bucket. It depends on the lookup table. \n",
    "\n",
    "#### In the below example of categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\",\"HAWAII\"]), there are two new values, and hence one got assigned to index 5 and other to index 6 as per our num_oov_value parameter.\n",
    "\n",
    "#### However, if we use categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\",\"HAWAII\",\"BALI\"]), then both Hawaii and bali got assigned to index 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed345f6e-3584-4873-adc2-977ee5c25062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4260e6c-843f-4c82-9b8e-6bf8300f5b2f",
   "metadata": {},
   "source": [
    "### oov buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c10ceeb-016d-4d1c-b8ce-6a969632336b",
   "metadata": {},
   "source": [
    "Why use oov buckets? Well, if the number of categories is large (e.g., zip codes, cities, words, products, or users) and the dataset is large as well, or it keeps changing, then getting the full list of categories may not be convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d78acd-579a-4230-a22e-502f746fe1ed",
   "metadata": {},
   "source": [
    "One solution is to define the vocabulary based on a data sample (rather than the whole training set) and add some oov buckets for the other categories that were not in the data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a0b27f-f966-4441-a347-d8a827b491fa",
   "metadata": {},
   "source": [
    "The more unknown categories you expect to find during training, the more oov buckets you should use. Indeed, if there are not enough oov buckets, there will be collisions: different categories will end up in the same bucket, so the neural network will not be able to distinguish them (at least not based on this feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a25e28-5118-4b24-9ef6-39bdfe6d9428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d341f24d-5c8e-4d4a-912a-e0f09ef4e5dc",
   "metadata": {},
   "source": [
    "Now let’s use the lookup table to encode a small batch of categorical features to onehot vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f351b521-efd4-49e6-ad96-ed4ffe9d88a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=string, numpy=\n",
       "array([b'NEAR BAY', b'DESERT', b'INLAND', b'INLAND', b'HAWAII', b'BALI'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\",\"HAWAII\",\"BALI\"])\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d2ec3f7-81b8-44d5-9bae-853a30442675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'NEAR BAY', shape=(), dtype=string)\n",
      "tf.Tensor(b'DESERT', shape=(), dtype=string)\n",
      "tf.Tensor(b'INLAND', shape=(), dtype=string)\n",
      "tf.Tensor(b'INLAND', shape=(), dtype=string)\n",
      "tf.Tensor(b'HAWAII', shape=(), dtype=string)\n",
      "tf.Tensor(b'BALI', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for j in categories:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3f4fff44-4732-4632-a087-8b57f40b0374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int64, numpy=array([3, 5, 1, 1, 6, 6], dtype=int64)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7bc4cc5c-dfe2-4231-a24e-227828603c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
    "cat_one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876731af-f8ef-458a-b20d-5c68a67983a2",
   "metadata": {},
   "source": [
    "As you can see, \"NEAR BAY\" was mapped to index 3, the unknown category \"DESERT\" was mapped to one of the two oov buckets (at index 5), and \"INLAND\" was mapped to index 1, twice and HAWAII got mapped to index 6. Then we used tf.one_hot() to one-hot encode these indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a549bb6d-11d2-4c65-a4f1-98fd082e69b9",
   "metadata": {},
   "source": [
    "Notice that we have to tell this function the total number of indices, which is equal to the vocabulary size plus the number of oov buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57953b20-b365-4331-835f-b4da44eee470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ca8a2-a9c0-4cfc-9072-c4b426e37591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0010280b-5add-4594-884d-476814b92421",
   "metadata": {},
   "source": [
    "### Creating the Pipeline, Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f15a7-3190-4164-9479-9d5aaabc5ba9",
   "metadata": {},
   "source": [
    "1) Just like earlier, it wouldn’t be too difficult to bundle all of this logic into a nice selfcontained class. Its adapt() method would take a data sample and extract all the distinct categories it contains. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb4723-b633-4f87-8a5a-bc92feae9a2d",
   "metadata": {},
   "source": [
    "2) It would create a lookup table to map each category to its index (including unknown categories using oov buckets). Then its call() method would use the lookup table to map the input categories to their indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25125857-5fbf-4429-8670-a2b7aaceadbc",
   "metadata": {},
   "source": [
    "3) Keras has a layer called keras.layers.TextVectorization, which will be capable of doing exactly that: its adapt() method will extract the vocabulary from a data sample, and its call() method will convert each category to its index in the vocabulary. For adapt method see https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed3155c-ea2a-45ff-a871-e5013554bbf6",
   "metadata": {},
   "source": [
    "4) You could add this layer at the beginning of your model, followed by a Lambda layer that would apply the tf.one_hot() function, if you want to convert these indices to one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3343bf1c-1201-474d-aced-296bc81f4665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.src.layers.preprocessing.text_vectorization.TextVectorization"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898044d8-575b-4409-b0cc-5c13ddbba58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "852a415c-0c05-4b22-86c5-7ae3338a803c",
   "metadata": {},
   "source": [
    "### IMPORTANT POINT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "As a rule of thumb, if the number of categories is lower than 10, then one-hot encoding is generally the way to go (but your mileage may vary!). If the number of categories is greater than 50 (which is often the case when you use hash buckets), then embeddings are usually preferable. In between 10 and 50 categories, you may want to experiment with both options and see which one works best for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f13712-daed-4402-b9e3-41256dbfdc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d44aea84-4d57-459b-ba39-aa8b005f1756",
   "metadata": {},
   "source": [
    "## IMPORTANT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Encoding Categorical Features Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef5f12-2af6-4e5a-95b4-28a48682923b",
   "metadata": {},
   "source": [
    "An embedding is a trainable dense vector that represents a category. By default, embeddings are initialized randomly, so for example the \"NEAR BAY\" category could be represented initially by a random vector such as [0.131, 0.890]. while the \"NEAR OCEAN\" category might be represented by another random vector such as [0.631,0.791]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c18d-40e5-4f12-a016-e8fcb501c122",
   "metadata": {},
   "source": [
    "In this example, we use 2D embeddings, but the number of dimensions is a hyperparameter you can tweak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18e4a3-3967-4ddb-ae62-f869d403d987",
   "metadata": {},
   "source": [
    "#### IMPORTANT POINT !!!!!!!!!!!\n",
    "Since these embeddings of \"NEAR BAY\" and \"NEAR OCEAN\" are trainable, they will gradually improve during training; and as they represent fairly similar categories, Gradient Descent will certainly end up pushing them closer together, while it will tend to move them away from the \"INLAND\" category’s embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d4415-d95c-47ce-a5a3-2928332ee5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d8e781c-8263-47e5-a0ed-48c164788235",
   "metadata": {},
   "source": [
    "### Representation learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d60fc1-171f-4316-a577-89382a8f46f3",
   "metadata": {},
   "source": [
    "The better the representation, the easier it will be for the neural network to make accurate predictions, so training tends to make embeddings useful representations of the categories. This is called representation learning.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb455f2-db59-49ec-9545-1c4bd0117670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf295934-3302-4351-9819-04ca8a9be73c",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5ce8c-bc3b-43ed-be50-330c1061093e",
   "metadata": {},
   "source": [
    "Not only will embeddings generally be useful representations for the task at hand, but quite often these same embeddings can be reused successfully for other tasks. The most common example of this is word embeddings (i.e., embeddings of individual words): when you are working on a natural language processing task, you are often better off reusing pretrained word embeddings than training your own, i.e. good vector representations of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91a2c8-5594-48fe-b968-9b5b5b29d1a4",
   "metadata": {},
   "source": [
    "The idea of using vectors to represent words dates back to the 1960s, and many sophisticated techniques have been used to generate useful vectors, including using neural networks. But things really took off in 2013, when Tomáš Mikolov and other Google researchers published a paper describing an efficient technique to learn word embeddings using neural networks, significantly outperforming previous attempts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0133db-eee5-41f8-a444-2308197fbbce",
   "metadata": {},
   "source": [
    "This allowed them to get embeddings on a very large corpus of text: they trained a neural network to predict the words near any given word, and obtained astounding word embeddings. For example, synonyms had very close embeddings, and semantically related words such as France, Spain, and Italy ended up clustered together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03fc41-feb3-44fc-8701-ef18f8db9744",
   "metadata": {},
   "source": [
    "It’s not just about proximity, though: word embeddings were also organized along meaningful axes in the embedding space. Here is a famous example: if you compute King – Man + Woman (adding and subtracting the embedding vectors of these words), then the result will be very close to the embedding of the word Queen. In other words, the word embeddings encode the concept of gender!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb191b-3185-4050-a11a-a8ef505fd811",
   "metadata": {},
   "source": [
    "Similarly, you can compute Madrid – Spain + France, and the result is close to Paris, which seems to show that the notion of capital city was also encoded in the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddcecd6-ba47-4f55-93aa-bbf0ff937d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20ec7dc3-7ed6-4d9f-a553-d5eb7f623ba9",
   "metadata": {},
   "source": [
    "## Implementing Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1457c-bec6-4bb3-8d82-91ea24489679",
   "metadata": {},
   "source": [
    "Let’s look at how we could implement embeddings manually, to understand how they work (then we will use a simple Keras layer instead). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ce7ca-aabe-43b9-ac33-6ed5f9d3e34a",
   "metadata": {},
   "source": [
    "1) First, we need to create an embedding matrix containing each category’s embedding, initialized randomly; it will have one row per category and per oov bucket, and one column per embedding dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "15ddfabf-693f-42ff-bb69-0ea38891ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ec4a9864-33c0-4f2c-89c6-1ac157559044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 2), dtype=float32, numpy=\n",
       "array([[0.7413678 , 0.62854624],\n",
       "       [0.01738465, 0.3431449 ],\n",
       "       [0.51063764, 0.3777541 ],\n",
       "       [0.07321596, 0.02137029],\n",
       "       [0.2871771 , 0.4710616 ],\n",
       "       [0.6936141 , 0.07321334],\n",
       "       [0.93251204, 0.20843053]], dtype=float32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
    "embed_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bfc9a21f-55d9-4630-b12f-2910a90e7c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.7413678 , 0.62854624],\n",
       "       [0.01738465, 0.3431449 ],\n",
       "       [0.51063764, 0.3777541 ],\n",
       "       [0.07321596, 0.02137029],\n",
       "       [0.2871771 , 0.4710616 ],\n",
       "       [0.6936141 , 0.07321334],\n",
       "       [0.93251204, 0.20843053]], dtype=float32)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = tf.Variable(embed_init)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4347d-a4a6-4e56-a7d3-a103a98a644d",
   "metadata": {},
   "source": [
    "In this example we are using 2D embeddings, but as a rule of thumb embeddings typically have 10 to 300 dimensions, depending on the task and the vocabulary size (you will have to tune this hyperparameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32915bc4-f9b6-424b-8857-776916a8f937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fade8c4-b0b5-4b87-9b80-6cbf8671110c",
   "metadata": {},
   "source": [
    "2) This embedding matrix is a random 6 × 2 matrix, stored in a variable (so it can be\r\n",
    "tweaked by Gradient Descent during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "dda2d582-3267-4ac2-8b53-d8ba7e444798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.7413678 , 0.62854624],\n",
       "       [0.01738465, 0.3431449 ],\n",
       "       [0.51063764, 0.3777541 ],\n",
       "       [0.07321596, 0.02137029],\n",
       "       [0.2871771 , 0.4710616 ],\n",
       "       [0.6936141 , 0.07321334],\n",
       "       [0.93251204, 0.20843053]], dtype=float32)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3a687-b28f-4b7b-855b-ef6067bf76e6",
   "metadata": {},
   "source": [
    "3) Now let’s encode the same batch of categorical features as earlier, but this time using these embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9dd901f1-ce25-42ac-a568-f2d125f8174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "57965dd0-b9e8-49bb-a7c1-3527a715648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1d293b3b-6eac-440e-ad7b-ec92d162c83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.07321596, 0.02137029],\n",
       "       [0.6936141 , 0.07321334],\n",
       "       [0.01738465, 0.3431449 ],\n",
       "       [0.01738465, 0.3431449 ]], dtype=float32)>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81b54f2-a85c-4f00-993a-a508c01d8c32",
   "metadata": {},
   "source": [
    "The tf.nn.embedding_lookup() function looks up the rows in the embedding matrix, at the given indices—that’s all it does. For example, the lookup table says that the \"INLAND\" category is at index 1, so the tf.nn.embedding_lookup() function returns the embedding at row 1 in the embedding matrix (twice): [0.3528825, 0.46448255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09929b-b1d9-48f1-957d-d11ce9e2da5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52999ad8-e8c6-4fa9-a01e-0b377320651c",
   "metadata": {},
   "source": [
    "### keras.layers.Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af471c1-40cf-4ff6-acdb-e1506936002a",
   "metadata": {},
   "source": [
    "Keras provides a keras.layers.Embedding layer that handles the embedding matrix (trainable, by default); when the layer is created it initializes the embedding matrix randomly, and then when it is called with some category indices it returns the rows at those indices in the embedding matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3483b2e2-2a76-4281-a8af-acd0e0f81dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x29ae8578a90>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets, output_dim=embedding_dim)\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "44e7337c-3544-4233-80ae-22549933197b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[ 0.04739643,  0.02759985],\n",
       "       [ 0.04873708,  0.02481348],\n",
       "       [-0.01103915,  0.01602587],\n",
       "       [-0.01103915,  0.01602587]], dtype=float32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5637590-3faa-41a4-aa36-a883ebf7e101",
   "metadata": {},
   "source": [
    "#### Creating the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05df048-cbdf-46d8-a466-8c3c6865ac3c",
   "metadata": {},
   "source": [
    "4) Putting everything together, we can now create a Keras model that can process categorical features (along with regular numerical features) and learn an embedding for each category (as well as for each oov bucket):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b07fc973-4875-4852-8aa1-4313a7495e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_inputs = keras.layers.Input(shape=[8]) # First Input\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string) # Second Input\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
    " outputs=[outputs ]) # The encoded inputs are passed into the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c948471-443f-4572-a866-d5cc88508f97",
   "metadata": {},
   "source": [
    "#### Explanation of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6849c6-d4b6-4b3b-b107-aa05fa7eac7f",
   "metadata": {},
   "source": [
    "This model takes two inputs: a regular input containing eight numerical features per instance, plus a categorical input (containing one categorical feature per instance). It uses a Lambda layer to look up each category’s index, then it looks up the embeddings for these indices. Next, it concatenates the embeddings and the regular inputs in order to give the encoded inputs, which are ready to be fed to a neural network. We could add any kind of neural network at this point, but we just add a dense output layer, and we create the Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c858d3-5410-4eaa-a03f-c25236391f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "179bd577-2892-4802-a7e4-21721949e269",
   "metadata": {},
   "source": [
    "### keras.layers.TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464c7b4-9b5e-4a20-ac76-196822fb1e31",
   "metadata": {},
   "source": [
    "With keras.layers.TextVectorization you can call its adapt() method to make it extract the vocabulary from a data sample (it will take care of creating the lookup table for you). Then you can add it to your model, and it will perform the index lookup (replacing the Lambda layer in the previous code example). For adapt example see https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843dda7-bf1f-43fa-a0fd-c904ea0807ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd9942c9-2253-4534-bc2f-5bda85c67c1b",
   "metadata": {},
   "source": [
    "### Important Tip\n",
    "One-hot encoding followed by a Dense layer (with no activation function and no biases) is equivalent to an Embedding layer. However, the Embedding layer uses way fewer computations (the performance difference becomes clear when the size of the embedding matrix grows). The Dense layer’s weight matrix plays the role of the embedding matrix. For example, using one-hot vectors of size 20 and a Dense layer with 10 units is equivalent to using an Embedding layer with input_dim=20 and output_dim=10. As a result, it would be wasteful to use more embedding dimensions than the number of units in the layer that follows the Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329351b-405c-43f5-8994-6d8dc0005e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6e683e2-07f8-420d-bc58-a60668188fef",
   "metadata": {},
   "source": [
    "## Keras Preprocessing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728371f7-cd47-4d28-be23-d0607f6773e3",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/governance/blob/master/rfcs/20190502-preprocessing-layers.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530b175-2be0-46c0-bc88-5ad15e856ffe",
   "metadata": {},
   "source": [
    "TensorFlow provides a set of standard Keras preprocessing layers. We already discussed two of these layers: the keras.layers.Normalization layer that will perform feature standardization (it will be equivalent to the Standardization layer we defined earlier), and the TextVectorization layer that will be capable of encoding each word in the inputs into its index in the vocabulary. In both cases, you create the layer, you call its adapt() method with a data sample, and then you use the layer normally in your model. The other preprocessing layers will follow the same pattern.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241c867e-564c-4949-a559-ee254cb57d7a",
   "metadata": {},
   "source": [
    "The API will also include a keras.layers.Discretization layer that will chop continuous data into different bins and encode each bin as a one-hot vector. For example, you could use it to discretize prices into three categories, (low, medium, high), which would be encoded as [1, 0, 0], [0, 1, 0], and [0, 0, 1], respectively. Of course this loses a lot of information, but in some cases it can help the model detect patterns that would otherwise not be obvious when just looking at the continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8992ff9-daa9-4424-ae4a-eb639ecbc72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5ecf67f-6ddc-4c1c-baba-89991700178c",
   "metadata": {},
   "source": [
    "### WARNING!!!!\n",
    "The Discretization layer will not be differentiable, and it should only be used at the start of your model. Indeed, the model’s preprocessing layers will be frozen during training, so their parameters will not be affected by Gradient Descent, and thus they do not need to be differentiable. This also means that you should not use an Embedding layer directly in a custom preprocessing layer, if you want it to be trainable: instead, it should be added separately to your model, as in the previous code example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824f5c6-08dc-409e-b989-f26451e3d4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b126eee3-5bb1-4165-9c27-544a595533d7",
   "metadata": {},
   "source": [
    "#### PreprocessingStage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454eeac2-48b5-4cbf-8b2e-7842184aca25",
   "metadata": {},
   "source": [
    "It will also be possible to chain multiple preprocessing layers using the Preproces singStage class. For example, the following code will create a preprocessing pipeline that will first normalize the inputs, then discretize them. After you adapt this pipeline to a data sample, you can use it like a regular layer in your models (but again, only at the start of the model, since it contains a nondifferentiable preprocessing layer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8e89ab4c-81d7-489a-88f9-9c6feff84346",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization = keras.layers.Normalization()\n",
    "discretization = keras.layers.Discretization()\n",
    "# Removed in TF 2.0 pipeline = keras.layers.PreprocessingStage([normalization, discretization])\n",
    "# pipeline.adapt(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b1953-2bc6-49cf-8288-67831ac4b7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680674c9-020c-45ba-804f-3f87a55ae6c4",
   "metadata": {},
   "source": [
    "## TextVectorization and Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdcff20-5e1f-47a8-b85d-145c947ee3d9",
   "metadata": {},
   "source": [
    "The TextVectorization layer will also have an option to output word-count vectors instead of word indices. For example, if the vocabulary contains three words, say [\"and\", \"basketball\", \"more\"], then the text \"more and more\" will be mapped to the vector [1, 0, 2]: the word \"and\" appears once, the word \"basketball\" does not appear at all, and the word \"more\" appears twice. This text representation is called a bag of words, since it completely loses the order of the words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc243e-6ccb-4d20-a0a6-ff8551fa5346",
   "metadata": {},
   "source": [
    "### Bag of Words Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e1f67a-8f74-41ee-a74c-5263c3c7f1c5",
   "metadata": {},
   "source": [
    "Common words like \"and\" will have a large value in most texts, even though they are usually the least interesting (e.g., in the text \"more and more basketball\" the word \"basketball\" is clearly the most important, precisely because it is not a very frequent word). So, the word counts should be normalized in a way that reduces the importance of frequent words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061adb15-b7fc-4164-8c31-2c33cb2a51e1",
   "metadata": {},
   "source": [
    "A common way to do this is to divide each word count by the log of the total number of training instances( the documents) in which the word appears. This technique is called Term-Frequency × Inverse-Document-Frequency (TF-IDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd1daee-38cb-4efe-943d-4b5f828f18e2",
   "metadata": {},
   "source": [
    "For example, let’s imagine that the words \"and\", \"basketball\", and \"more\" appear respectively in 200, 10, and 100 text instances in the training set: Then for the text \"more and more\", the final vector will be [1/log(200), 0/log(10), 2/log(100)], which is approximately equal to [0.19, 0., 0.43]. The TextVectorization layer will (likely) have an option to perform TF-IDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb2cec-360d-4087-8303-dfa1e066d21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce57b2c-501d-4f22-a88f-3b3aea696558",
   "metadata": {},
   "source": [
    "### subclassing the keras.layers.PreprocessingLayer\n",
    "\n",
    "##### keras.layers.PreprocessingLayer not present in current TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f57670-d7ed-4f40-9b84-e81aef38bfc8",
   "metadata": {},
   "source": [
    "If the standard preprocessing layers are insufficient for your task, you will still have the option to create your own custom preprocessing layer, much like we did earlier with the Standardization class. Create a subclass of the keras.layers.PreprocessingLayer class with an adapt() method, which should take a data_sample argument and optionally an extra reset_state argument: if True, then the adapt() method should reset any existing state before computing the new state; if False, it should try to update the existing state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e078683-0b51-4d70-82dd-d719fb2728eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a63cf6f7-2ad8-42b2-aeea-c2c8d3e9a397",
   "metadata": {},
   "source": [
    "## TF Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c766fa-4f7e-4e6e-8833-9796cd79403c",
   "metadata": {},
   "source": [
    "During training, it may be preferable to perform preprocessing ahead of time. Let’s see why we’d want to do that and how we’d go about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae6fbe-7398-45d2-96a5-9baec6571bed",
   "metadata": {},
   "source": [
    "If preprocessing is computationally expensive, then handling it before training rather than on the fly may give you a significant speedup: the data will be preprocessed just once per instance before training, rather than once per instance and per epoch during training as in preprocessing during training, essentially there is a layer in the model that is being called for preprocessing, hence for every epoch it will be called, and hence every training instance will get preprocessed for epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07eff5-f19c-43ff-b361-4ae2284a5fd2",
   "metadata": {},
   "source": [
    "As mentioned earlier, if the dataset is small enough to fit in RAM, you can use its cache() method. But if it is too large, then tools like Apache Beam or Spark will help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a3c5a1-6d23-41e1-ae02-4752787da5ba",
   "metadata": {},
   "source": [
    "They let you run efficient data processing pipelines over large amounts of data, even distributed across multiple servers, so you can use them to preprocess all the training data before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f9bfb-41eb-49e4-9c2d-1bb3f758305a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f10b0897-c1e3-431c-b197-8d804bc2db39",
   "metadata": {},
   "source": [
    "### Roadblock Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5c7da4-88ba-4ffa-9124-057346a120d4",
   "metadata": {},
   "source": [
    "This methods described above sound great and indeed can speed up training, but there is one problem: once your model is trained, suppose you want to deploy it to a mobile app. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678a803-65e2-4021-bcde-ecd9bf4b4f92",
   "metadata": {},
   "source": [
    "1) In that case you will need to write some code in your app to take care of preprocessing the data before it is fed to the model. And suppose you also want to deploy the model to TensorFlow.js so that it runs in a web browser? Once again, you will need to write some pre‐processing code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e003f-f9a8-4b34-b5ec-9a0efca2667f",
   "metadata": {},
   "source": [
    "2) This can become a maintenance nightmare: whenever you want to change the preprocessing logic, you will need to update your Apache Beam code, your mobile app code, and your JavaScript code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0b0f7-96d0-4f14-94db-82d04a98a87d",
   "metadata": {},
   "source": [
    "3) This is not only time-consuming, but also error-prone: you may end up with subtle differences between the preprocessing operations performed before training and the ones performed in your app or in the browser. This training/serving skew will lead to bugs or degraded performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc1e1de-47ad-4f81-a5b1-1a3c67f014b3",
   "metadata": {},
   "source": [
    "### Possible Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed2a44-efcb-4281-85bf-02b194951bde",
   "metadata": {},
   "source": [
    "One improvement would be to take the trained model (trained on data that was preprocessed by your Apache Beam or Spark code) and, before deploying it to your app or the browser, add extra preprocessing layers to take care of preprocessing on the fly. That’s definitely better, since now you just have two versions of your preprocessing code: the Apache Beam or Spark code, and the preprocessing layers’ code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd2676-fade-4429-a870-cd79ef5fa669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2791b92d-921d-488f-9d68-4a76c582646d",
   "metadata": {},
   "source": [
    "### TF Transform (Better Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ff25f-054f-41da-9db9-e2ab0c461116",
   "metadata": {},
   "source": [
    "But what if you could define your preprocessing operations just once? This is what TF Transform was designed for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a726f1c6-bdce-4d2a-93ae-fc0a578b2599",
   "metadata": {},
   "source": [
    "It is part of TensorFlow Extended (TFX), an end-toend platform for productionizing TensorFlow models. https://www.tensorflow.org/tfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c5e78-f8c1-4da4-a0cf-982e8d2f759b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4df91e44-b0af-495c-b066-5f0a95e81a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "60b296c1-b846-4b0f-b03b-1490565a305e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.4'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version('numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6892c78-d5d0-4de5-b97e-f1a9b7a15aa8",
   "metadata": {},
   "source": [
    "You then define your preprocessing function just once (in Python), by using TF Transform functions for scaling, bucketizing, and more. You can also use any TensorFlow operation you need. Here is what this preprocessing function might look like if we just had two features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870a78b-43fe-4d6c-b16a-8db205f52f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_transform as tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f5a3adae-005c-4361-bea7-17841d388ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs): # inputs = a batch of input features\n",
    "    median_age = inputs[\"housing_median_age\"]\n",
    "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
    "    standardized_age = tft.scale_to_z_score(median_age)\n",
    "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "    return {\"standardized_median_age\": standardized_age,\"ocean_proximity_id\": ocean_proximity_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3a92c-9e5d-4f90-82ff-75b5b527f2a1",
   "metadata": {},
   "source": [
    "Next, TF Transform lets you apply this preprocess() function to the whole training set using Apache Beam (it provides an AnalyzeAndTransformDataset class that you can use for this purpose in your Apache Beam pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e697cde0-2ede-43b3-a1d6-2965d56c8cb2",
   "metadata": {},
   "source": [
    "#### Working of the Function!!!!\n",
    "\n",
    "The function will compute all the necessary statistics over the whole training set: in this example, the mean and standard deviation of the housing_median_age feature, and the vocabulary for the ocean_proximity feature. The components that compute these statistics are called analyzers.\r\n",
    "\n",
    "Importantly, TF Transform will also generate an equivalent TensorFlow Function that you can plug into the model you deploy. This TF Function includes some constants that correspond to all the all the necessary statistics computed by Apache Beam (the mean, standard deviation, and vocabulary).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a58c05-265e-49b1-9b15-22418c61e6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dde785a8-6e2b-4c20-9ba5-e902bb343980",
   "metadata": {},
   "source": [
    "## The TensorFlow Datasets (TFDS) Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16921267-fb89-402a-8977-ff11f046448f",
   "metadata": {},
   "source": [
    "The TensorFlow Datasets project makes it very easy to download common datasets, from small ones like MNIST or Fashion MNIST to huge datasets like ImageNet (you will need quite a bit of disk space!). The list includes image datasets, text datasets (including translation datasets), and audio and video datasets. You can visit https://homl.info/tfds to view the full list, along with a description of each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce902e34-cfa0-4a65-b395-2630a6274375",
   "metadata": {},
   "source": [
    "TFDS is not bundled with TensorFlow, so you need to install the tensorflowdatasets library (e.g., using pip). Then call the tfds.load() function, and it will download the data you want (unless it was already downloaded earlier) and return the data as a dictionary of datasets (typically one for training and one for testing, but this depends on the dataset you choose). For example, let’s download MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b650f959-a349-474b-aa67-8ff17681264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0532ac3a-2507-41cf-9b96-de960ff6b9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tfds.load(name=\"mnist\")\n",
    "# mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5771d1-0b8d-4e74-8c49-9033d909ab7b",
   "metadata": {},
   "source": [
    "You can then apply any transformation you want (typically shuffling, batching, and prefetching), and you’re ready to train your model. Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7241f41a-68b3-4c44-8233-03d76ec4f8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train = mnist_train.shuffle(10000).batch(32).prefetch(1)\n",
    "# for item in mnist_train:\n",
    "#  images = item[\"image\"]\n",
    "#  labels = item[\"label\"]\n",
    "#  [...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fb7929-6eb5-46e4-ba34-fef451d4d579",
   "metadata": {},
   "source": [
    "#### Note that each item in the dataset is a dictionary containing both the features and the labels. But Keras expects each item to be a tuple containing two elements (again, the features and the labels). You could transform the dataset using the map() method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f51735a6-1651-46fa-888c-c039c2976f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train = mnist_train.shuffle(10000).batch(32)\n",
    "# mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "# mnist_train = mnist_train.prefetch(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa90cb3-e4cd-4880-b1a5-1908abdaeb5b",
   "metadata": {},
   "source": [
    "#### But it’s simpler to ask the load() function to do this for you by setting as_supervised=True (obviously this works only for labeled datasets). You can also specify the batch size if you want. Then you can pass the dataset directly to your tf.keras model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc6eb139-b510-4b41-b44a-f59de1962662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
    "# mnist_train = dataset[\"train\"].prefetch(1)\n",
    "# model = keras.models.Sequential([...])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\")\n",
    "# model.fit(mnist_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d3d677-e7c7-4125-a1f0-0b498f0fae5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf87ef4-91e9-4168-bd87-31f4df844d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3149dcb7-e7c1-49f3-bff1-7c5bc8ee8f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c9edb-c215-481e-b786-a91789b083fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45527c28-421c-4ba8-b63d-089f752d46dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5ab6d-880a-4b07-bded-967c66e9c10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03dc27f-629c-42b2-9b95-c0ad82f4a02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae44270-8a6c-497d-afc5-83c339fdb5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d4b11-e659-449e-bcc0-c581e59d960c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7e10a-1424-477a-980e-bfe21ac12840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b467183-2b43-4bfc-afda-ade668c5e855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b790185-39c9-4a38-a502-1288a0432688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f2593-324c-46de-8de5-149e5dbc29ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413f642b-f18e-427c-8b46-2488176c9644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59551cc-db17-45cc-9521-dbe5cf5ef359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4650f3-3c9e-423a-90f3-a56fdf50e52b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44f6526-c4ba-4fb2-9dac-938d0eb8dcdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926d7fb-4d62-4486-9733-ebeb7105c2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0147f017-b354-4d32-a503-6aa3397f1773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee9e18-e1a9-4099-9570-737a33613528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7958b-d0d8-4b91-b4aa-723f2c360d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf21a85-3251-43ad-9f7b-6083db91c83e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693d944-0456-4541-bb3a-fa7d3ff89646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53b3dd-f202-4841-b86f-6343a9717376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cb995-79e2-453b-8192-a18a4d7470c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fa4976-1cf3-4ab5-b398-0a3408b08a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8add4-f476-4815-92c9-86878036d9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28339eb9-f17a-438c-a9e0-122184e52b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45764ae-d325-4703-a810-35ed1239ba05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673652bb-942b-4848-9280-8ca7b856ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d38459d-e44e-41fa-8a75-c78f8e44b062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86083aa9-c5ca-4ee8-a008-10575499ac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e6d3d3-e42d-4024-913f-259b3e27deec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482dd4c-d34a-4d27-b956-d205f2a9d844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d35bd-5f06-4fee-abad-31c74e57a56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4124e-3136-4979-b51b-ef7e8e19dec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0754c-91fc-4d2f-860d-28898fc1a9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1b0b9-5f22-4a0e-ad9c-3e17463669a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59be568-7e4c-4802-875e-d654c8a6b22d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82587f9d-bb01-4879-ad86-6237f7564ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
