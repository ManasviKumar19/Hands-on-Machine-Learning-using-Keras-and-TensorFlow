{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf124b65-6c04-40bb-91fc-5b56e9417b90",
   "metadata": {},
   "source": [
    "# Custom Models and Training with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2801dfc-39c7-4f89-8733-5a58e537a878",
   "metadata": {},
   "source": [
    "Up until now, we’ve used only TensorFlow’s high-level API, tf.keras, but it already got us pretty far: we built various neural network architectures, including regression and classification nets, Wide & Deep nets, and self-normalizing nets, using all sorts of techniques, such as Batch Normalization, dropout, and learning rate schedules. In fact, 95% of the use cases you will encounter will not require anything other than tf.keras and tf.data;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02797e6-b9a3-4ba9-98d4-3483526590a9",
   "metadata": {},
   "source": [
    "But now it’s time to dive deeper into TensorFlow and take a look at its lower-level Python API. This will be useful when you need extra control to write custom loss functions, custom metrics, layers, models, initializers, regularizers, weight constraints, and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309106be-5d5e-4cdb-bbcb-35104ecc4e56",
   "metadata": {},
   "source": [
    "You may even need to fully control the training loop itself, for example to apply special transformations or constraints to the gradients (beyond just clipping them) or to use multiple optimizers for different parts of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a22600-a504-4507-890b-f52a16892e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebf4f166-4b26-4039-9883-3a341bc36ed5",
   "metadata": {},
   "source": [
    "## A Quick Tour of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f36fc-c8c8-4c01-a159-b83447de1ae7",
   "metadata": {},
   "source": [
    "### So what does TensorFlow offer? Here’s a summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008608d3-a4c1-4112-8aee-61ba9884168a",
   "metadata": {},
   "source": [
    "#### 1) Its core is very similar to NumPy, but with GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b2c9a-b641-4f6d-bd4f-0e1ecb1da719",
   "metadata": {},
   "source": [
    "#### 2) It supports distributed computing (across multiple devices and servers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc25fc8-f591-4bdd-995c-ba0b57276866",
   "metadata": {},
   "source": [
    "#### Important point\n",
    "#### 3) It includes a kind of just-in-time (JIT) compiler that allows it to optimize computations for speed and memory usage. It works by extracting the computation graph from a Python function, then optimizing it (e.g., by pruning unused nodes), and finally running it efficiently (e.g., by automatically running independent operations in parallel).\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560eac3c-9267-4440-bb0e-72e326c5a21a",
   "metadata": {},
   "source": [
    "#### Important point\n",
    "\n",
    "#### 4) Computation graphs can be exported to a portable format, so you can train a TensorFlow model in one environment (e.g., using Python on Linux) and run it in another (e.g., using Java on an Android device)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9d404-0bd0-4f6c-8f8e-bd9fd8846c33",
   "metadata": {},
   "source": [
    "#### 5) It implements autodiff and provides some excellent optimizers, such as RMSProp and Nadam, so you can easily minimize all sorts of loss functions.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e993a-1eb9-4be6-9861-169f07a19797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02985077-020f-4dd9-b75e-73fc466f9e73",
   "metadata": {},
   "source": [
    "### TensorFlow APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6e81c-59ac-4376-a254-7142d3bfe64a",
   "metadata": {},
   "source": [
    "TensorFlow offers many more features built on top of these core features: the most important is of course tf.keras, but it also has data loading and preprocessing ops (tf.data, tf.io, etc.), image processing ops (tf.image), signal processing ops (tf.signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f620fd-d059-4985-8f92-a12b42eb278d",
   "metadata": {},
   "source": [
    "##### IMPORTANT!! See figure 12-1 TensorFlow’s Python API for the list of all the APIs offered by Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b64612-0a7e-41d4-8f72-3858c351965b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1764f4ef-8751-41b9-b409-321c2fcbea0e",
   "metadata": {},
   "source": [
    "### TensorFlow foundational structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11bd5c9-f176-4559-ba28-071005e1b6ae",
   "metadata": {},
   "source": [
    "At the lowest level, each TensorFlow operation (op for short) is implemented using highly efficient C++ code. Many operations have multiple implementations called kernels: each kernel is dedicated to a specific device type, such as CPUs, GPUs, or even TPUs (tensor processing units). As you may know, GPUs can dramatically speed up computations by splitting them into many smaller chunks and running them in parallel across many GPU threads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acf8e0f-e0e9-4ba7-bcb9-902f28f6cfb6",
   "metadata": {},
   "source": [
    "##### TPUs are even faster: they are custom ASIC chips built specifically for Deep Learning operations\n",
    "\n",
    "##### To learn more about TPUs and how they work, check out https://homl.info/tpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5130d-3359-40a6-9f32-75d9f7a1a345",
   "metadata": {},
   "source": [
    "TensorFlow’s architecture is shown in Figure 12-2. Most of the time your code will use the high-level APIs (especially tf.keras and tf.data); but when you need more flexibility, you will use the lower-level Python API, handling tensors directly. Note that APIs for other languages are also available. In any case, TensorFlow’s execution engine will take care of running the operations efficiently, even across multiple devices and machines if you tell it to.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0106c46-9376-4bbe-b19e-9ca90a07aeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ffd3d6-c3c4-436a-81a9-e61f7f1d47e8",
   "metadata": {},
   "source": [
    "### TensorFlow cross-device compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac241ea3-f82f-4d93-9c48-6434e1a8647c",
   "metadata": {},
   "source": [
    "TensorFlow runs not only on Windows, Linux, and macOS, but also on mobile devices (using TensorFlow Lite), including both iOS and Android. If you do not want to use the Python API, there are C++, Java, Go, and Swift APIs. There is even a JavaScript implementation called TensorFlow.js that makes it possible to run your models directly in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5880a-c3fe-4a38-bfa8-d52aa67b4e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05c8455d-bf7f-429f-a6c3-be489a00f859",
   "metadata": {},
   "source": [
    "### TensorFlow Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d60e6-1630-44ab-86b3-b362929f70f3",
   "metadata": {},
   "source": [
    "TensorFlow is at the center of an extensive ecosystem of libraries. First, there’s TensorBoard for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc49815-79b8-416e-ae53-6c18d282e70f",
   "metadata": {},
   "source": [
    "Next, there’s TensorFlow Extended (TFX), which is a set of libraries built by Google to productionize TensorFlow projects: it includes tools for data validation, preprocessing, model analysis, and serving with TF Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809114ba-cc88-4cd8-9e63-48beb745acf2",
   "metadata": {},
   "source": [
    "Google’s TensorFlow Hub provides a way to easily download and reuse pretrained neural networks. You can also get many neural network architectures, some of them pre-trained, in TensorFlow’s model garden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d32e32-d1bd-4822-81ab-0ba40f9dccf5",
   "metadata": {},
   "source": [
    "More and more ML papers are released along with their implementations, and sometimes even with pretrained models. Check out https://paperswithcode.com/ to easily find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffed943-a796-4cd3-9f03-27acce663f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04ea4bd1-f3aa-4810-933a-8516104b5c6b",
   "metadata": {},
   "source": [
    "## Using TensorFlow like NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d717948-ff1c-4c12-a876-33e78269d490",
   "metadata": {},
   "source": [
    "TensorFlow’s API revolves around tensors, which flow from operation to operation hence the name TensorFlow. A tensor is very similar to a NumPy ndarray: it is usually a multidimensional array, but it can also hold a scalar (a simple value, such as 42). These tensors will be important when we create custom cost functions, custom metrics, custom layers, and more, so let’s see how to create and manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d1f3236-de04-4ac2-bae0-04f9340e2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2300fd0-24da-4676-a3c7-f37f1ba28ad3",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835588bf-f05d-45a2-a810-c9b7f7658838",
   "metadata": {},
   "source": [
    "You can create a tensor with tf.constant(). For example, here is a tensor representing a matrix with two rows and three columns of floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e33de2-05e3-4aa1-930c-5e20d248ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tensor = tf.constant([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c92ae35-44f9-4a80-a166-559985a92b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f56f311-0241-4e52-aaa6-085f9a6599b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar_tensor = tf.constant(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58945dc4-7437-47f5-ae0a-eab5b3c06c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8248092-e3b3-4d08-873b-6c1e1ae8b427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa51bf34-efd5-4f54-a8af-2c5b29750b74",
   "metadata": {},
   "source": [
    "##### Just like an ndarray, a tf.Tensor has a shape and a data type (dtype):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db4be83-c93c-4383-b056-0e5abe708810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4dd37c-7a42-4f30-91cd-8b1570853f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67161dae-e1f9-48ad-854d-50a538989791",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc9af2bb-f051-46c6-a134-fec657ae5d16",
   "metadata": {},
   "source": [
    "##### Indexing works much like in NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2dbb86-066d-4f77-816e-6df62d7e0ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3a814-23ba-4d83-8a8d-b1d7dbc5ce05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa7a61be-3a51-4fc6-9f8c-f8221e0dbf1d",
   "metadata": {},
   "source": [
    "#### Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a28d8-75a7-4c7c-aa83-9ec16ac5d6c4",
   "metadata": {},
   "source": [
    "##### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af2c604-0d72-44fc-8b27-f1380d173c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor + 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce33734-26af-4e8e-b23e-715c31438ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb4f19-510d-428f-83a0-bc48cfeb4008",
   "metadata": {},
   "source": [
    "##### squaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eefa614e-048f-43eb-b4e8-a699b53d50c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7420467-c04c-4961-8517-989930893678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193aca0c-fe36-4ea0-8b30-040599b2ac56",
   "metadata": {},
   "source": [
    "##### Matrix Multiplication tf.matmul() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cddc0ac-1ce8-4a0e-864d-ae2bf037e55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tensor @ tf.transpose(sample_tensor) # The @ operator was added in Python 3.5, for matrix multiplication: it is equivalent to calling the tf.matmul() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03a49e-0705-417f-8706-857e3f541c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b44ad13-181d-46c6-8007-894f70d564a6",
   "metadata": {},
   "source": [
    "### TensoFlow operation list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e057a5-7969-4b12-8964-74d9d94077d8",
   "metadata": {},
   "source": [
    "1) You will find all the basic math operations you need (tf.add(), tf.multiply(), tf.square(), tf.exp(), tf.sqrt(), etc.) and most operations that you can find in NumPy (e.g., tf.reshape(), tf.squeeze(), tf.tile())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b1450-2e96-4cf8-bbd1-b643aabb3eae",
   "metadata": {},
   "source": [
    "2) Some functions have a different name than in NumPy; for instance, tf.reduce_mean(), tf.reduce_sum(), tf.reduce_max(), and tf.math.log() are the equivalent of np.mean(), np.sum(), np.max() and np.log()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d5b36-cb2d-4a00-b1ec-6cde01c787c6",
   "metadata": {},
   "source": [
    "#### Important Point!!!!!!\n",
    "4) When the name differs, there is often a good reason for it. For example, in TensorFlow you must write tf.transpose(t); you cannot just write t.T like in NumPy. The reason is that the tf.transpose() function does not do exactly the same thing as NumPy’s T attribute: in TensorFlow, a new tensor is created with its own copy of the transposed data, while in NumPy, t.T is just a transposed view on the same data. Similarly, the tf.reduce_sum() operation is named this way because its GPU kernel (i.e., GPU implementation) uses a reduce algorithm that does not guarantee the order in which the elements are added: because 32-bit floats have limited precision, the result may change ever so slightly every time you call this operation. The same is true of tf.reduce_mean() (but of course tf.reduce_max() is deterministic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9352b-98d2-4fd9-ae57-18350d4911dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93672b41-8784-4c7b-86a0-d3bc957bdee9",
   "metadata": {},
   "source": [
    "## Tensors and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802ed98-e5b2-4511-b0cb-cf2a7bd1993a",
   "metadata": {},
   "source": [
    "Tensors play nice with NumPy: you can create a tensor from a NumPy array, and vice versa. You can even apply TensorFlow operations to NumPy arrays and NumPy operations to tensors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b3730-1d83-4b77-b08f-243e7c12e8b3",
   "metadata": {},
   "source": [
    "#### Arrays to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd673a99-f689-41d0-a749-c0e5d91239f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 4., 5.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f56eb6d4-2e80-4a83-9485-794a21e169d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = tf.constant(a)\n",
    "tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad286f0d-8428-4506-a681-0c5fd20c8d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=4.0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a[1]\n",
    "\n",
    "# tensor_a[1] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a3659-d6c1-4e63-b4bf-2d0f9cfdb726",
   "metadata": {},
   "source": [
    "#### Tensors to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79af3cbb-2581-4110-894a-75bc3ecf0973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]] converting using TF\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]] converting using numpy\n"
     ]
    }
   ],
   "source": [
    "sample_tensor_to_numpy = sample_tensor.numpy()\n",
    "print(sample_tensor_to_numpy,'converting using TF')\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "# The above part can also be done as follows\n",
    "sample_numpy_array = np.array(sample_tensor)\n",
    "print(sample_numpy_array,'converting using numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c28cd2-8ce7-4c7e-980e-6e8607ebb9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a47cceb-dcf7-4721-9245-e6f504cc2424",
   "metadata": {},
   "source": [
    "### IMPORTANT WARNING!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set dtype=tf.float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff8414-dcb5-4ca5-ba10-f80489a39cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "324e1e05-a73e-465c-8acb-4ffe787dc1dc",
   "metadata": {},
   "source": [
    "### Type Conversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2af4ea-d053-45f5-af10-85639c06ef2f",
   "metadata": {},
   "source": [
    "Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c9f5c-ca12-4919-9fa7-c4625dbddf2f",
   "metadata": {},
   "source": [
    "For example, you cannot add a float tensor and an integer tensor, and you cannot even add a 32-bit float and a 64-bit float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e460937-7af2-4515-920a-2cc513b51314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6a98a87-229c-48dc-8198-d33ba0181560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant(2.) + tf.constant(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deec86a7-5ad6-433f-b5cc-727f79b7210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.constant(2.,dtype=tf.float32) + tf.constant(40., dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629da3fa-a20f-4bfb-9a36-87868c9025e2",
   "metadata": {},
   "source": [
    "#### This may be a bit annoying at first, but remember that it’s for a good cause! And of course you can use tf.cast() when you really need to convert types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec304ef4-760a-4cd8-af8c-8b1565a69f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "712b3619-94eb-4bf5-81d7-9364f6d06427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601a804-a207-4d53-b9c6-2977061f1743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "915ff6ba-53d0-4e58-be92-3e98f0df6458",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf2e9c-2301-436a-9b16-2c757bc58651",
   "metadata": {},
   "source": [
    "The tf.Tensor values we’ve seen so far are immutable: you cannot modify them. This means that we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation. Plus, other parameters may also need to change over time (e.g., a momentum optimizer keeps track of past gradients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c9005-a724-4956-b493-b64884f984ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a932700-cc4c-4657-b3b4-b0e8be01360c",
   "metadata": {},
   "source": [
    "#### What we need is a tf.Variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d74b4d5-5b33-45b6-ba8e-20e5139786f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061e0b60-2e00-4f08-8942-cbb6e245c12b",
   "metadata": {},
   "source": [
    "A tf.Variable acts much like a tf.Tensor: you can perform the same operations with it, it plays nicely with NumPy as well, and it is just as picky with types. But it can also be modified in place using the assign() method (or assign_add() or assign_sub(), which increment or decrement the variable by the given value). You can also modify individual cells (or slices), by using the cell’s (or slice’s) assign() method (direct item assignment will not work) or by using the scatter_update() or scatter_nd_update() methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec781ed0-23f4-44f3-a978-675d63356836",
   "metadata": {},
   "source": [
    "#### Assign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0539bb07-8f0a-48ef-a157-98f1435accc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9bec82a-262d-4727-a92e-d4b388851976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf490dc7-b12f-4b22-be54-48178cde29d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c553bd9-06bb-4a32-b705-97b487bb97a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a05036-fc51-4262-ba6d-88130f7abe64",
   "metadata": {},
   "source": [
    "#### Scatter and update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "900e7352-1239-4080-b60e-cbca37c8e6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaea419-2125-48f9-9740-badb9dc09f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bcd415-c6d5-47f6-9ae2-f5e5e6ee9174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e766621-f0a3-40e3-8161-28380750c1c1",
   "metadata": {},
   "source": [
    "### Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7edea5-287b-4b88-9ddd-8812830ae026",
   "metadata": {},
   "source": [
    "##### Sparse tensors (tf.SparseTensor)\n",
    "\n",
    "Efficiently represent tensors containing mostly zeros. The tf.sparse package contains operations for sparse tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb5735c-5efb-4460-8375-37bef5890e64",
   "metadata": {},
   "source": [
    "##### Tensor arrays (tf.TensorArray)\n",
    "\n",
    "Are lists of tensors. They have a fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a470a5-d77f-4e57-93b2-669421a70eaf",
   "metadata": {},
   "source": [
    "##### Ragged tensors (tf.RaggedTensor)\n",
    "\n",
    "Represent static lists of lists of tensors, where every tensor has the same shape\r\n",
    "and data type. The tf.ragged package contains operations for ragged tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f087909-50e0-4a93-a86e-a612fd29ef2c",
   "metadata": {},
   "source": [
    "##### String tensors\n",
    "Are regular tensors of type tf.string. These represent byte strings, not Unicode strings, so if you create a string tensor using a Unicode string (e.g., a regular Python 3 string like \"café\"), then it will get encoded to UTF-8 automatically (e.g., b\"caf\\xc3\\xa9\"). Alternatively, you can represent Unicode strings using tensors of type tf.int32, where each item represents a Unicode code point (e.g., [99, 97, 102, 233]). The tf.strings package (with an s) contains ops for byte strings and Unicode strings (and to convert one into the other). It’s important to note that a tf.string is atomic, meaning that its length does not appear in the tensor’s shape. Once you convert it to a Unicode tensor (i.e., a tensor of type tf.int32 holding Unicode code points), the length appears in the shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756168d2-aeb5-4a82-b01f-e9becc956a9e",
   "metadata": {},
   "source": [
    "##### Sets\n",
    "Are represented as regular tensors (or sparse tensors). For example, tf.constant([[1, 2], [3, 4]]) represents the two sets {1, 2} and {3, 4}. More generally, each set is represented by a vector in the tensor’s last axis. You can manipulate sets using operations from the tf.sets package.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64ab334-8d2f-4832-8510-598f66be379f",
   "metadata": {},
   "source": [
    "##### Queues\n",
    "Store tensors across multiple steps. TensorFlow offers various kinds of queues: simple First In, First Out (FIFO) queues (FIFOQueue), queues that can prioritize some items (PriorityQueue), shuffle their items (RandomShuffleQueue), and batch items of different shapes by padding (PaddingFIFOQueue). These classes are all in the tf.queue package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18035fde-8c76-4984-8066-1e2f5bb75a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d04d08-ca3f-43f7-bcaa-53d1e276e873",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218221d7-9a14-4f7f-b992-ea1c42fea593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bad07eb-bd7a-479d-be49-e93eca05e82f",
   "metadata": {},
   "source": [
    "### Custom Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1f866-fe73-4e81-944f-d5b0509ab151",
   "metadata": {},
   "source": [
    "Let’s start by creating a custom loss function, which is a simple and common use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b29da-0041-4bf0-9f4b-6a99d5d1c457",
   "metadata": {},
   "source": [
    "#### Custom Loss Function Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdd1ec-b172-467a-93c9-aace499eec96",
   "metadata": {},
   "source": [
    "Suppose you want to train a regression model, but your training set is a bit noisy. Of course, you start by trying to clean up your dataset by removing or fixing the outliers, but that turns out to be insufficient; the dataset is still noisy. Which loss function should you use? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00219a-db42-4871-971b-f2f6add2050c",
   "metadata": {},
   "source": [
    "The mean squared error might penalize large errors too much and cause your model to be imprecise. The mean absolute error would not penalize outliers as much, but training might take a while to converge, and the trained model might not be very precise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131a76c-524d-4523-be6a-48ab982052f8",
   "metadata": {},
   "source": [
    "This is probably a good time to use the Huber loss (introduced in Chapter 10) instead of the good old MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa91ea1-401c-4ab3-90c5-a92e33047596",
   "metadata": {},
   "source": [
    "The Huber loss is not currently part of the official Keras API, but it is available in tf.keras (just use an instance of the keras.losses.Huber class). But let’s pretend it’s not there:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6c839-b834-4eef-a074-b62e82509381",
   "metadata": {},
   "source": [
    "Just create a function that takes the labels and predictions as arguments, and use TensorFlow operations to compute every instance’s loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8017296-130b-42cd-a0c9-7aac1d1c361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33024676-d854-4415-833b-975b09815604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34c0e1a1-08f8-4e88-8ec6-17743bd1d48d",
   "metadata": {},
   "source": [
    "#### Creating the Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d5db477-aa17-400c-bd07-c5663a017e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    print(y_true,y_pred)\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    print(tf.where(is_small_error, squared_loss, linear_loss),' dekhle')\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89757efb-7224-4c47-9dde-76e8801c00e8",
   "metadata": {},
   "source": [
    "#### Important Note about the Custom Loss Function\n",
    "It is also preferable to return a tensor containing one loss per instance, rather than returning the mean loss. This way, Keras can apply class weights or sample weights when requested ( Refer the Important Note about Training block from the chapter 10 jupyter nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48522f28-7610-4f93-bc54-0fc4dc389a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08db3d-07a7-41ae-a56a-3b6c5108ee02",
   "metadata": {},
   "source": [
    "#### Training a network with the custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db898b89-ff46-451a-bfac-4da1a7be5098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67deae60-92d8-41be-a47a-6345419f43a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a87c7dcc-4228-419b-aa88-328a3d39af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 1), dtype=float32) Tensor(\"sequential/dense_1/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"huber_fn/SelectV2:0\", shape=(None, 1), dtype=float32)  dekhle\n",
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 1), dtype=float32) Tensor(\"sequential/dense_1/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"huber_fn/SelectV2:0\", shape=(None, 1), dtype=float32)  dekhle\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.6327 - mae: 1.0001Tensor(\"IteratorGetNext:1\", shape=(None, 1), dtype=float32) Tensor(\"sequential/dense_1/BiasAdd:0\", shape=(None, 1), dtype=float32)\n",
      "Tensor(\"huber_fn/SelectV2:0\", shape=(None, 1), dtype=float32)  dekhle\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.6273 - mae: 0.9937 - val_loss: 0.2392 - val_mae: 0.5361\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2232 - mae: 0.5203 - val_loss: 0.2000 - val_mae: 0.4845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x275c910a1d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc91cdef-89ce-4405-8f44-5dcc5d0e0109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49dcaacb-0e48-4e6e-8574-4f60c17e19d8",
   "metadata": {},
   "source": [
    "#### Working of the model\n",
    "For each batch during training, Keras will call the huber_fn() function to compute the loss and use it to perform a Gradient Descent step. Moreover, it will keep track of the total loss since the beginning of the epoch, and it will display the mean loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220392a-d3f3-4763-9d81-04ee5df9f487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d821f09-2b55-4b02-8e18-8d3665e2a0ff",
   "metadata": {},
   "source": [
    "### Saving and Loading Models That Contain Custom Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373fe5c8-af24-4930-a5ae-a41468069bad",
   "metadata": {},
   "source": [
    "Now, in the previous section you defined a custom loss function, But what happens to this custom loss when you save the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea04615-69ea-473e-be21-7fc4220d27f4",
   "metadata": {},
   "source": [
    "Saving a model containing a custom loss function works fine, as Keras saves the name of the function. Whenever you load it, you’ll need to provide a dictionary that maps the function name to the actual function. More generally, when you load a model containing custom objects, you need to map the names to the objects:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7271336-7cae-4b32-9bd5-7075046c5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034324f2-89cf-49e6-bd93-62bc9e298483",
   "metadata": {},
   "source": [
    "Saving a model containing a custom loss function works fine, as Keras saves the name of the function. Whenever you load it, you’ll need to provide a dictionary that maps the function name to the actual function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d331fae9-5da4-48f7-9407-8045c884739a",
   "metadata": {},
   "source": [
    "More generally, when you load a model containing custom objects, you need to map the names to the objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1770207-ebdd-4a90-b6fd-8ff9cc775878",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.keras\", custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f26d6-1425-479d-9040-51bc8dfa1570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0446e0a4-1c61-4cfd-8b2a-0f94486203f6",
   "metadata": {},
   "source": [
    "#### Customized Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54c65d6-fcd0-49de-8fc6-6a6d7651069b",
   "metadata": {},
   "source": [
    "With the current implementation, any error between –1 and 1 is considered “small.” But what if you want a different threshold? One solution is to create a function that creates a configured loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5cb96fa-8408-4b04-92dc-3986607a5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1db051f4-ee1b-441f-b8d1-9a1a5bf8bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39e28a95-e270-4efb-90eb-78090cfddedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_with_a_custom_loss_threshold_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a6698-9bf0-434b-a4c2-546b43372a46",
   "metadata": {},
   "source": [
    "#### !!!WARNING FOR CUSTOMIZED THRESHOLD!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79c9ca-301c-4068-9c49-2ebd5731dad9",
   "metadata": {},
   "source": [
    "Unfortunately, when you save the model, the threshold will not be saved. This means that you will have to specify the threshold value when loading the model (note that the name to use is \"huber_fn\", which is the name of the function you gave Keras, not the name of the function that created it, which basically means the function that actually calculated the loss, yes it means that although you pass reate_huber(2.0) when you compile the model, the function that actually calculates the loss is the huber_fn() and that is what keras also gets, so remember to pass that name.):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "930217ff-0053-4f23-bf8a-fb745ee97c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Nadam', because it has 9 variables whereas the saved optimizer has 1 variables. \n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.keras\",\n",
    " custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cac726-369a-4ff9-90a2-9fc6e7aa26da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e920b45-498b-4a7e-9ca0-b444f9ede6eb",
   "metadata": {},
   "source": [
    "### Implemention Keras Subclassing API to solve the problem of custom threshold not being saved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffefcfa-3561-4e49-b8bd-adaf179c9865",
   "metadata": {},
   "source": [
    "You can solve this by creating a subclass of the keras.losses.Loss class, and then implementing its get_config() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35da5231-3edf-472c-b389-eb54c86c495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286b62d-aa5a-455e-8dc5-ad7e2e3a6fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c718bbd-2376-472e-a918-b040b6ae2d6d",
   "metadata": {},
   "source": [
    "#### Understanding the above code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9282753-cc5a-4765-b6de-dc64b1a7ccbc",
   "metadata": {},
   "source": [
    "1) The constructor accepts **kwargs and passes them to the parent constructor, which handles standard hyperparameters: the name of the loss and the reduction algorithm to use to aggregate the individual instance losses. By default, it is \"sum_over_batch_size\", which means that the loss will be the sum of the instance losses, weighted by the sample weights, if any, and divided by the batch size (not by the sum of weights, so this is not the weighted mean. It would not be a good idea to use a weighted mean: if you did, then two instances with the same weight but in different batches would have a different impact on training, depending on the total weight of each batch.). Other possible values are \"sum\" and \"none\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d2c6a-3e5e-4dec-9c39-ba5c07fffe92",
   "metadata": {},
   "source": [
    "2) The call() method takes the labels and predictions, computes all the instance losses, and returns them.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b4b369-1fe1-475a-b70c-e240244fcdbb",
   "metadata": {},
   "source": [
    "3) The get_config() method returns a dictionary mapping each hyperparameter name to its value. It first calls the parent class’s get_config() method, then adds the new hyperparameters to this dictionary (the new hyperparameters are the new loss calculating ways that you defined). Now, a side note about the **base_config, so first of all this get_config() is called only when you save or serialize or clone the model, it is a way for keras to remember the custom things that you implemented, like the loss function. Now what **base_config does is that it's like the **kwargs like it is a dictionary, but here instead of passing the values to a function, it actually adds the self.threshold into the original  base_config dictionary. AN EXAMPLE IS SHOWN BELOW PLASE CHECK!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c7c49f5-ee2f-40ba-a266-563193f960aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aaa': 11, 'ddd': 234, 'stof': 321}  first one \n",
      "\n",
      "\n",
      "\n",
      "{'aaa': 11, 'ddd': 234, 'stof': 321, 'my_day': 111}\n"
     ]
    }
   ],
   "source": [
    "def upd_dict(dictio):\n",
    "    \n",
    "    return {**dictio,'stof':321}\n",
    "\n",
    "dd = {'aaa':11,'ddd':234}\n",
    "\n",
    "update_dict = upd_dict(dictio=dd)\n",
    "print(update_dict,' first one \\n\\n\\n')\n",
    "\n",
    "print({**update_dict,'my_day':111})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bcb355-81e9-4a02-8754-06f2ae28e2e5",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3349992c-6420-4913-a7a5-affd3919b8ee",
   "metadata": {},
   "source": [
    "You can then use any instance of this class when you compile the model:\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c45f2260-b350-4e65-90cf-aa9b76fa34b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d97e01d5-11a9-481a-a899-755fa0dd16d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.2366 - val_loss: 0.2412\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2289 - val_loss: 0.2138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x275c9797cd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb77007-8a76-41a4-819e-959ff6da6fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be2e2f7c-e98e-4595-a436-3e48cc12df51",
   "metadata": {},
   "source": [
    "#### Saving this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c184bbc-c9c5-42a2-ae25-3187320f5cba",
   "metadata": {},
   "source": [
    "When you save the model, the threshold will be saved along with it; and when you load the model, you just need to map the class name to the class itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f57d8c7-d0b4-4f79-8f22-44fdc72e07de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model_with_a_custom_loss_threshold_and_subclassedAPI.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9184a0-399c-4313-9eff-87c5100d7cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f13808-1499-49aa-af6f-77a0c7d8a98d",
   "metadata": {},
   "source": [
    "#### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8df632c-597b-451e-aba9-5cefff9ca4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_and_subclassedAPI.keras\", custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc13f2f-89cc-4863-8a50-0b7766777f81",
   "metadata": {},
   "source": [
    "#### Working of the Saving and Loading of the model\n",
    "When you save a model, Keras calls the loss instance’s get_config() method and saves the config as JSON. When you load the model, it calls the from_config() class method on the HuberLoss class: this method is implemented by the base class (Loss) and creates an instance of the class, passing **config to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbb693-66a6-4ea6-9a28-5125a149256c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baff871-ecde-42c5-8731-c1b233764c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16406f5e-1ae9-4ac3-8199-d07c2c7ae76c",
   "metadata": {},
   "source": [
    "### Custom Activation Functions, Initializers, Regularizers, and Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c244f-f53b-404e-aa17-54a0f8634eb4",
   "metadata": {},
   "source": [
    "Most Keras functionalities, such as losses, regularizers, constraints, initializers, metrics, activation functions, layers, and even full models, can be customized in very much the same way. Most of the time, you will just need to write a simple function with the appropriate inputs and outputs. Here are examples of a custom activation function (equivalent to keras.activations.softplus() or tf.nn.softplus()), a custom Glorot initializer (equivalent to keras.initializers.glorot_normal()), a custom ℓ1 regularizer (equivalent to keras.regularizers.l1(0.01)), and a custom constraint that ensures weights are all positive (equivalent to keras.constraints.nonneg() or tf.nn.relu()):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b0566b20-1cf3-4d58-b359-bda8d10626d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8efa65-1c66-483d-bc2c-bc581fd5ea04",
   "metadata": {},
   "source": [
    "As you can see, the arguments depend on the type of custom function. These custom functions can then be used normally; for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d896cad7-2a70-416e-bf68-ac399e64a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(30, activation=my_softplus, kernel_initializer=my_glorot_initializer, kernel_regularizer=my_l1_regularizer, kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d68ee-be12-49d2-b47b-286187e0c419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cfef949-eec6-4227-bc40-761ddd1581ae",
   "metadata": {},
   "source": [
    "#### Working of the layer with Customized parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b6c12-8072-437e-8c5e-a8f94e22f90b",
   "metadata": {},
   "source": [
    "1) The activation function will be applied to the output of this Dense layer, and its result will be passed on to the next layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e10f8f-b7d8-440f-a205-58d396bfd756",
   "metadata": {},
   "source": [
    "2) The layer’s weights will be initialized using the value returned by the initializer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a3cde7-ffb0-4e12-88a5-e2ad719af71e",
   "metadata": {},
   "source": [
    "#### IMPORTANT POINT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "3) At each training step the weights will be passed to the regularization function to compute the regularization loss, which will be added to the main loss to get the final loss used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ec595-0792-4c70-86ee-b0e07acda01d",
   "metadata": {},
   "source": [
    "4) Finally, the constraint function will be called after each training step, and the layer’s weights will be replaced by the constrained weights(def my_positive_weights(weights):)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb47a7-467f-4088-8835-bc9b5dbab13e",
   "metadata": {},
   "source": [
    "#### Training the Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4778c656-e217-4e4e-9f42-760b9c6faae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a46ba41f-94dc-4a4b-9b3e-f2a84aa52370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23c302b0-f002-4ab4-87cf-e8e48f242683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13a884d3-3b93-43d9-99b5-45441d8ef681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.5671 - mae: 0.9036 - val_loss: 1.4726 - val_mae: 0.5687\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5997 - mae: 0.5385 - val_loss: 1.1946 - val_mae: 0.5207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x275cc46c8d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782fa0a5-a547-4602-865e-6013453cf852",
   "metadata": {},
   "source": [
    "#### Saving and Loading the Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54a38d70-6328-45eb-9f34-9e4b21da489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\initializers\\__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'function'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\regularizers.py:426: UserWarning: The `keras.regularizers.serialize()` API should only be used for objects of type `keras.regularizers.Regularizer`. Found an instance of type <class 'function'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "C:\\Python 3.11\\Lib\\site-packages\\keras\\src\\constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'function'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92bf231e-8c66-4351-9e3a-fca5c9bf2626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.keras\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba61afa-963b-4ec0-b606-7fc806ac131e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b4e739e-3594-466b-bfe4-3abd3ca10461",
   "metadata": {},
   "source": [
    "#### Implementing Subclassing API for custom functions that have hyperparameters that need to be saved separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df4bdc-b477-4ede-a3b9-b09e0fe9e66f",
   "metadata": {},
   "source": [
    "If a function has hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class, such as keras.regularizers.Regularizer, keras.constraints.Constraint, keras.initializers.Initializer, or keras.layers.Layer (for any layer, including activation functions). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255220ee-13f7-4800-bdf4-32685341bd52",
   "metadata": {},
   "source": [
    "##### Implementing Subclassing API for Custom Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc6a91-82f8-4cc6-85c0-99f2d79086e6",
   "metadata": {},
   "source": [
    "Much like we did for the custom loss, here is a simple class for ℓ1 regularization that saves its factor hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af65f5f-8177-495c-896a-e40a48776e50",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE ABOUT THE REGULARIZER SUBCLASS API!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "(this time we do not need to call the parent constructor or the get_config() method, as they are not defined by the parent class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "347081ea-8add-4bc0-84f3-c8a14d487b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ce582fc-70c3-4c9a-9165-153ee9b9ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "273879bb-d347-4021-b9ce-efd0d3074f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ac2e240-ce0a-4f78-addd-571b9b1aa9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c9ba5a0-ac74-4c52-b08a-be812add4be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.8643 - mae: 0.9571 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6662 - mae: 0.5244 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x275cc6d2350>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae7f3eea-cfc8-44fe-828d-ea3003047af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts_and_subclassingAPI.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe8df91b-0ef7-432f-9e0e-e5bec07f91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts_and_subclassingAPI.keras\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53d46a-d3cc-4ee7-b7a0-c4472208a5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09763f02-b256-4738-b9b0-ff2b5ac0fddf",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c5be1-926b-44bc-8d3a-3809ec99be83",
   "metadata": {},
   "source": [
    "Losses and metrics are conceptually not the same thing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8a74f-cc43-46b6-a71d-6ab511e2d977",
   "metadata": {},
   "source": [
    "#### Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2cdf9-c3e3-47cb-8fee-ef6c7f1e96ba",
   "metadata": {},
   "source": [
    "Losses (e.g., cross entropy) are used by Gradient Descent to train a model, so they must be differentiable (at least where they are evaluated), and their gradients should not be 0 everywhere. Plus, it’s OK if they are not easily interpretable by humans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c3ce1-cbfe-4874-abef-396ea2756b78",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bdfa3e-73b2-4cbb-946d-ae3169f4cf7b",
   "metadata": {},
   "source": [
    "Metrics (e.g., accuracy) are used to evaluate a model: they must be more easily interpretable, and they can be non-differentiable or have 0 gradients everywhere.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7f76c-2b21-4b69-b41d-a60cf2682e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62164f75-cadb-4150-866d-55a8ebf6aed5",
   "metadata": {},
   "source": [
    "#### Metrics and Losses Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1078012e-95c4-42cd-95c4-f67b52598e1a",
   "metadata": {},
   "source": [
    "That said, in most cases, defining a custom metric function is exactly the same as defining a custom loss function. In fact, we could even use the Huber loss function we created earlier as a metric; it would work just fine (and persistence would also work the same way, in this case only saving the name of the function, \"huber_fn\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9124c81-5d22-4321-966a-0dfebaa8e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d621a-774b-4ba6-84af-0a36cfc1c5d6",
   "metadata": {},
   "source": [
    "For each batch during training for the model defined above, Keras will compute this metric and keep track of its mean since the beginning of the epoch. Most of the time, this is exactly what you want, BUT NOT ALWAYS!! IN THE BELOW SUBSECTION  Metrics and Losses DIFFERENCE!!! WE SEE A SCENARIO THAT HIGHLIGHTS THE DIFFERENCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d940c7-ab8f-467a-b03e-bca17729414f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78966d36-9aa1-4cf4-b1f1-95f5ac6d60ca",
   "metadata": {},
   "source": [
    "#### Metrics and Losses DIFFERENCE!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7432897-d0c6-4862-a80f-0ba1774a0aee",
   "metadata": {},
   "source": [
    "Consider a binary classifier’s precision, for example. As we saw in Chapter 3, precision is the number of true positives divided by the number of positive predictions (including both true positives and false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb9335-c068-4ce1-825e-5310bd71d274",
   "metadata": {},
   "source": [
    "Suppose the model made five positive predictions in the first batch, four of which were correct: that’s 80% precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4316843-395a-48dc-a52c-28b9cdd6cc88",
   "metadata": {},
   "source": [
    "Then suppose the model made three positive predictions in the second batch, but they were all incorrect: that’s 0% precision for the second batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f301a28-64b1-4630-aab3-84ed6791c4b4",
   "metadata": {},
   "source": [
    "If you just compute the mean of these two precisions, you get 40%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5ed04-05ec-4698-beb4-7f86b1baf1d5",
   "metadata": {},
   "source": [
    "But wait a second—that’s not the model’s precision over these two batches! Indeed, there were a total of four true positives (4 + 0) out of eight positive predictions (5 + 3), so the overall precision is 50%, not 40%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a887ccd-6b11-4690-9876-0695d3344e80",
   "metadata": {},
   "source": [
    "What we need is an object that can keep track of the number of true positives and the number of false positives and that can compute their ratio when requested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97baa0e6-1010-4657-a98f-e654f4591197",
   "metadata": {},
   "source": [
    "##### This is precisely what the keras.metrics.Precision class does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3290cae4-5e9b-429d-9039-81b6f8ff7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = keras.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aa1db4d-9ea8-4c65-a766-cc4601a903a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "808c3f31-6c07-402d-ac31-6aacb8a1435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3414a0bb-974d-483f-83ab-ec4b9c5cd7fe",
   "metadata": {},
   "source": [
    "#### Explanation of Precision object of the keras.metrics.Precision created in the above example!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a5b509-1e73-414a-ad7f-404fe37fd96a",
   "metadata": {},
   "source": [
    "In this example, we created a Precision object, then we used it like a function, passing it the labels and predictions for the first batch, then for the second batch (note that we could also have passed sample weights)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649c8880-078b-4616-88da-cc33a670b590",
   "metadata": {},
   "source": [
    "We used the same number of true and false positives as in the example we just discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa7e39-8036-4a32-871d-51663fcd85f4",
   "metadata": {},
   "source": [
    "#### IMPORTANT POINT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "After the first batch, it returns a precision of 80%; then after the second batch, it returns 50% (which is the overall precision so far, not the second batch’s precision).\n",
    "\n",
    "This is called a streaming metric (or stateful metric), as it is gradually updated, batch after batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01145573-3499-4ee3-9a40-75223fb5a5ea",
   "metadata": {},
   "source": [
    "#### Precision Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee006cf-0ebd-4b2b-aa7a-eb60b278218d",
   "metadata": {},
   "source": [
    "At any point, we can call the result() method to get the current value of the metric. We can also look at its variables (tracking the number of true and false positives) by using the variables attribute, and we can reset these variables using the reset_states() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "452efaac-940a-45ec-96cc-dc25947a31ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7691f519-9d65-4cb5-9654-85f8f2409a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4912685-e7e2-45c2-8d21-f1a9be4a0103",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states() # both variables get reset to 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19334621-666e-47e3-a817-d9de61acd2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680d7ea-a984-48c9-af6a-13e81f6a9394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0b89497-4b92-4b3c-b071-6e526abb6f35",
   "metadata": {},
   "source": [
    "### Creating a Streaming Metric using Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffff12c-570d-4881-8ed8-7e790f7de29a",
   "metadata": {},
   "source": [
    "If you need to create such a streaming metric, create a subclass of the keras.metrics.Metric class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8404a2cc-fc64-491e-8455-0ba2e8be277b",
   "metadata": {},
   "source": [
    "Here is a simple example that keeps track of the total Huber loss and the number of instances seen so far. When asked for the result, it returns the ratio, which is simply the mean Huber loss:\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c798de5d-2163-40b3-b9a2-cde8d0c14dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    \n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "\n",
    "    \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bf123-9eb0-4934-80ef-60dd40250ae5",
   "metadata": {},
   "source": [
    "#### Working of the Code!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95404e4-49b7-4081-ab41-ecd28c057c14",
   "metadata": {},
   "source": [
    "1) The constructor uses the add_weight() method to create the variables which are self.total and self.count needed to keep track of the metric’s state over multiple batches—in this case, the sum of all Huber losses (total) and the number of instances seen so far (count). You could just create variables manually if you preferred. Keras tracks any tf.Variable that is set as an attribute (and more generally, any “trackable” object, such as layers or models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af189358-bc24-4f14-8875-dcaf6bf35633",
   "metadata": {},
   "source": [
    "2) The update_state() method is called when you use an instance of this class as a function (as we did with the Precision object and what we do when write model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)]), here metrics=[HuberMetric(2.0)] means we are using the instance metrics as a function.). It updates the variables which are the total and the count, given the labels and predictions for one batch (and sample weights, but in this case we ignore them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ee492-c31b-4ceb-b4b7-58cf3d8b4426",
   "metadata": {},
   "source": [
    "3) The result() method computes and returns the final result, in this case the mean Huber metric over all instances. When you use the metric as a function, the update_state() method gets called first, then the result() method is called, and its output is returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232ab696-b8b0-4998-b993-9b274690f190",
   "metadata": {},
   "source": [
    "4) We also implement the get_config() method to ensure the threshold gets saved along with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed529e75-c229-4892-9208-6961b74dfb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "512be1ca-1455-4058-82b2-87c87d40db0c",
   "metadata": {},
   "source": [
    "#### Training a model with this custom metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "087982c7-1f59-48a3-a70d-588fe85f136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b03ee6e-8fb3-408b-8908-3c2658fec76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "af28ee82-d30f-4e7e-b66a-5162f0af67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67723742-77c7-4da8-b858-1f28ffa48b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.8065 - huber_metric: 0.8065\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2572 - huber_metric: 0.2572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x275cd770b90>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4531ed75-dff3-4ced-bffa-3f845c25997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a97ebd1-723b-4d0b-a9ef-9778be247b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric.keras\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e34f50-e3de-4460-b232-e432be0b35f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55334704-fa18-4538-a20d-13847e6b83dc",
   "metadata": {},
   "source": [
    "#### Custom Metrics conclusion\n",
    "When you define a metric using a simple function, Keras automatically calls it for each batch, and it keeps track of the mean during each epoch, just like we did manually. So the only benefit of our HuberMetric class is that the threshold will be saved. But of course, some metrics, like precision, cannot simply be averaged over batches: in those cases, there’s no other option than to implement a streaming metric.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2444b219-e595-4064-8315-ea146a5d8209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3b3555-d7dc-4672-b34a-8702a365b8c7",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd5c71-5257-4579-a7d4-eb9da6c17b36",
   "metadata": {},
   "source": [
    "#### Custom Layer Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176bc007-d88d-4a16-aae2-5b719be27325",
   "metadata": {},
   "source": [
    "You may occasionally want to build an architecture that contains an exotic layer for which TensorFlow does not provide a default implementation. In this case, you will need to create a custom layer. Or you may simply want to build a very repetitive architecture, containing identical blocks of layers repeated many times, and it would be convenient to treat each block of layers as a single layer. For example, if the model is a sequence of layers A, B, C, A, B, C, A, B, C, then you might want to define a custom layer D containing layers A, B, C, so your model would then simply be D, D, D. Let’s see how to build custom layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401be4b-730f-4d82-b9f8-a1a4c77ab152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "591a03d2-53c5-4696-9bf0-43990582a7de",
   "metadata": {},
   "source": [
    "#### Layers without Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa6259-4f3e-4309-a978-a6e8551baff1",
   "metadata": {},
   "source": [
    "First, some layers have no weights, such as keras.layers.Flatten or keras.layers.ReLU. If you want to create a custom layer without any weights, the simplest option is to write a function and wrap it in a keras.layers.Lambda layer. For example, the following layer will apply the exponential function to its inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "709eca90-3926-4272-899d-067a025d4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca8590-6f62-4165-81d1-2fe23108c7d4",
   "metadata": {},
   "source": [
    "This custom layer can then be used like any other layer, using the Sequential API, the Functional API, or the Subclassing API. You can also use it as an activation function (or you could use activation=tf.exp, activation=keras.activations.exponential, or simply activation=\"exponential\"). The exponential layer is sometimes used in the output layer of a regression model when the values to predict have very different scales (e.g., 0.001, 10., 1,000.).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a65ed9a-1d96-4a18-a7c8-245db17f0ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6507 - val_loss: 0.4141\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6393 - val_loss: 0.4175\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4340 - val_loss: 0.3676\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4604 - val_loss: 0.3725\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3991 - val_loss: 0.3617\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37407541275024414"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fbce5-90e6-4f7d-b160-76bcdfc852a1",
   "metadata": {},
   "source": [
    "### Custom Layer with Weights IMPORTANT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05580a8f-3d19-4859-a7d5-3a47627ca335",
   "metadata": {},
   "source": [
    "To build a custom stateful layer (i.e., a layer with weights), you need to create a subclass of the keras.layers.Layer class. For example, the following class implements a simplified version of the Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e15f9446-9940-4949-b6fd-1e049c766ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c5cb5-96f7-43f4-8441-f9d02ab984d0",
   "metadata": {},
   "source": [
    "#### Working of the CODE!!!!\n",
    "In the code, units means the number of neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f49373-863a-4a95-8a6a-9a3d293642ba",
   "metadata": {},
   "source": [
    "#### The Constructor\n",
    "1) The constructor takes all the hyperparameters as arguments (in this example, units and activation), and importantly it also takes a **kwargs argument. It calls the parent constructor, passing it the kwargs: this takes care of standard arguments such as input_shape, trainable, and name. Then it saves the hyperparameters as attributes, converting the activation argument to the appropriate activation function using the keras.activations.get() function (it accepts functions, standard strings like \"relu\" or \"selu\", or simply None). See, it's basically like how you define a layer right?! there you pass all these parameters keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape), so it's like that only, all that you passed like this gets passed to the parent constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b26828-3b4d-458c-80ec-42db4e82efaa",
   "metadata": {},
   "source": [
    "#### The build() method IMPORTANT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "The build() method’s role is to create the layer’s variables by calling the add_weight() method for each weight. The build() method is called the first time the layer is used. At that point, Keras will know the shape of this layer’s inputs, and it will pass it to the build() method,9 which is often necessary to create some of the weights. For example, we need to know the number of neurons in the previous layer in order to create the connection weights matrix (i.e., the \"kernel\"): this corresponds to the size of the last dimension of the inputs.  At the end of the build() method (and only at the end), you must call the parent’s build() method: this tells Keras that the layer is built (it just sets self.built=True)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61159ed6-3c60-4f76-9f92-645155ba2e97",
   "metadata": {},
   "source": [
    "#### The call() method IMPORTANT!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "The call() method performs the desired operations. In this case, we compute the matrix multiplication of the inputs X and the layer’s kernel, we add the bias vector, and we apply the activation function to the result, and this gives us the output of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b30e8-0e7e-4a40-9705-e81d42a7a6d5",
   "metadata": {},
   "source": [
    "#### The compute_output_shape() method\n",
    "The compute_output_shape() method simply returns the shape of this layer’s outputs. In this case, it is the same shape as the inputs, except the last dimension is replaced with the number of neurons in the layer. Note that in tf.keras, shapes are instances of the tf.TensorShape class, which you can convert to Python lists using as_list().\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "An example is, suppose you are calling it for the second layer and it has 100 neurons or units, now suppose the first layer has 300 neurons and the batch size is 500. Now when this second layer got the input, the shape of the input was (500,300) so this layer's 100 neurons had connection to the first layer's 300 neurons. Now after the call method when we have computed the output of this layer, we only have 100 left, since there are just 100 neurons in this layer, hence the shape that will be passed onto the next layer will be (500,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69ae9d-8e75-4e33-99b3-e116bbae0df0",
   "metadata": {},
   "source": [
    "#### The get_config() method\n",
    "The get_config() method is just like in the previous custom classes. Note that we save the activation function’s full configuration by calling keras.activations.serialize()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af94b68f-28c1-464a-926f-a467b224cbb2",
   "metadata": {},
   "source": [
    "#### You can now use a MyDense layer just like any other layer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303baca-45bf-4d14-83ff-7971bd70e0dc",
   "metadata": {},
   "source": [
    "#### Training a model with Custom Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c25d4958-e793-4cf2-8d67-c90a4f5007bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff62eb60-8e69-4039-9da3-af2ebf5f710f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 1.3076 - val_loss: 0.7839\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5938 - val_loss: 0.6507\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 0.4902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4902033507823944"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f65c599c-2e54-498a-9d19-0e8b0e8b573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd0c8736-b372-42f8-b00c-7a716c752085",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.keras\",\n",
    "                                custom_objects={\"MyDense\": MyDense})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31d60a-d160-4e0d-8bfe-090b84f1d0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a173ab-e48a-421d-9238-95efe71d7814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6460a01-d51f-4968-8063-3aba905f3d91",
   "metadata": {},
   "source": [
    "### Custom Dynamic Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7febb3-8036-42c8-a4ee-b8752e94b149",
   "metadata": {},
   "source": [
    "To create a layer with multiple inputs (e.g., Concatenate), the argument to the call() method should be a tuple containing all the inputs, and similarly the argument to the compute_output_shape() method should be a tuple containing each input’s batch shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e05e8-94e9-4f0e-8669-ebff33f90da9",
   "metadata": {},
   "source": [
    "To create a layer with multiple outputs, the call() method should return the list of outputs, and compute_output_shape() should return the list of batch output shapes (one per output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7f8fe-d53a-4142-b27f-a5c1e64f10c1",
   "metadata": {},
   "source": [
    " For example, the following toy layer takes two inputs and returns three outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12eac32e-4234-4da0-95d5-5c4a7cac462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging of custom layer\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff7d90-572a-440c-8755-9306ad0b1ac1",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE FOR THE ABOVE CODE!!!!!!!!!!!!!!!!!!\n",
    "See that we're just returning the batch shape and not adding the self.units or the number of neurons, or in the call() we are not performing the operation of input multiplied by weights plus the bias that is because this code is only showing the changes we need to make, there are no other things that were there in the previous one like the __init__ method and all so we didn't add the self.units in the compute_output_shape() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffcc320-55d1-48ca-a1b3-e0f086efee50",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE ABOUT CUSTOM DYNAMIC LAYER!!!!!!!!!!!!!\n",
    "This layer may now be used like any other layer, but of course only using the Functional and Subclassing APIs, not the Sequential API (which only accepts layers with one input and one output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfae21-ec53-404d-9134-a92613dbd2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0a3c28-7210-4803-b596-1ec91db2c1e3",
   "metadata": {},
   "source": [
    "### Custom Layer with different behaviour during Training and Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44063d17-2bcd-41bb-b3b7-1995ed524df2",
   "metadata": {},
   "source": [
    "If your layer needs to have a different behavior during training and during testing (e.g., if it uses Dropout or BatchNormalization layers), then you must add a train ing argument to the call() method and use this argument to decide what to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4671a-c291-4af2-aab8-7183b93e2e10",
   "metadata": {},
   "source": [
    "For example, let’s create a layer that adds Gaussian noise during training (for regularization) but does nothing during testing (Keras has a layer that does the same thing, keras.layers.GaussianNoise):\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8cf2662-67c8-4b54-a86f-e88a88204437",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266962d-dcb5-43c1-97cc-03e5790bfab4",
   "metadata": {},
   "source": [
    "#### IMPORTANT NOTE FOR THE ABOVE CODE!!!!!!!!!!!!!!!!!!\n",
    "See that we're just returning the batch shape and not adding the self.units or the number of neurons, or in the call() we are not performing the operation of input multiplied by weights plus the bias that is because this code is only showing the changes we need to make, there are no other things that were there in the previous one like the __init__ method and all so we didn't add the self.units in the compute_output_shape() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d88f95-239d-423c-99cc-d8b80ba5cfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8450ffc6-03c8-4884-ad08-cb229baacf17",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c654e21-3b14-4b39-ac87-689700baa352",
   "metadata": {},
   "source": [
    "It’s straightforward: subclass the keras.Model class, create layers and variables in the constructor, and implement the call() method to do whatever you want the model to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413af748-e666-437a-aa44-22c2085446b9",
   "metadata": {},
   "source": [
    "#### Scenario Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a550a96-2fc6-4c5e-a44f-c318c80244ed",
   "metadata": {},
   "source": [
    "Suppose you want to build the model where, The inputs go through a first dense layer, then through a residual block(a residual block adds its inputs to its outputs) composed of two dense layers and an addition operation, then through this same residual block three more times, then through a second residual block, and the final result goes through a dense output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247412db-d895-4ab1-a460-ea12038f0f5a",
   "metadata": {},
   "source": [
    "Note that this model does not make much sense; it’s just an example to illustrate the fact that you can easily build any kind of model you want, even one that contains loops and skip connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc34730-0296-4fb0-99ee-9b464c7cdfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a3c5057-6dda-4d16-960a-82a426cf016a",
   "metadata": {},
   "source": [
    "### Implementing the Custom Residual Layer for the Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab515b-5e2e-42aa-86b0-7d3d9d1c91b9",
   "metadata": {},
   "source": [
    "To implement this model, it is best to first create a ResidualBlock layer, since we are going to create a couple of identical blocks (and we might want to reuse it in another model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "97fc3f39-3dfb-4572-b30b-270bac53d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\", kernel_initializer=\"he_normal\") for _ in range(n_layers)]\n",
    " \n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e9e265-beef-40f3-9340-828c8eca5da2",
   "metadata": {},
   "source": [
    "#### Explanation of the Code Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45107140-493b-4de7-9998-15c7e8ecc7f8",
   "metadata": {},
   "source": [
    "1) This layer is a bit special since it contains other layers. This is handled transparently by Keras: it automatically detects that the hidden attribute contains trackable objects (layers in this case), that means that it automatically detects that this layer is composed of multiple layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a177fbd-aecf-4e9a-a42c-2da2620c621a",
   "metadata": {},
   "source": [
    "2) So their variables are automatically added to this layer’s list of variables, which are the weights and all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c78622-bf11-4dc6-a15b-3342bd0313de",
   "metadata": {},
   "source": [
    "3) Also note that output of the residual layer is inputs + Z, this is because of what a residual layer does as mentioned before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fc79b-24b0-4bc4-9756-ecb7fadd8c1c",
   "metadata": {},
   "source": [
    "### Defining the Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ced1c-eb17-4a36-b3c2-ac64d58b5b2c",
   "metadata": {},
   "source": [
    "Next, let’s use the Subclassing API \n",
    "to define the model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94630ce6-566f-4104-8640-19b81defd6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3c5d4a-6d40-404e-a0bd-34bca11d38f3",
   "metadata": {},
   "source": [
    "1) Now pay attention to the for _ in range(1 + 3):\n",
    " Z = self.block1(Z) in the above block, this was done purely because of the scenario that was defined before, where then through this same residual block three more times part was written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48401d-12cb-4c1e-8140-c361fbd8ba04",
   "metadata": {},
   "source": [
    "#### Explanation of the code block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464d970-be0b-4cfa-892e-8c125d32fb7b",
   "metadata": {},
   "source": [
    "We create the layers in the constructor and use them in the call() method. This model can then be used like any other model (compile it, fit it, evaluate it, and use it to make predictions). If you also want to be able to save the model using the save() method and load it using the keras.models.load_model() function, you must implement the get_config() method (as we did earlier) in both the ResidualBlock class and the ResidualRegressor class. Alternatively, you can save and load the weights using the save_weights() and load_weights() methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f601a9-3c36-4245-a662-6f62b5f23387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3019d4b9-84e1-4603-9794-78aad2ad81dc",
   "metadata": {},
   "source": [
    "### Notes and Discussion about the Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56077905-7a90-486b-9fcd-23eee30fb176",
   "metadata": {},
   "source": [
    "The Model class is a subclass of the Layer class, so models can be defined and used exactly like layers. But a model has some extra functionalities, including of course its compile(), fit(), evaluate(), and predict() methods (and a few variants), plus the get_layers() method (which can return any of the model’s layers by name or by index) and the save() method (and support for keras.models.load_model() and keras.models.clone_model())."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed3911-840c-41c1-a5c6-d042ddf5a763",
   "metadata": {},
   "source": [
    "### Intersting Take on Model Class and Layer Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5defe0a2-2458-451f-b59c-f2f26bb4979b",
   "metadata": {},
   "source": [
    "If models provide more functionality than layers, why not just define every layer as a model? Well, technically you could, but it is usually cleaner to distinguish the internal components of your model (i.e., layers or reusable blocks of layers) from the model itself (i.e., the object you will train). This means that the Residual layer defined in the above example that should subclass the Layer class, while the Model defined in the above example that is ResidualRegressor should subclass the Model class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52313f4f-f0a0-4fa9-abb1-0b396c61a0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14f8e64e-7fbd-49d3-bb4b-30c3c8f934b5",
   "metadata": {},
   "source": [
    "## Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008757c-4d03-4643-85ef-2cecb4623753",
   "metadata": {},
   "source": [
    "The custom losses and metrics we defined earlier were all based on the labels and the predictions (and optionally sample weights). There will be times when you want to define losses based on other parts of your model, such as the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a190cbe-69b1-45de-b329-f9ea3864775e",
   "metadata": {},
   "source": [
    "To define a custom loss based on model internals you do as follows:- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0ca9b5-7920-438b-b415-1d259e587521",
   "metadata": {},
   "source": [
    "1) compute it based on any part of the model you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60d26c-15f2-43d3-91b2-091dbd129316",
   "metadata": {},
   "source": [
    "2) Then pass the result to the add_loss() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2674fe8-996c-4e0d-963e-e0ad148bf763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaa1be6c-2e72-4e7b-8978-c8f4e7108a53",
   "metadata": {},
   "source": [
    "### Scenario for Losses on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7734c6-cda1-47cb-b463-09e9aa5bc155",
   "metadata": {},
   "source": [
    "For example, let’s build a custom regression MLP model composed of a stack of five hidden layers plus an output layer. This custom model will also have an auxiliary output on top of the upper hidden layer. The loss associated to this auxiliary output will be called the reconstruction loss, this reconstruction loss is the mean squared difference between the reconstruction and the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed32cd-b197-4a69-9589-383b0b639eeb",
   "metadata": {},
   "source": [
    "By adding this reconstruction loss to the main loss, we will encourage the model to preserve as much information as possible through the hidden layers—even information that is not directly useful for the regression task itself. In practice, this loss sometimes improves generalization (it is a regularization loss). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4d473-bef9-448d-86fa-76cc8091e9a3",
   "metadata": {},
   "source": [
    "Here is the code for this custom model with a custom reconstruction loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f25e1434-5a5b-467c-b614-68830f7fea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        \n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        # super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa51b8-a0cf-49f4-9f52-3ec022553612",
   "metadata": {},
   "source": [
    "#### Let's walk through the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a9c0c-d64a-44dc-ba38-ab36c1c53027",
   "metadata": {},
   "source": [
    "1) The constructor creates the DNN with five dense hidden layers and one dense output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a967e-c7c5-4429-98e6-78ee46f65d73",
   "metadata": {},
   "source": [
    "2) The build() method creates an extra dense layer which will be used to reconstruct the inputs of the model. It must be created here because its number of units must be equal to the number of inputs, and this number is unknown before the build() method is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be054e2-da14-4cd5-b506-42e7aaf8e6a9",
   "metadata": {},
   "source": [
    "3) The call() method processes the inputs through all five hidden layers, then passes the result through the reconstruction layer, which produces the reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73674570-6d48-40dd-88d5-9a2ed67ce910",
   "metadata": {},
   "source": [
    "#### Important!!!\n",
    "4) Then the call() method also computes the reconstruction loss (the mean squared difference between the reconstruction and the inputs), and adds it to the model’s list of losses using the add_loss() method. Notice that we scale down the reconstruction loss by multiplying it by 0.05 (this is a hyperparameter you can tune). This ensures that the reconstruction loss does not dominate the main loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86efbed5-bb64-488a-9d49-9fcf0a7c5b2e",
   "metadata": {},
   "source": [
    "##### Note about the add_loss method\n",
    "You can also call add_loss() on any layer inside the model, as the model recursively gathers losses from all of its layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbc7160-1c66-45f3-a584-c1583d3d36ea",
   "metadata": {},
   "source": [
    "5) Finally, the call() method passes the output of the hidden layers to the output layer and returns its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31623581-1e58-46d7-bd40-c13aaf949576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3d55c9f-b178-4761-8326-2daf0cbff8a2",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bade8071-0e8f-4983-8862-b3c4099ae40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f1a49237-1398-4a98-a517-7e529b737e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 2ms/step - loss: 0.7689\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4082\n",
      "162/162 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb17658-44fe-453d-b190-4016e288da80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89ab6cef-3d87-4640-ac7a-b2f0f509a062",
   "metadata": {},
   "source": [
    "### For Metrics on Model Internals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3a884-0a5a-4f83-bd5e-15d32a315bfe",
   "metadata": {},
   "source": [
    "Similarly, you can add a custom metric based on model internals by computing it in any way you want, as long as the result is the output of a metric object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cba48-f70a-4e43-8f04-82a031ca29b8",
   "metadata": {},
   "source": [
    "For example, you can create a keras.metrics.Mean object in the constructor, then call it in the call() method, passing it the recon_loss, and finally add it to the model by calling the model’s add_metric() method. This way, when you train the model, Keras will display both the mean loss over each epoch (the loss is the sum of the main loss plus 0.05 times the reconstruction loss) and the mean reconstruction error(the metric) over each epoch. Both will go down during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "91eb9c58-00b3-4957-9b26-e273bcda2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\") #This part was added for the metric, not there in the loss described before\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        # super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "\n",
    "        \n",
    "        if training: #This part was added for the metric, not there in the loss described before\n",
    "            result = self.reconstruction_mean(recon_loss) #This part was added for the metric, not there in the loss described before\n",
    "            self.add_metric(result) #This part was added for the metric, not there in the loss described before\n",
    "\n",
    "        \n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ef113f8-b4e3-40e0-9975-19e19a816bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02d898d5-39d5-4f03-8d6f-5734ca0b15f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 2ms/step - loss: 0.6959 - reconstruction_error: 0.7893\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4226 - reconstruction_error: 0.3597\n",
      "162/162 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41466049-9485-4060-8bdb-1b0487d6d6f3",
   "metadata": {},
   "source": [
    "#### In the above code you can see the reconstruction_error which is basically the metric that was not there before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f695fd01-652f-4998-9afe-a7ce14fb5505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4dcfc25-f488-4cf1-8aed-ecd1ccf16378",
   "metadata": {},
   "source": [
    "## Computing Gradients Using Autodif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39d2f0-cedb-4582-8255-cc2507c71935",
   "metadata": {},
   "source": [
    "#### First let's have a look at partial derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed570aa1-aa19-40df-aab4-519628954046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_dev_func(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b60e4-cddb-4e54-9ed5-e8535dafeb5c",
   "metadata": {},
   "source": [
    "If you know calculus, you can analytically find that the partial derivative of this function with regard to w1 is 6 * w1 + 2 * w2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6f29a-b9f1-4af6-8f13-0f14e86bd3ee",
   "metadata": {},
   "source": [
    "You can also find that its partial derivative with regard to w2 is 2 * w1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75154642-2b10-4775-ab2c-90d56ba20b00",
   "metadata": {},
   "source": [
    "Let's try implementing the an approximation of each partial derivative by measuring how much the function’s output changes when you tweak the corresponding parameter a little, which is the eps that we have added below using the part_dev_func that we defined before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "79b3e012-7175-4f72-8a0e-5af8c950725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = 5, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15498ffa-c91f-4f4a-b7e4-cc58c7c9495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69697575-2d32-44b8-bb0e-6a5a580777f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(part_dev_func(w1 + eps, w2) - part_dev_func(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "10009e8f-c6a1-4a92-a3e1-de09e5a38727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(part_dev_func(w1, w2 + eps) - part_dev_func(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807ad06e-71b8-47d0-ab13-fd8a9e4712d4",
   "metadata": {},
   "source": [
    "As you can see, at the point (w1, w2) = (5, 3), these partial derivatives are equal to 36 and 10, respectively, so the gradient vector at this point is (36, 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e952034-cf8c-4980-a805-598740067636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07586a9d-5c68-4f44-bed0-fd91aa158c96",
   "metadata": {},
   "source": [
    "### Using Autodiff TensorFlow style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29b596-ab07-4daa-8762-eac8b49c506d",
   "metadata": {},
   "source": [
    "In the above example we computed the partial derivative, But if this were a neural network, the function would be much more complex, typically with tens of thousands of parameters, and finding the partial derivatives analytically by hand would be an almost impossible task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949ec61-2c57-4627-9e31-cc4ec5644081",
   "metadata": {},
   "source": [
    "Also, it is just an approximation, and importantly you need to call f() at least once per parameter (not twice, since we could compute f(w1, w2) just once). This means that when you are computing the partial derivative let's say w.r.t the parameter w1, you will differentiate w.r.t just w1 right?! so you don't need to call f(w1,w2) twice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e20e830-3868-4ab0-838a-6ff6562d28c3",
   "metadata": {},
   "source": [
    "TensorFlow makes autodiff pretty simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ddc3f751-9631-462f-9786-5c399ba04594",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc6eca6d-44e3-4028-bf2c-5a9058ed307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = part_dev_func(w1,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "01ebe6cf-4c2e-46f3-a03b-90f1ae4e813f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=105.0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z # The output will be 105 which will be the result if you plug in 5 and 3 in w1 and w2 in the equation 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "62509d23-0968-4e59-a4e9-56788af6f185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients = tape.gradient(z, [w1, w2])\n",
    "gradients\n",
    "# 1)  Here the output for the first case is 36 which comes after you partially differentiate the equation 3 * w1 ** 2 + 2 * w1 * w2 w.r.t to w1 and then you get 6 * w1 + 2 * w2, and then you plug in the values of w1 and w2.\n",
    "\n",
    "# 2)  Here the output for the second case is 10 which comes after you partially differentiate the equation 3 * w1 ** 2 + 2 * w1 * w2 w.r.t to w2 and then you get  2 * w1, and then you plug in the values of w1 and w2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c29c3e-c9c2-41e6-b19e-a62f47c7e980",
   "metadata": {},
   "source": [
    "#### Working of the above code\n",
    "We first define two variables w1 and w2, then we create a tf.GradientTape context that will automatically record every operation that involves a variable, and finally we ask this tape to compute the gradients of the result z with regard to both variables [w1, w2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66bec3-28f5-4715-a3c6-13358be3f9b6",
   "metadata": {},
   "source": [
    "#### The Gradient Tape\n",
    "Perfect! Not only is the result accurate (the precision is only limited by the floatingpoint errors), but the gradient() method only goes through the recorded computations ONCE!!!! (in reverse order), no matter how many variables there are, so it is incredibly efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcf20e-bc30-4e9b-a919-e1b208e6a47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b44ff9-27eb-469f-a15d-a77caca3f2e6",
   "metadata": {},
   "source": [
    "#### Warning Gradient Tape\n",
    "To save memory, only put the strict minimum inside the tf.GradientTape() block. Alternatively, pause recording by creating a with tape.stop_recording() block inside the tf.GradientTape() block."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333c33d-d956-4f5b-b517-d28255bf5f84",
   "metadata": {},
   "source": [
    "#### IMPORTANT WARNING TAPE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "The tape is automatically erased immediately after you call its gradient() method, so you will get an exception if you try to call gradient() twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd49d96-78a4-4f49-8d49-bd02f9d38c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7888a09-b561-4ce2-ab65-95e82034f3c6",
   "metadata": {},
   "source": [
    "#### Persisting the TAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6fe0f-c83c-4b5c-8827-55186a49059d",
   "metadata": {},
   "source": [
    "If you need to call gradient() more than once, you must make the tape persistent and delete it each time you are done with it to free resources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cdf758-3714-458e-b6a2-0b590afd415b",
   "metadata": {},
   "source": [
    "If the tape goes out of scope, for example when the function that used it returns, Python’s garbage collector will delete it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aabe9783-3d79-4895-94ec-50abb645d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = part_dev_func(w1,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0f7fa846-fd6f-49f1-a237-191825efea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz_dw1 = tape.gradient(z, w1) # => tensor 36.0\n",
    "dz_dw2 = tape.gradient(z, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8f0656fb-bf4c-4702-a113-2c4e40ec8596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=36.0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a077812-0a20-4df4-a434-825e6c0a9f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "337d0896-ad92-425f-8392-e07dbbc7c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c45718-aadb-41ca-97f7-7c6e124050cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "327ab6df-4f20-4566-b1a0-4769117f90bd",
   "metadata": {},
   "source": [
    "#### Tape with Constants and watching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfa90a-38c5-45fc-9b61-3cb6d96888e0",
   "metadata": {},
   "source": [
    "By default, the tape will only track operations involving variables, so if you try to compute the gradient of z with regard to anything other than a variable, the result will be None:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f014af22-aa6e-4eef-ac09-a54c85bde20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = part_dev_func(c1, c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ca90ca1-d361-4486-a9a8-98291931bffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients = tape.gradient(z, [c1, c2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391a447-837b-48f7-b1c0-64f4cf6d94b1",
   "metadata": {},
   "source": [
    "However, you can force the tape to watch any tensors you like, to record every operation that involves them. You can then compute gradients with regard to these tensors, as if they were variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "236752c8-574d-4d0d-8884-cf5da09d5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = part_dev_func(c1, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "789f2121-691b-4f80-8a21-a51df9c2ac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients = tape.gradient(z, [c1, c2])\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262c3175-9589-4211-b8b5-640eacf58025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c43991e4-d188-4fdb-937c-ddbcc5acce1c",
   "metadata": {},
   "source": [
    "#### Uses of Tapes with constant and watching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacf4250-d752-46d6-8c64-62678c7d6943",
   "metadata": {},
   "source": [
    "This can be useful in some cases, like if you want to implement a regularization loss that penalizes activations that vary a lot when the inputs vary little: the loss will be based on the gradient of the activations with regard to the inputs. Since the inputs are not variables, you would need to tell the tape to watch them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da913c-41a4-4f5e-9366-e5867a80ce2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c41a9c9f-5c61-4394-b745-9dac1b1d349d",
   "metadata": {},
   "source": [
    "### Reverse Mode Auto-Diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c60f1d-9bc9-4c2e-aeb7-d545eee908e3",
   "metadata": {},
   "source": [
    "1) Most of the time a gradient tape is used to compute the gradients of a single value (usually the loss, right as you've seen, you perform the gradient descent w.r.t the loss function right) with regard to a set of values (usually the model parameters, for ex you could consider w1 and w2 that we defined before). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a4069-ceee-4f05-83b4-b8d6ae9f7b17",
   "metadata": {},
   "source": [
    "2) This is where reverse-mode autodiff shines, as it just needs to do one forward pass and one reverse pass to get all the gradients at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b331094b-2797-497e-99da-fa3dbddfe339",
   "metadata": {},
   "source": [
    "#### Scenario if you compute the gradient of a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9023dd1-acfb-4479-8b63-aa0b9f267841",
   "metadata": {},
   "source": [
    "1) If you try to compute the gradients of a vector, for example a vector containing multiple losses, then TensorFlow will compute the gradients of the vector’s sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89aafc-06d9-4e54-8127-0bbaa8f0fb71",
   "metadata": {},
   "source": [
    "#### Calculating gradient per parameter of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1480f-e2ab-438a-97a1-8120d82189ab",
   "metadata": {},
   "source": [
    "1) So if you ever need to get the individual gradients (e.g., the gradients of each loss with regard to model's each parameter), you must call the tape’s jacobian() method: it will perform reverse-mode autodiff once for each loss in the vector (all in parallel by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8f4dc-4aba-4274-8697-5fb933d4a6c9",
   "metadata": {},
   "source": [
    "2) It is even possible to compute second-order partial derivatives (the Hessians, i.e., the partial derivatives of the partial derivatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f51da4-4478-4507-8bce-1c1f5c6bf4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3e6383e-38b1-49e2-94c0-95e28f8a1ece",
   "metadata": {},
   "source": [
    "#### Stopping gradients from backpropagating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef301c9-41d8-4475-9a54-6e8fb760ba94",
   "metadata": {},
   "source": [
    "In some cases you may want to stop gradients from backpropagating through some part of your neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c727e-4315-4853-bbe3-fffa36ddb2ab",
   "metadata": {},
   "source": [
    "To do this, you must use the tf.stop_gradient() function. The function returns its inputs during the forward pass (like tf.identity()), but it does not let gradients through during backpropagation (it acts like a constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bb03c73c-8bd0-42bf-bce1-921955d6730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4b8b2599-fce9-4c7b-8793-cd5a1e329a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=105.0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2) \n",
    "z # same result as without stop_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66921b0a-834e-4e09-b740-1233606ed619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients = tape.gradient(z, [w1, w2]) \n",
    "gradients # => returns [tensor 30., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d76006-bfde-4457-b33b-25fa733c6caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c3b363-e2ed-464c-b311-5963a84aa23c",
   "metadata": {},
   "source": [
    "## Custom Gradients for specific issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3d3891-6e08-459b-910d-f8fc4b409d12",
   "metadata": {},
   "source": [
    "you may occasionally run into some numerical issues when computing gradients. For example, if you compute the gradients of the my_softplus() function for large inputs, the result will be NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bf47d190-2c02-4e0d-8ecb-d9b668e0f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([100.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aa6d490a-9b56-4493-9796-eb913059a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a2469da-10bb-4e75-9bf2-ad55b55687b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tape.gradient(z, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014fc72-eb71-4a8e-b90a-d5d5917b200a",
   "metadata": {},
   "source": [
    "This is because computing the gradients of this function using autodiff leads to some numerical difficulties: due to floating-point precision errors, autodiff ends up computing infinity divided by infinity (which returns NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c042b73b-66f2-42fa-96b0-cc3807db9fdd",
   "metadata": {},
   "source": [
    "Fortunately, we can analytically find that the derivative of the softplus function is just 1 / (1 + 1 / exp(x)), which is numerically stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db93a8b-097d-4184-8f12-c044d16325a5",
   "metadata": {},
   "source": [
    "Next, we can tell TensorFlow to use this stable function when computing the gradients of the my_softplus() function by decorating it with @tf.custom_gradient and making it return both its normal output and the function that computes the derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0438f23-457a-4b62-85d6-5f558ef8c1e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4802bde9-d349-4f04-9bc4-142b4ccbacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc96e7-de06-465c-8574-3c29217c22fd",
   "metadata": {},
   "source": [
    "note that we are using grad / (1 + 1 / exp) instead of 1 / (1 + 1 / exp(x)) because my_softplus_gradients will receive as input the gradients that were backpropagated so far to the softplus function; and according to the chain rule, we should multiply them with this function’s gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa71938-d489-4860-9ff2-c17155737f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fc6d714-3426-4fdc-9670-42b11eb18bfc",
   "metadata": {},
   "source": [
    "## Custom Training Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e50c81-ab06-4f60-ae94-ba977c0e9c83",
   "metadata": {},
   "source": [
    "In some rare cases, the fit() method may not be flexible enough for what you need to do. For example, the Wide & Deep paper we discussed in Chapter 10 uses two different optimizers: one for the wide path and the other for the deep path. Since the fit() method only uses one optimizer (the one that we specify when compiling the model), implementing this paper requires writing your own custom loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91fcc5-c0e1-45c0-85b0-98ffbc433e6c",
   "metadata": {},
   "source": [
    "#### Important Note about Custom Training Loops\n",
    "You may also like to write custom training loops simply to feel more confident that they do precisely what you intend them to do (perhaps you are unsure about some details of the fit() method). It can sometimes feel safer to make everything explicit. However, remember that writing a custom training loop will make your code longer, more error-prone, and harder to maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54e9eb-6011-41fd-90e1-0dfc2a970b6d",
   "metadata": {},
   "source": [
    "### Building a Custom Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc817e5-c398-4b8c-a72f-7dd72000de73",
   "metadata": {},
   "source": [
    "1) To build a custom training loop with start with first building a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d21569fc-66ea-4c4f-81ac-47d77fba39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([ keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg), keras.layers.Dense(1, kernel_regularizer=l2_reg)])\n",
    "# No need to compile it since we will do the training manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8797d4c-38f9-47b7-955c-a9f2c1af07a9",
   "metadata": {},
   "source": [
    "2) Next, let’s create a tiny function that will randomly sample a batch of instances from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b9c99879-9e15-4c63-ae56-340540072b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b05a0-7222-4cba-a870-325551121ac5",
   "metadata": {},
   "source": [
    "3) Let’s also define a function that will display the training status, including the number of steps, the total number of steps, the mean loss since the start of the epoch (i.e., we will use the Mean metric to compute it), and other metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "54139610-7b71-4ea3-b657-b2e72d6f3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a89442-2b7b-4e04-98b4-7fc95347b034",
   "metadata": {},
   "source": [
    "#### Explanation of the function\n",
    "string formatting: {:.4f} will format a float with four digits after the decimal point, and using \\r (carriage return) along with end=\"\" ensures that the status bar always gets printed on the same line. In the notebook, the print_status_bar() function includes a progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27056fc-f348-46ff-a2e8-4be8c871d3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44d9c43b-dff9-4fa2-b818-6e227729b03d",
   "metadata": {},
   "source": [
    "#### Creating the custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ba259-4e8c-4163-bc34-8c4733426633",
   "metadata": {},
   "source": [
    "1) First, we need to define some hyperparameters and choose the optimizer, the loss function, and the metrics (just the MAE in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "50f14bf0-1c31-486b-94de-2758a1e98b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d6d09-9196-41b8-bf13-df503dafb574",
   "metadata": {},
   "source": [
    "2) And now we are ready to build the custom loop!\r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6a22f43d-6ae6-45f5-b1f8-41c4e67345b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 - mean: 1.4810 - mean_absolute_error: 0.5859\n",
      "Epoch 2/5\n",
      "11610/11610 - mean: 0.6747 - mean_absolute_error: 0.5257\n",
      "Epoch 3/5\n",
      "11610/11610 - mean: 0.6298 - mean_absolute_error: 0.5167\n",
      "Epoch 4/5\n",
      "11610/11610 - mean: 0.6391 - mean_absolute_error: 0.5188\n",
      "Epoch 5/5\n",
      "11610/11610 - mean: 0.6456 - mean_absolute_error: 0.5231\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2238a871-0871-4e53-bb7d-fea6df7b0b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a8011cf-4562-4909-9ee5-47305d3bb888",
   "metadata": {},
   "source": [
    "#### Code walk through."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78698d6-a08f-4464-af81-7d74f97ee1d4",
   "metadata": {},
   "source": [
    "1) • We create two nested loops: one for the epochs, the other for the batches within\r\n",
    "an epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b0df1-b740-4e68-8450-660ef5a58dc8",
   "metadata": {},
   "source": [
    "2) Then we sample a random batch from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6a114-3d63-49ae-8f01-2da876f89475",
   "metadata": {},
   "source": [
    "3) Inside the tf.GradientTape() block, we make a prediction for one batch (using the model as a function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06095e-506b-4070-ad68-151152cca8d8",
   "metadata": {},
   "source": [
    "4) Then we compute the loss: it is equal to the main loss plus the other losses (in this model, there is one regularization loss per layer, the l2 regularizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491be00-815a-48d0-931a-296d4620ea7e",
   "metadata": {},
   "source": [
    "5) Since the mean_squared_error() function returns one loss per instance, we compute the mean over the batch using tf.reduce_mean() (if you wanted to apply different weights to each instance, like for underepresented classes you might want to assign them bigger weights, this is where you would do it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b848f9-79fe-44fd-8b17-277fedaa1f53",
   "metadata": {},
   "source": [
    "6) The regularization losses are already reduced to a single scalar each when we call the model.losses, so we just need to sum them (using tf.add_n(), which sums multiple tensors of the same shape and data type)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6da7cc2-4287-4e59-830c-5978209eb74c",
   "metadata": {},
   "source": [
    "7) Next, we ask the tape to compute the gradient of the loss with regard to each trainable variable (not all variables!), and we apply them to the optimizer to perform a Gradient Descent step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b057c-be4b-46c6-9ae3-6b2446389d60",
   "metadata": {},
   "source": [
    "8) Then we update the mean loss and the metrics which is the mean absolute error, now as you've previously seen before that there is an overlap between the losses and metrics, however you know that the metric is for the streaming result and you want it over the entire training. Then we display the current mean loss and current metric over the current epoch and we display the status bar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b635f5-9a70-4256-a91a-42e87da82143",
   "metadata": {},
   "source": [
    "9) At the end of each epoch, we display the status bar again to make it look complete and to print a line feed, and we reset the states of the mean loss and the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7899c151-040b-4f17-8542-562929cb9755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "958d03f8-6c3a-4826-916c-25898088cb3f",
   "metadata": {},
   "source": [
    "#### To avoid exploding gradients\n",
    "If you set the optimizer’s clipnorm or clipvalue hyperparameter, it will take care of this for you. If you want to apply any other transformation to the gradients, simply do so before calling the apply_gradients() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d913e1f-3215-46bd-8949-4473f158cc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f1253e-6a02-42ff-8a5d-280a93ac7f5f",
   "metadata": {},
   "source": [
    "#### Weights and Bias Constraints\n",
    "If you add weight constraints to your model (e.g., by setting kernel_constraint or bias_constraint when creating a layer), you should update the training loop to apply these constraints just after apply_gradients():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0e698241-ec3e-461e-9651-856636cdfd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in model.variables:\n",
    "    if variable.constraint is not None:\n",
    "        variable.assign(variable.constraint(variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea8848-2e99-40c5-b5cf-277cf3bbe621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d36166f1-af8d-43c2-b286-fbe3ed1d6aa8",
   "metadata": {},
   "source": [
    "#### Model behaviour during Training and Testing\n",
    "\n",
    "Most importantly, this training loop does not handle layers that behave differently during training and testing (e.g., BatchNormalization or Dropout). To handle these, you need to call the model with training=True and make sure it propagates this to every layer that needs it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1372d40-200b-4151-abde-b6c3969c054f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c82b0b3-4ee1-4fdf-b996-881da8c3d4d8",
   "metadata": {},
   "source": [
    "#### Conclusion Custom Training\n",
    "As you can see, there are quite a lot of things you need to get right, and it’s easy to make a mistake. But on the bright side, you get full control, so it’s your call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452781aa-b4e9-4bb3-834d-43bae46fd618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a9cee3-ea06-47cd-b826-4d714e6015be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b30f0b-4a7c-44e8-a9d7-09bfe45559fa",
   "metadata": {},
   "source": [
    "## TensorFlow Functions and Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed56ef-e3f3-445d-ae73-76460a71eca8",
   "metadata": {},
   "source": [
    "In TensorFlow 1, graphs were unavoidable (as were the complexities that came with them) because they were a central part of TensorFlow’s API. In TensorFlow 2, they are still there, but not as central, and they’re much (much!) simpler to use. To show just how simple, let’s start with a trivial function that computes the cube of its input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3195b76e-377f-4dbd-a79b-4f652f18a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ba3cbb-2387-4ad4-a441-ae1276b4ce31",
   "metadata": {},
   "source": [
    "We can obviously call this function with a Python value, such as an int or a float, or we can call it with a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "508fc9df-7a6c-4df6-92b1-f9f7cb1d5465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a2085efa-8b8f-4611-b795-c3da7153096a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d622cca3-24e5-499f-8cd1-bbf1bbd6e6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50fb56d4-daa0-47b3-a0ad-da530bd5e4f1",
   "metadata": {},
   "source": [
    "Now, let’s use tf.function() to convert this Python function to a TensorFlow Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eba2ed6c-8b59-48bf-8dcb-95b0ea915858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x275cd93b110>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b29c2-06f1-4ae7-8f97-7f4f5ea80e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea1c68bd-aaf8-4e09-be96-55fd0cd7d5d4",
   "metadata": {},
   "source": [
    "This TF Function can then be used exactly like the original Python function, and it will return the same result (but as tensors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "437200b1-a473-4d34-a08f-5cc1994f2d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=33925063503334067>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(323723)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "52ac3a01-3c0b-4ae2-9be3-e5420af0990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.4229387e+16>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(242323.42312310))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57ae01b-494d-4b94-bb69-e045ee766f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20726589-7be9-4ab1-bd89-01972e5dcb42",
   "metadata": {},
   "source": [
    "Under the hood, tf.function() analyzed the computations performed by the cube() function and generated an equivalent computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a65c39-7d05-403c-83a3-4ac5b216c39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f8a0964-cd92-4527-b7a7-efeb859ae88f",
   "metadata": {},
   "source": [
    "#### Alternatively, we could have used tf.function as a decorator; this is actually more common: \n",
    "\n",
    "Here if you add the @ decorator, then tensorflow converts the python function to a tf function, and then returns the output in form of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a10c9407-1a5b-47a5-a4df-6431e34a21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b1f63ead-ea7d-4bb9-b86e-b3a4b549a3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=12167>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b5f3f-34da-49b5-9210-3609d4a5400d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d488a5bd-3477-4162-88e8-c4b8f035a556",
   "metadata": {},
   "source": [
    "### TensorFlow Computation Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ad058-498e-4edd-8f98-71ca746fd03e",
   "metadata": {},
   "source": [
    "1) TensorFlow optimizes the computation graph, pruning unused nodes, simplifying expressions (e.g., 1 + 2 would get replaced with 3), and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc866ff7-64cb-4c76-a2d5-9227cac4b9db",
   "metadata": {},
   "source": [
    "2) Once the optimized graph is ready, the TF Function efficiently executes the operations in the graph, in the appropriate order (and in parallel when it can)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e209d-9241-4a3c-80dc-6e2445e16de7",
   "metadata": {},
   "source": [
    "3) As a result, a TF Function will usually run much faster than the original Python function, especially if it performs complex computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9acfa-4937-406b-a84a-d05ba9b4c15e",
   "metadata": {},
   "source": [
    "#### Pro-Tip\n",
    "Where applicable, when you want to boost a Python function, just transform it into a TF Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea88f65-bfa5-4d7e-b84e-bae9d03fc4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc74f57d-3ed5-4124-a819-0360afebad37",
   "metadata": {},
   "source": [
    "#### Moreover, when you write a custom loss function, a custom metric, a custom layer, or any other custom function and you use it in a Keras model (as we did throughout this chapter), Keras automatically converts your function into a TF Function—no need to use tf.function().\r\n",
    "For ex:- remember how you implemented the custom huber loss function, and you passed it in the model's fit method, there tensorflow automatically converted the normal python function to tf.function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3dd575-d4be-4cf8-8797-946f395d0b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2c870d9-7161-402d-89bf-38a139672d41",
   "metadata": {},
   "source": [
    "### IMPORTANT WARNING TENSORFLOW FUNCTIONS GRAPH!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f80e54-4649-4643-96c0-b0b0f028c287",
   "metadata": {},
   "source": [
    "1) By default, a TF Function generates a new graph for every unique set of input shapes and data types and caches it for subsequent calls. For example, if you call tf_cube(tf.constant(10)), a graph will be generated for int32 tensors of shape []. Then if you call tf_cube(tf.constant(20)), the same graph will be reused. But if you then call tf_cube(tf.constant([10, 20])), a new graph will be generated for int32 tensors of shape [2]. This is how TF Functions handle polymorphism (i.e., varying argument types and shapes). However, this is only true for tensor arguments: if you pass numerical Python values to a TF Function, a new graph will be generated for every distinct value: for example, calling tf_cube(10) and tf_cube(20) will generate two graphs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2) If you call a TF Function many times with different numerical Python values, then many graphs will be generated, slowing down your program and using up a lot of RAM (you must delete the TF Function to release it). Python values should be reserved for arguments that will have few unique values, such as hyperparameters like the number of neurons per layer. This allows TensorFlow to better optimize each variant of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe7a24d-3684-4088-b26a-74aa88e57468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "667ab6f4-02b3-4dcb-88ac-8dcec5a4e3d2",
   "metadata": {},
   "source": [
    "## AutoGraph and Tracing\n",
    "\n",
    "### Tracing :- https://www.tensorflow.org/guide/function#tracing\n",
    "\n",
    "#### In a nutshell, when autograph generates the graph, it first traces the original python code which means, it differentiates the normal operations from tensorflow operations, as the normal operations won't be part of the tf.graph(). Now when you read the TF Function Rules section, there I have explained why f(tf.constant(2.)) and f(tf.constant(3.)) will return the same random number.r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a56530-6f4f-4f01-8954-b24486951518",
   "metadata": {},
   "source": [
    "So how does TensorFlow generate graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dd5482-d4dc-4c9c-863a-1b4ac3238444",
   "metadata": {},
   "source": [
    "1) It starts by analyzing the Python function’s source code to capture all the control flow statements, such as for loops, while loops, and if statements, as well as break, continue, and return statements. This first step is called __AutoGraph__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c5a53-f575-4e13-9e5b-ee5445d0ad5b",
   "metadata": {},
   "source": [
    "2) The reason TensorFlow has to analyze the source code is that Python does not provide any other way to capture control flow statements: it offers magic methods like __ add __() and __ mul __() to capture operators like + and *, but there are no __ while __() or __ if __() magic methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51661ec4-a47d-4b07-96bb-35d64600a837",
   "metadata": {},
   "source": [
    "3) After analyzing the function’s code, AutoGraph outputs an upgraded version of that function in which all the control flow statements are replaced by the appropriate TensorFlow operations, such as tf.while_loop() for loops and tf.cond() for if statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00a4fa-c2cf-40b7-8cbe-4b6f6a345c79",
   "metadata": {},
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a6bcc-369f-4044-a1e2-a59f7fdc5b0e",
   "metadata": {},
   "source": [
    "#### Below, we'll see an example of autograph converting a regular python function to tf.function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4fa86f-b385-45aa-b7d1-75e7750a6216",
   "metadata": {},
   "source": [
    "##### First we create a normal python function and add the tf_function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e9e0b50e-3231-404e-9072-158b0e5ffa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def sum_squares(n):\n",
    "    s = 0\n",
    "    for i in tf.range(n+1):\n",
    "        s += i ** 2\n",
    "    return s\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2e998-18a8-4fc2-92c5-b9639eab1876",
   "metadata": {},
   "source": [
    "##### Now we'll see the code that Autograph generates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d9f7beb4-9da9-4319-9451-8807f2740b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__sum_squares(n):\n",
      "    with ag__.FunctionScope('sum_squares', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "        s = 0\n",
      "\n",
      "        def get_state():\n",
      "            return (s,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal s\n",
      "            s, = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal s\n",
      "            i = itr\n",
      "            s = ag__.ld(s)\n",
      "            s += i ** 2\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (ag__.ld(n) + 1,), None, fscope), None, loop_body, get_state, set_state, ('s',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(s)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(sum_squares.python_function))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc038166-270a-4927-95a2-3c4a9f4eeb3d",
   "metadata": {},
   "source": [
    "##### Now we'll mention the steps that were taken by AutoGraph to generate this code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4022b-0c83-4f9b-9554-93f4f829be95",
   "metadata": {},
   "source": [
    "1) AutoGraph analyzes the source code of the sum_squares() Python function, and it generates the tf__ sum_squares() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d462a83-8b76-4160-856d-8e50f6440b4e",
   "metadata": {},
   "source": [
    "2) In this function, the for loop is replaced by the definition of the loop_body() function (containing the body of the original for loop), followed by a call to the for_stmt() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de64a0-d7aa-410c-9946-7e1e46fe067b",
   "metadata": {},
   "source": [
    "3) This call will build the appropriate tf.while_loop() operation in the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bfc98-47c2-4629-92e3-8768aedd13ce",
   "metadata": {},
   "source": [
    "4) Next, TensorFlow calls this “upgraded” function, but instead of passing the argument, it passes a symbolic tensor—a tensor without any actual value, only a name, a data type, and a shape. This point is explained below with an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b08bb3-774d-4da8-923f-e15ce2871a61",
   "metadata": {},
   "source": [
    "4.1) For example, if you call sum_squares(tf.constant(10)), then the tf__ sum_squares() function will be called with a symbolic tensor of type int32 and shape []. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8cb69d-e841-4ff6-bffd-8d47844f740b",
   "metadata": {},
   "source": [
    "4.2) The function will run in graph mode, meaning that each TensorFlow operation will add a node in the graph to represent itself and its output tensor(s) (as opposed to the regular mode, called eager execution, or eager mode). As you saw before, the output is present in the numpy <tf.Tensor: shape=(), dtype=int32, numpy=12167>, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8af2a7-709d-43ba-abd9-b9596ada2f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b059ba1c-6fcb-40c4-9d47-04c68b8ef229",
   "metadata": {},
   "source": [
    "## TF Function Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a013a6-8536-4841-90eb-122b47c0ce70",
   "metadata": {},
   "source": [
    "Most of the time, converting a Python function that performs TensorFlow operations into a TF Function is trivial: decorate it with @tf.function or let Keras take care of it for you. However, there are a few rules to respect:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaac2d7-9734-4abb-8755-b522b97d5aff",
   "metadata": {},
   "source": [
    "1) If you call any external library, including NumPy or even the standard library, this call will run only during tracing; it will not be part of the graph. Indeed, a TensorFlow graph can only include TensorFlow constructs (tensors, operations, variables, datasets, and so on). So, make sure you use tf.reduce_sum() instead of np.sum(), tf.sort() instead of the built-in sorted() function, and so on (unless you really want the code to run only during tracing). This has a few additional implications:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210180ef-1720-4066-bceb-b059a4299280",
   "metadata": {},
   "source": [
    "1.i) If you define a TF Function f(x) that just returns np.random.rand(), a random number will only be generated when the function is traced, so f(tf.constant(2.)) and f(tf.constant(3.)) will return the same random number, because the code has been already traced for f(tf.constant(2.)) and since f(tf.constant(2.)) and f(tf.constant(3.)) have the same datatype, as per the rule of tracing https://www.tensorflow.org/guide/function#rules_of_tracing tracing will not be done again. But f(tf.constant([2., 3.])) will return a different one. If you replace np.random.rand() with tf.random.uniform([]), then a new random number will be generated upon every call, since the operation will be part of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d70c2-35d4-47e5-bfbe-079aed6976c1",
   "metadata": {},
   "source": [
    "1 ii) If your non-TensorFlow code has side effects (such as logging something or updating a Python counter), then you should not expect those side effects to occur every time you call the TF Function, as they will only occur when the function is traced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d0b1c-e935-495f-8b0a-5d66303cbbd6",
   "metadata": {},
   "source": [
    "1 iii) You can wrap arbitrary Python code in a tf.py_function() operation, but doing so will hinder performance, as TensorFlow will not be able to do any graph optimization on this code. It will also reduce portability, as the graph will only run on platforms where Python is available (and where the right libraries are installed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f05237-f80a-44cb-852e-d30503fd7233",
   "metadata": {},
   "source": [
    "2) You can call other Python functions or TF Functions inside you tf.function, but they should follow the same rules, as TensorFlow will capture their operations in the computation graph. Note that these other functions do not need to be decorated with @tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0646415d-f84a-4ce8-9186-9eb9a46e0654",
   "metadata": {},
   "source": [
    "3) If the function creates a TensorFlow variable (or any other stateful TensorFlow object, such as a dataset or a queue), it must do so upon the very first call, and only then, or else you will get an exception. It is usually preferable to create variables outside of the TF Function(e.g., in the build() method of a custom layer). If you want to assign a new value to the variable, make sure you call its assign() method, instead of using the = operator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a72b9-755c-4862-8d25-fc8eef09a77b",
   "metadata": {},
   "source": [
    "4) The source code of your Python function should be available to TensorFlow. If the source code is unavailable (for example, if you define your function in the Python shell, which does not give access to the source code, or if you deploy only the compiled *.pyc Python files to production), then the graph generation process will fail or have limited functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b8cc7-8a38-4d35-baf6-346f2d3c9063",
   "metadata": {},
   "source": [
    "5) TensorFlow will only capture for loops that iterate over a tensor or a dataset. So make sure you use for i in tf.range(x) rather than for i in range(x), or else the loop will not be captured in the graph. Instead, it will run during tracing. (A scenario where you may want the loop to run during tracing could be if the for loop is meant to build the graph, for example to create each layer in a neural network.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4208fe0c-17ce-4bd8-84a5-262b782936bc",
   "metadata": {},
   "source": [
    "6) As always, for performance reasons, you should prefer a vectorized implementation whenever you can, rather than using loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4261d7f-ee76-4023-a7dd-0deb88c80777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b35e36-aebc-441f-9322-22cdce84664e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127e5a9-0fcb-4e49-b188-3d45440861ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e101190-6329-4107-b36b-f699c15b1430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1d29c-c761-497c-9d24-b8e3966f8822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf3c3c-0b5e-49b2-95bc-77ee89276333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bfd439-69ab-4e72-9b42-9ceca95dd437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de88342e-4679-4922-9def-09785cf6089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6afe2-0126-4ffa-a6bc-26d66e03478a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23580e0e-75a3-47f9-94db-b11bcf7405e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f1187-864b-413a-80e9-01e2ad60944f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa491e-c41c-4393-945d-1c669dfa04a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63ab3c-1d23-4d5a-9585-0db6957efcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a53a0-9989-400e-a21f-fabbd392d07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea1b11-dfda-45b3-8aa1-9d191c97015e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd8b1a-ed28-41c3-afa8-93ac39fca3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10525505-b63e-40c9-988c-3a050242fba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d906524-6ef5-4f45-98d4-4087d43cb29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c2f421-69d6-4e3e-896b-514d799ba740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23852d06-c74f-4ef8-a81e-5b5abc6b58a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed37af-029c-4886-b57b-a9a9a9b64e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43aee5f-ba70-4c05-8822-5247df4c3bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d3596-c7bf-4f5b-ae7f-3768ce063b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677adfd-48cb-467e-8db7-c2c0cd8169ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7353c71-64c3-417c-a02a-ba5d1a4f8ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d602c4-4989-4ffa-9ba0-71fb0de3e425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ae844-9d51-493e-bb32-bfe68edc753a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39476f7f-56d9-4e16-9622-0eb36b17767d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c3872-ae1d-4ff9-bb05-9ba8e66c8aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942d6bf-a293-4dc9-8dac-ed5f0d79ef54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db90156-2eda-493a-8ba8-8aac7b5be21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15ccb4-27bb-47c3-915c-0e52ae88a717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db4e5b-6842-4db4-9cfd-f5a50d811b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadabed3-e188-4999-bca1-d70c7fb9fee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0466cb-7e73-40ea-9b93-a770c69ddd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387c952-fd07-41f6-aa36-76fc410b0ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f16c-d594-4716-b05c-27784d641748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2371a4e-4262-4887-856f-8aecd8be1088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f14585-7830-4632-8831-3fb2ed7c9ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820ceb40-a86f-49e4-9a78-1c7b0958931c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b40747-be44-475e-8ae6-a819a3e93409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667d954-efe5-41ba-94eb-0c20fa999d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fb392-ed1d-461f-957b-d8d829343160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0922c1-b89d-40b6-824e-ea89f423b49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae0b6a-59b4-46d1-a743-eed7e1264c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaecaddb-55cd-4418-8ec3-73ef30408b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c38b627-0dc6-4afc-b892-07c21f8ff747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4572694-f9d8-4226-868a-feb50fb0cb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c5588-b08f-43d5-87c3-be82c6c20a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbefd7b3-2c75-4b53-a437-24bb2e5fc947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a277ab-60e3-4852-9006-1b56a5590f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ac598-e5a5-4d8c-a1d4-9fa37c6ceb40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ba2af-c840-42bb-b0bf-30832420de1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf2737f-29ef-4b74-b7e2-a9e17598594f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f81b7e9-3ca9-49e2-8be2-916021b97650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab4d8a-8052-4974-b449-a78df93eb61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5a829-b951-4fc3-83f7-f3ba5fa8ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13995e1-42ff-490d-92d7-00c996f3e58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2005b4ad-a44d-47ea-a25f-6adf915b2aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d32f13-0eb9-4bbf-b28f-34882863dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e971c-cb8b-4905-a21c-07291d66c4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146e193-c2dd-454c-8e4e-15a0f91104e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3f0b4-024c-48de-a573-8b937e613a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536d8b6-5de0-42b0-a34a-caa95f818d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c63828-3b2b-4fbc-8b07-c08d6cc3964f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00cb08-660c-48bc-82ee-bafcee6e1fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a5bc5-5b8c-4afa-87cd-09ada92a1ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ea1129-4fb5-4412-84af-13b7ad5719c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a387829-0745-4471-903a-0e24660a9c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ccf58-791c-4978-942e-78ddea48be31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f83db-8ad5-47b3-a520-d38b3a4db797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e73f3-8713-4db9-b811-7ae6d5ada9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a14a328-72f1-4aaf-a7e6-7cc2027001c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedbd48-6ac3-4b03-827c-84f75b209377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b170d1-a104-4cf6-92d0-91486e039f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc915723-7266-40ec-9a31-1f46c2395042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad42c53-0431-41c3-bdeb-9b8bf1d48c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71af62-8ea2-45cb-bdf8-07221366f847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e1f32-c9b6-44f4-9aa8-5ae8cd237a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089fec90-1d50-4520-92c5-06b706bacdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e6e56-dcc3-421c-a9e6-9699a9ed4656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7a819-f7e0-4441-8923-5a73d01104ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518d845-943d-4a34-ad0e-71d174ca1ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ded1f1-6923-40aa-94d6-f9718dbe32a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed4911-a23d-43e1-b0e5-791c0be0dba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc617ad-3239-4601-8143-7b301062fcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7443687-0e2d-4ae8-8b89-a47231a339c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671a353-4c84-499c-9e06-eab1ae6b1166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d0087-7cbd-4415-bc91-4d6f89244445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805bebc0-26df-4bb0-b17e-fa138f8caa17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b2812-cf06-4b93-8f60-33edb0256088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9620d60-5e0a-4bd6-ba4a-ec3c48ba574a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17672f92-c495-453e-93a1-99e4552d2a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1aaa1d-53a3-4db0-a586-f99960f2046a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a183c0-5bfe-424f-ac6e-0fca617cb81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b129f10-29f1-4f5e-b9a5-95cee5644920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd11de-9068-4a60-860f-a4f9bd74fd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3bda3f-a666-4666-ac32-efb83993438c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877d599-6f70-4099-9b80-93c98ea92249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed396265-9db3-4e13-a627-af4764d0ad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6dedfa-52ca-4d93-8275-38b69e11f0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42249d7-a3f3-40e2-80a2-4fb11c099dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7449770-cb32-4f0d-b7c4-d15d5b534655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b709fc8-2b7e-4a31-a338-f483ea96ccc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914428e-e380-4a22-8d50-7259ee22f40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576bb0b-871b-4d59-aa6c-e9f5023f5f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb4080-d8b1-4f05-bb61-95390a20dc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1f6fca-9301-4079-9d8f-ddf1255d9011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e34267-a591-4b46-85d0-e708372c3f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed5390-7a97-4594-ae62-187defe862f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca84226-3cb9-4cb3-a4b3-3b19b9107d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9d7c2-2674-465a-95ab-6c0163ec6a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf9bc1-14e7-4efc-a780-41ff6d1f4086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984f4df-66e7-4f19-a5c1-d5646ba9da7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ea6d9-a2d8-4c72-ae03-69cfd3647e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9971d57-8cfc-4b29-a4aa-f261abfd58e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144e862-28c1-47aa-8fac-3460b99f5cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f0d48-a38e-4b2a-a89f-e6e5576d2af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bd4a3-e57e-4210-b867-b821affd945b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb15a9a-ed1f-4056-a544-e60020f46298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad710e-afac-4f72-a69e-f33d2483ebe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c64394-8d79-4bd4-a797-6447babc5c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a4941-b96a-4629-89fe-51e0a3724885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d6628d-23c0-4fa5-a3d2-ac0317a0d894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25545523-7844-47e0-8c6d-1d1ebef4fb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec25a69-2599-4cf8-b1e9-1de431c98657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ffb55-513b-4307-906f-392f7d40ee89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5965cf2-d78c-4b3c-805f-0b0e089d9c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e4048-762a-481c-9ca0-18c8b89e6a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e83fa-3a81-4a5d-b452-9c893a0606bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414d496-0527-471a-8c1f-ae9b3465d774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66843ec-c88e-4b1a-87b1-3600c7040d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcc897-edd1-46dd-972c-09bd00e72613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9395220-c457-4b77-a50d-11f90f713477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79274f3b-c1cc-4d84-9de9-660a52fa20ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818173e8-6a90-4b0c-ae5c-efb3417870ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9664e89-9c79-4bac-8792-2413fd86d811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43262a5-557b-4e32-abe3-611fc3b1303d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44970a-071a-4932-878d-cf653ac3555f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a00b4ff-910c-4cf6-b993-725c4c8628ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00863142-d28c-48d3-b669-1696657698e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f72dc1-00fa-4408-8aec-28002e702972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b1783-aa19-4823-b938-72569c14701d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20be17-1e71-4c6c-8106-35a88b8ba0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c94e6-3ac5-4170-8690-88fb7f69e0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a51f7-5384-47d0-a5f4-4470deccd1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e8b66-a598-4d62-b38e-656b46ea593c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86217d6-a7af-453a-8a59-6f7daa5d22ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbe16d-99c4-44a2-962a-0c6972039ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77500d-76bc-4461-839c-d1c6d42fa959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81653831-98fd-4cca-849e-0bdcb65aaea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b2557-3ade-43bf-9a01-573f0318f176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f68a4-683c-4b88-b60d-615e1bf5f0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d11ec-9a6b-436e-bb17-2185570fcf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf0b6f-7a04-47cc-b95a-6b4a0c4001a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca216044-2349-461b-82ac-f9b5e47bb211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9945bfc-ff10-49b5-b4b9-f348488c6930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1994c78-363f-4846-ba56-1e76cb300882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8656dd4-fe63-4e09-835e-327225145eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf1c83-2996-4aed-8f85-a395bfa9a202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7873bb-9dde-4bbe-9ae3-41adde28bb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d12c9-032c-4f7c-a806-176b3939d816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858eb82-709c-439f-b31b-9cde5c21818c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a31e68-6e43-4c11-9f52-0e5e5f0936c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37caf363-9b97-4966-bf74-556a563b54fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c631d-cd4f-419e-837d-aacd71e5ea6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1e6b5-9721-4d16-a8eb-110085091f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b3e6e1-f01c-4740-9e43-328f44894574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da468ad-7bdc-46e4-b061-0d1966d528c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2b8bf-32b1-4ebc-b3c4-99001e3b0670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee346e-95a2-4c8a-b72c-6624ef76dc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae5fc42-d54f-44b1-8416-19f7bfb0af05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e0a9b-3eb4-4fd6-bc21-ea18016acfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8d006-1123-47b5-a95a-497a6761c29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d3610-a127-4256-922e-c6a176752f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a8b2e-7921-47c5-b6de-4cd6bbd25c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e39de-ad9a-4926-8863-44869a4f9e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b095f5-2f9d-45c3-86c2-a5190f0871f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5569e9-48b2-450a-ad64-5828cc02b7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b289417-266b-4516-94f5-da24859513fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250a044-f087-48dd-b534-fb0bb99829c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b653bddd-1b2a-4526-9a69-ce2ff0153d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061663c8-5397-4426-9970-d9c3ca0d4d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5eecc-d7f3-4437-a514-dfe73e4c6e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21504c-d63d-4c0a-bd0f-2c0ef68b615c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563915f-4403-4ee5-8c3d-2821f6bcb146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493c584-9b05-464a-9c6b-9245bdfe9e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932eefaf-23e4-4cbf-b09e-98773eeeb36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d750dc-d8e1-4a79-8ae5-c59292821acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a8f70-5b2e-4f27-8a3d-42c398cc88b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc6d5f-c8e9-42cc-8667-baa99b0ab305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebd7f0a-46a2-4eb4-b73d-0a2a4cbd6930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588966db-cf17-4268-855b-8d0526e4a5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046da16-d45b-43e5-8b34-de890a5c431c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a28500a-96b0-4d86-af3b-4986becb263a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f076c7-63d8-4e3a-82fc-0819684a6fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eaf844-4af0-4ed6-84fb-3cceb090eb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a753a-ee68-47b8-8476-f7166982200e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a9b09-064a-4962-bc13-38120a8e5d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9504d51-051f-4e7f-82e7-ec3dfb8dcc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe1aab6-244c-45f6-83c6-dc14f19171b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b30c09-573a-4d3c-946d-8bcc154a69cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b7aee-dd75-4861-9d0b-147bab0765ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4e3c5-ed9e-492d-be61-459963c92e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f35f2d-0399-4920-852a-7b28e060c976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505dc80-7718-402a-a992-b78737f8d32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef4bb5-7abd-4c66-9aa0-2347a1cadd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49b91d-8d24-4d63-8d73-4df25369727d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40550b-d924-42df-b785-41818f8f4b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
